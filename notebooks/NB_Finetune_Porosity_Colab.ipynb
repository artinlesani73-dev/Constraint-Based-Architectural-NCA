{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning for Porous Structures (Google Colab)\n",
    "\n",
    "This notebook fine-tunes the v3.1 MODEL C to produce more porous, lightweight architectural structures.\n",
    "\n",
    "## Setup Instructions\n",
    "1. Upload your project files OR mount Google Drive\n",
    "2. Run all setup cells\n",
    "3. Run the fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('WARNING: No GPU detected. Training will be slow.')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive & Setup Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your project path in Google Drive\n",
    "# CHANGE THIS to match your folder location!\n",
    "PROJECT_PATH = '/content/drive/MyDrive/Constraint-Based-Architectural-NCA'\n",
    "\n",
    "# Alternative: If you uploaded as a zip, uncomment below:\n",
    "# !unzip /content/drive/MyDrive/nca_project.zip -d /content/\n",
    "# PROJECT_PATH = '/content/Constraint-Based-Architectural-NCA'\n",
    "\n",
    "import os\n",
    "os.chdir(PROJECT_PATH)\n",
    "print(f'Working directory: {os.getcwd()}')\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify required files exist\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "required_files = [\n",
    "    'notebooks/sel/MODEL C - Copy - no change/v31_fixed_geometry.pth',\n",
    "    'notebooks/sel/MODEL C - Copy - no change/config_step_b.json',\n",
    "    'deploy/model_utils.py'\n",
    "]\n",
    "\n",
    "all_found = True\n",
    "for f in required_files:\n",
    "    exists = os.path.exists(f)\n",
    "    status = 'OK' if exists else 'MISSING'\n",
    "    print(f'[{status}] {f}')\n",
    "    if not exists:\n",
    "        all_found = False\n",
    "\n",
    "if not all_found:\n",
    "    print('\\nERROR: Some files are missing. Please check your PROJECT_PATH.')\n",
    "else:\n",
    "    print('\\nAll required files found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add deploy to path for imports\n",
    "sys.path.insert(0, 'deploy')\n",
    "\n",
    "from model_utils import (\n",
    "    UrbanPavilionNCA,\n",
    "    UrbanSceneGenerator,\n",
    "    compute_corridor_target_v31,\n",
    "    LocalLegalityLoss\n",
    ")\n",
    "\n",
    "print('Imports successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_MODEL_DIR = Path('notebooks/sel/MODEL C - Copy - no change')\n",
    "CONFIG_PATH = BASE_MODEL_DIR / 'config_step_b.json'\n",
    "CHECKPOINT_PATH = BASE_MODEL_DIR / 'v31_fixed_geometry.pth'\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = Path('notebooks/finetuned_porous')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Load config\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    CONFIG = json.load(f)\n",
    "\n",
    "# Fine-tuning modifications\n",
    "CONFIG['max_thickness'] = 1      # Reduced from 2\n",
    "CONFIG['fill_ratio_min'] = 0.03  # Reduced from 0.05\n",
    "CONFIG['fill_ratio_max'] = 0.10  # Reduced from 0.15\n",
    "CONFIG['lr_finetune'] = 0.0005   # Half of original\n",
    "CONFIG['batch_size'] = 4         # Adjust based on GPU memory\n",
    "\n",
    "print('Config loaded with fine-tuning modifications:')\n",
    "print(f\"  max_thickness: {CONFIG['max_thickness']} (was 2)\")\n",
    "print(f\"  lr_finetune: {CONFIG['lr_finetune']}\")\n",
    "print(f\"  batch_size: {CONFIG['batch_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "model = UrbanPavilionNCA(CONFIG).to(device)\n",
    "\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded checkpoint from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
    "else:\n",
    "    model.load_state_dict(checkpoint)\n",
    "    print('Loaded checkpoint (raw state dict)')\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Model parameters: {n_params:,}')\n",
    "print(f'Model on: {next(model.parameters()).device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ EXISTING LOSSES ============\n",
    "\n",
    "class CorridorCoverageLoss(nn.Module):\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, structure, corridor_target):\n",
    "        corridor_mask = corridor_target > 0.5\n",
    "        corridor_volume = corridor_mask.float().sum() + 1e-8\n",
    "        covered = (structure * corridor_mask.float()).sum()\n",
    "        coverage_ratio = covered / corridor_volume\n",
    "        return F.relu(0.7 - coverage_ratio)\n",
    "\n",
    "\n",
    "class CorridorSpillLoss(nn.Module):\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, structure, corridor_target, legality_field):\n",
    "        outside_corridor = (corridor_target < 0.5).float()\n",
    "        legal_outside = outside_corridor * legality_field\n",
    "        spill = (structure * legal_outside).sum()\n",
    "        total_structure = structure.sum() + 1e-8\n",
    "        return spill / total_structure\n",
    "\n",
    "\n",
    "class GroundOpennessLoss(nn.Module):\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.street_levels = config['street_levels']\n",
    "\n",
    "    def forward(self, structure, corridor_target, legality_field):\n",
    "        ground = structure[:, :self.street_levels]\n",
    "        corridor_ground = corridor_target[:, :self.street_levels]\n",
    "        outside_corridor_ground = (corridor_ground < 0.5).float()\n",
    "        unwanted = ground * outside_corridor_ground\n",
    "        return unwanted.mean()\n",
    "\n",
    "\n",
    "class ThicknessLoss(nn.Module):\n",
    "    def __init__(self, max_thickness: int = 1):\n",
    "        super().__init__()\n",
    "        self.max_thickness = max_thickness\n",
    "\n",
    "    def forward(self, structure):\n",
    "        binary = (structure > 0.5).float()\n",
    "        eroded = binary.clone()\n",
    "        for _ in range(self.max_thickness):\n",
    "            eroded = -F.max_pool3d(-eroded.unsqueeze(0).unsqueeze(0), 3, 1, 1).squeeze()\n",
    "        core_ratio = eroded.sum() / (binary.sum() + 1e-8)\n",
    "        return core_ratio\n",
    "\n",
    "\n",
    "class SparsityLossV31(nn.Module):\n",
    "    def __init__(self, target_ratio: float = 0.06):\n",
    "        super().__init__()\n",
    "        self.target = target_ratio\n",
    "\n",
    "    def forward(self, structure, available):\n",
    "        available_vol = available.sum() + 1e-8\n",
    "        filled = structure.sum()\n",
    "        ratio = filled / available_vol\n",
    "        excess = F.relu(ratio - self.target)\n",
    "        return excess ** 2\n",
    "\n",
    "\n",
    "class DensityPenalty(nn.Module):\n",
    "    def __init__(self, target: float = 0.04):\n",
    "        super().__init__()\n",
    "        self.target = target\n",
    "\n",
    "    def forward(self, structure):\n",
    "        return F.relu(structure.mean() - self.target)\n",
    "\n",
    "\n",
    "class TotalVariation3D(nn.Module):\n",
    "    def forward(self, x):\n",
    "        dz = torch.abs(x[:, 1:, :, :] - x[:, :-1, :, :]).mean()\n",
    "        dy = torch.abs(x[:, :, 1:, :] - x[:, :, :-1, :]).mean()\n",
    "        dx = torch.abs(x[:, :, :, 1:] - x[:, :, :, :-1]).mean()\n",
    "        return (dz + dy + dx) / 3\n",
    "\n",
    "\n",
    "class AccessConnectivityLoss(nn.Module):\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, state):\n",
    "        cfg = self.config\n",
    "        structure = state[:, cfg['ch_structure']]\n",
    "        access = state[:, cfg['ch_access']]\n",
    "        dilated = F.max_pool3d(structure.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "        connected = (access * dilated).sum()\n",
    "        total_access = access.sum() + 1e-8\n",
    "        return 1.0 - (connected / total_access)\n",
    "\n",
    "\n",
    "class LoadPathLoss(nn.Module):\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, state):\n",
    "        cfg = self.config\n",
    "        structure = state[:, cfg['ch_structure']]\n",
    "        B, D, H, W = structure.shape\n",
    "        ground_support = structure[:, 0:1].clone()\n",
    "        supported = ground_support\n",
    "        for z in range(1, D):\n",
    "            below = F.max_pool3d(supported.unsqueeze(1), (1, 3, 3), 1, (0, 1, 1)).squeeze(1)\n",
    "            supported = torch.max(supported, torch.min(structure[:, z:z+1], below[:, -1:]))\n",
    "        unsupported = F.relu(structure - supported.expand_as(structure))\n",
    "        return unsupported.mean()\n",
    "\n",
    "\n",
    "class CantileverLoss(nn.Module):\n",
    "    def forward(self, structure):\n",
    "        below = F.pad(structure[:, :-1], (0, 0, 0, 0, 1, 0))\n",
    "        unsupported = F.relu(structure - below)\n",
    "        return unsupported.mean()\n",
    "\n",
    "\n",
    "class FacadeContactLoss(nn.Module):\n",
    "    def __init__(self, config: dict, max_contact_ratio: float = 0.15):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.max_ratio = max_contact_ratio\n",
    "\n",
    "    def forward(self, state):\n",
    "        cfg = self.config\n",
    "        structure = state[:, cfg['ch_structure']]\n",
    "        existing = state[:, cfg['ch_existing']]\n",
    "        dilated_existing = F.max_pool3d(existing.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "        facade_zone = dilated_existing * (1 - existing)\n",
    "        contact = (structure * facade_zone).sum()\n",
    "        total_struct = structure.sum() + 1e-8\n",
    "        ratio = contact / total_struct\n",
    "        return F.relu(ratio - self.max_ratio)\n",
    "\n",
    "\n",
    "print('Existing losses defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ NEW POROSITY LOSSES ============\n",
    "\n",
    "class PorosityLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Encourage internal voids within the structure.\n",
    "    Penalizes structures where interior voxels are filled.\n",
    "    \"\"\"\n",
    "    def __init__(self, target_porosity: float = 0.25, erosion_steps: int = 1):\n",
    "        super().__init__()\n",
    "        self.target_porosity = target_porosity\n",
    "        self.erosion_steps = erosion_steps\n",
    "\n",
    "    def forward(self, structure, corridor):\n",
    "        binary = (structure > 0.5).float()\n",
    "        eroded = binary.clone()\n",
    "        for _ in range(self.erosion_steps):\n",
    "            eroded = -F.max_pool3d(\n",
    "                -eroded.unsqueeze(0).unsqueeze(0), 3, 1, 1\n",
    "            ).squeeze(0).squeeze(0)\n",
    "\n",
    "        interior_mask = eroded > 0.5\n",
    "        if interior_mask.sum() < 10:\n",
    "            return torch.tensor(0.0, device=structure.device)\n",
    "\n",
    "        interior_filled = (structure * interior_mask.float()).sum()\n",
    "        interior_total = interior_mask.float().sum()\n",
    "        fill_ratio = interior_filled / (interior_total + 1e-8)\n",
    "        porosity = 1.0 - fill_ratio\n",
    "        return F.relu(self.target_porosity - porosity)\n",
    "\n",
    "\n",
    "class SurfaceAreaLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Encourage higher surface-to-volume ratio.\n",
    "    Higher = more articulated/lattice-like.\n",
    "    \"\"\"\n",
    "    def __init__(self, target_ratio: float = 2.5):\n",
    "        super().__init__()\n",
    "        self.target_ratio = target_ratio\n",
    "\n",
    "    def forward(self, structure):\n",
    "        binary = (structure > 0.5).float()\n",
    "        volume = binary.sum() + 1e-8\n",
    "        padded = F.pad(binary.unsqueeze(0).unsqueeze(0), (1,1,1,1,1,1), value=0).squeeze()\n",
    "\n",
    "        surface = 0\n",
    "        surface += torch.abs(padded[1:, :, :] - padded[:-1, :, :]).sum()\n",
    "        surface += torch.abs(padded[:, 1:, :] - padded[:, :-1, :]).sum()\n",
    "        surface += torch.abs(padded[:, :, 1:] - padded[:, :, :-1]).sum()\n",
    "\n",
    "        ratio = surface / volume\n",
    "        return F.relu(self.target_ratio - ratio)\n",
    "\n",
    "\n",
    "print('New porosity losses defined')\n",
    "print(f'  PorosityLoss: target_porosity=0.25')\n",
    "print(f'  SurfaceAreaLoss: target_ratio=2.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fine-Tuning Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PorosityFineTuner:\n",
    "    def __init__(self, model, config, device):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        cfg = config\n",
    "\n",
    "        max_thickness = cfg.get('max_thickness', 1)\n",
    "        max_facade = cfg.get('max_facade_contact', 0.15)\n",
    "\n",
    "        # Loss functions\n",
    "        self.legality_loss = LocalLegalityLoss(cfg)\n",
    "        self.coverage_loss = CorridorCoverageLoss(cfg)\n",
    "        self.spill_loss = CorridorSpillLoss(cfg)\n",
    "        self.ground_loss = GroundOpennessLoss(cfg)\n",
    "        self.thickness_loss = ThicknessLoss(max_thickness)\n",
    "        self.sparsity_loss = SparsityLossV31(target_ratio=0.06)\n",
    "        self.facade_loss = FacadeContactLoss(cfg, max_facade)\n",
    "        self.access_conn_loss = AccessConnectivityLoss(cfg)\n",
    "        self.loadpath_loss = LoadPathLoss(cfg)\n",
    "        self.cantilever_loss = CantileverLoss()\n",
    "        self.density_loss = DensityPenalty(target=0.04)\n",
    "        self.tv_loss = TotalVariation3D()\n",
    "        self.porosity_loss = PorosityLoss(target_porosity=0.25)\n",
    "        self.surface_loss = SurfaceAreaLoss(target_ratio=2.5)\n",
    "\n",
    "        # MODIFIED WEIGHTS for porosity\n",
    "        self.weights = {\n",
    "            'legality': 30.0,\n",
    "            'coverage': 20.0,\n",
    "            'spill': 25.0,\n",
    "            'ground': 35.0,\n",
    "            'thickness': 50.0,    # INCREASED\n",
    "            'sparsity': 45.0,     # INCREASED\n",
    "            'facade': 10.0,\n",
    "            'access_conn': 15.0,\n",
    "            'loadpath': 10.0,\n",
    "            'cantilever': 5.0,\n",
    "            'density': 8.0,       # INCREASED\n",
    "            'tv': 0.5,            # REDUCED\n",
    "            'porosity': 20.0,     # NEW\n",
    "            'surface': 10.0,      # NEW\n",
    "        }\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=cfg.get('lr_finetune', 0.0005)\n",
    "        )\n",
    "        self.scene_gen = UrbanSceneGenerator(cfg)\n",
    "        self.history = []\n",
    "\n",
    "    def _random_scene_params(self):\n",
    "        G = self.config['grid_size']\n",
    "        gap_width = np.random.randint(8, 16)\n",
    "        gap_center = G // 2\n",
    "        left_x = (0, gap_center - gap_width // 2)\n",
    "        right_x = (gap_center + gap_width // 2, G)\n",
    "\n",
    "        buildings = [\n",
    "            {'x': list(left_x), 'y': [0, np.random.randint(20, 28)],\n",
    "             'z': [0, np.random.randint(10, 18)], 'side': 'left', 'gap_facing_x': left_x[1]},\n",
    "            {'x': list(right_x), 'y': [0, np.random.randint(16, 24)],\n",
    "             'z': [0, np.random.randint(10, 18)], 'side': 'right', 'gap_facing_x': right_x[0]}\n",
    "        ]\n",
    "\n",
    "        access_points = [\n",
    "            {'x': gap_center, 'y': np.random.randint(18, 26), 'z': 0, 'type': 'ground'}\n",
    "        ]\n",
    "        if np.random.random() > 0.3:\n",
    "            access_points.append({\n",
    "                'x': np.random.choice([left_x[1], right_x[0]]),\n",
    "                'y': np.random.randint(2, 8),\n",
    "                'z': np.random.randint(6, 12),\n",
    "                'type': 'elevated'\n",
    "            })\n",
    "\n",
    "        return {'buildings': buildings, 'access_points': access_points}\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        cfg = self.config\n",
    "        batch_size = cfg.get('batch_size', 4)\n",
    "\n",
    "        seeds, corridors = [], []\n",
    "        for _ in range(batch_size):\n",
    "            params = self._random_scene_params()\n",
    "            seed, _ = self.scene_gen.generate(params, device=self.device)\n",
    "            corridor = compute_corridor_target_v31(seed, cfg)\n",
    "            seeds.append(seed)\n",
    "            corridors.append(corridor)\n",
    "\n",
    "        seeds = torch.cat(seeds, dim=0)\n",
    "        corridor_target = torch.cat(corridors, dim=0)\n",
    "\n",
    "        seed_scale = cfg.get('corridor_seed_scale', 0.15)\n",
    "        if seed_scale > 0:\n",
    "            seeds[:, cfg['ch_structure']] = torch.clamp(\n",
    "                seeds[:, cfg['ch_structure']] + seed_scale * corridor_target, 0, 1\n",
    "            )\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        steps = np.random.randint(40, 60)\n",
    "        final = self.model(seeds, steps=steps)\n",
    "\n",
    "        structure = final[:, cfg['ch_structure']]\n",
    "        existing = final[:, cfg['ch_existing']]\n",
    "        available = 1.0 - existing\n",
    "        legality_field = self.legality_loss.compute_legality_field(final)\n",
    "\n",
    "        # Compute all losses\n",
    "        losses = {\n",
    "            'legality': self.legality_loss(final),\n",
    "            'coverage': self.coverage_loss(structure, corridor_target),\n",
    "            'spill': self.spill_loss(structure, corridor_target, legality_field),\n",
    "            'ground': self.ground_loss(structure, corridor_target, legality_field),\n",
    "            'thickness': self.thickness_loss(structure),\n",
    "            'sparsity': self.sparsity_loss(structure, available),\n",
    "            'facade': self.facade_loss(final),\n",
    "            'access_conn': self.access_conn_loss(final),\n",
    "            'loadpath': self.loadpath_loss(final),\n",
    "            'cantilever': self.cantilever_loss(structure),\n",
    "            'density': self.density_loss(structure),\n",
    "            'tv': self.tv_loss(structure),\n",
    "            'porosity': self.porosity_loss(structure, corridor_target),\n",
    "            'surface': self.surface_loss(structure),\n",
    "        }\n",
    "\n",
    "        total_loss = sum(self.weights[k] * v for k, v in losses.items())\n",
    "\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), cfg.get('grad_clip', 1.0))\n",
    "        self.optimizer.step()\n",
    "\n",
    "        metrics = {\n",
    "            'epoch': epoch,\n",
    "            'total_loss': total_loss.item(),\n",
    "            'L_porosity': losses['porosity'].item(),\n",
    "            'L_thickness': losses['thickness'].item(),\n",
    "            'L_coverage': losses['coverage'].item(),\n",
    "            'L_sparsity': losses['sparsity'].item(),\n",
    "            'fill_ratio': structure.mean().item(),\n",
    "        }\n",
    "        self.history.append(metrics)\n",
    "        return metrics\n",
    "\n",
    "    def evaluate(self, n_samples=8):\n",
    "        self.model.eval()\n",
    "        cfg = self.config\n",
    "        results = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(n_samples):\n",
    "                params = self._random_scene_params()\n",
    "                seed, _ = self.scene_gen.generate(params, device=self.device)\n",
    "                corridor = compute_corridor_target_v31(seed, cfg)\n",
    "\n",
    "                seed_scale = cfg.get('corridor_seed_scale', 0.15)\n",
    "                if seed_scale > 0:\n",
    "                    seed[:, cfg['ch_structure']] += seed_scale * corridor\n",
    "\n",
    "                grown = self.model(seed, steps=50)\n",
    "                structure = grown[:, cfg['ch_structure']]\n",
    "\n",
    "                corridor_mask = corridor > 0.5\n",
    "                coverage = (structure * corridor_mask.float()).sum() / (corridor_mask.sum() + 1e-8)\n",
    "                outside = (corridor < 0.5).float()\n",
    "                spill = (structure * outside).sum() / (structure.sum() + 1e-8)\n",
    "\n",
    "                results.append({\n",
    "                    'coverage': coverage.item(),\n",
    "                    'spill': spill.item(),\n",
    "                    'fill_ratio': structure.mean().item(),\n",
    "                })\n",
    "\n",
    "        return {\n",
    "            'avg_coverage': np.mean([r['coverage'] for r in results]),\n",
    "            'avg_spill': np.mean([r['spill'] for r in results]),\n",
    "            'avg_fill_ratio': np.mean([r['fill_ratio'] for r in results]),\n",
    "        }\n",
    "\n",
    "    def save_checkpoint(self, path, epoch):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'weights': self.weights,\n",
    "            'history': self.history,\n",
    "        }, path)\n",
    "        print(f'Saved checkpoint to {path}')\n",
    "\n",
    "\n",
    "print('PorosityFineTuner defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = PorosityFineTuner(model, CONFIG, device)\n",
    "\n",
    "print('Fine-tuning weights:')\n",
    "for name, weight in trainer.weights.items():\n",
    "    marker = ' *' if name in ['thickness', 'sparsity', 'density', 'porosity', 'surface'] else ''\n",
    "    print(f'  {name}: {weight}{marker}')\n",
    "print('\\n* = modified/new for porosity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning parameters\n",
    "N_EPOCHS = 150       # Total epochs\n",
    "EVAL_EVERY = 10      # Evaluate every N epochs\n",
    "SAVE_EVERY = 25      # Save checkpoint every N epochs\n",
    "\n",
    "print(f'Starting fine-tuning for {N_EPOCHS} epochs...')\n",
    "print(f'  Device: {device}')\n",
    "print(f'  Batch size: {CONFIG[\"batch_size\"]}')\n",
    "print(f'  Learning rate: {CONFIG[\"lr_finetune\"]}')\n",
    "print(f'  Eval every {EVAL_EVERY} epochs')\n",
    "print(f'  Save every {SAVE_EVERY} epochs')\n",
    "print(f'  Output: {OUTPUT_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "best_fill_ratio = 1.0\n",
    "\n",
    "for epoch in tqdm(range(1, N_EPOCHS + 1), desc='Fine-tuning'):\n",
    "    metrics = trainer.train_epoch(epoch)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(\n",
    "            f\"Epoch {epoch:4d} | Loss: {metrics['total_loss']:.2f} | \"\n",
    "            f\"Fill: {metrics['fill_ratio']*100:.1f}% | \"\n",
    "            f\"Poros: {metrics['L_porosity']:.3f} | \"\n",
    "            f\"Thick: {metrics['L_thickness']:.3f}\"\n",
    "        )\n",
    "\n",
    "    if epoch % EVAL_EVERY == 0:\n",
    "        eval_results = trainer.evaluate(n_samples=8)\n",
    "        print(f\"  [EVAL] Coverage: {eval_results['avg_coverage']*100:.1f}% | \"\n",
    "              f\"Spill: {eval_results['avg_spill']*100:.1f}% | \"\n",
    "              f\"Fill: {eval_results['avg_fill_ratio']*100:.1f}%\")\n",
    "\n",
    "        if eval_results['avg_fill_ratio'] < best_fill_ratio and eval_results['avg_coverage'] > 0.5:\n",
    "            best_fill_ratio = eval_results['avg_fill_ratio']\n",
    "            trainer.save_checkpoint(OUTPUT_DIR / 'best_porous.pth', epoch)\n",
    "\n",
    "    if epoch % SAVE_EVERY == 0:\n",
    "        trainer.save_checkpoint(OUTPUT_DIR / f'checkpoint_epoch_{epoch}.pth', epoch)\n",
    "\n",
    "# Final save\n",
    "trainer.save_checkpoint(OUTPUT_DIR / 'final_porous.pth', N_EPOCHS)\n",
    "print('\\nFine-tuning complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "history = trainer.history\n",
    "epochs = [h['epoch'] for h in history]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "\n",
    "axes[0, 0].plot(epochs, [h['total_loss'] for h in history])\n",
    "axes[0, 0].set_title('Total Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "\n",
    "axes[0, 1].plot(epochs, [h['L_porosity'] for h in history], 'g')\n",
    "axes[0, 1].set_title('Porosity Loss')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "\n",
    "axes[0, 2].plot(epochs, [h['L_thickness'] for h in history], 'purple')\n",
    "axes[0, 2].set_title('Thickness Loss')\n",
    "axes[0, 2].set_xlabel('Epoch')\n",
    "\n",
    "axes[1, 0].plot(epochs, [h['fill_ratio'] * 100 for h in history], 'orange')\n",
    "axes[1, 0].set_title('Fill Ratio %')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].axhline(y=10, color='r', linestyle='--', alpha=0.5, label='Target max')\n",
    "\n",
    "axes[1, 1].plot(epochs, [h['L_coverage'] for h in history], 'b')\n",
    "axes[1, 1].set_title('Coverage Loss')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "\n",
    "axes[1, 2].plot(epochs, [h['L_sparsity'] for h in history], 'r')\n",
    "axes[1, 2].set_title('Sparsity Loss')\n",
    "axes[1, 2].set_xlabel('Epoch')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'training_curves.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model\n",
    "model.eval()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "scene_gen = UrbanSceneGenerator(CONFIG)\n",
    "params = {\n",
    "    'buildings': [\n",
    "        {'x': [1, 9], 'y': [0, 27], 'z': [0, 14], 'side': 'left', 'gap_facing_x': 9},\n",
    "        {'x': [23, 32], 'y': [0, 19], 'z': [0, 14], 'side': 'right', 'gap_facing_x': 23}\n",
    "    ],\n",
    "    'access_points': [\n",
    "        {'x': 12, 'y': 23, 'z': 0, 'type': 'ground'},\n",
    "        {'x': 9, 'y': 1, 'z': 11, 'type': 'elevated'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "seed_state, _ = scene_gen.generate(params, device=device)\n",
    "corridor = compute_corridor_target_v31(seed_state, CONFIG)\n",
    "\n",
    "seed_scale = CONFIG.get('corridor_seed_scale', 0.15)\n",
    "if seed_scale > 0:\n",
    "    seed_state[:, CONFIG['ch_structure']] += seed_scale * corridor\n",
    "\n",
    "with torch.no_grad():\n",
    "    result = model(seed_state, steps=50)\n",
    "\n",
    "structure = (result[0, CONFIG['ch_structure']] > 0.5).cpu().numpy()\n",
    "print(f'Fine-tuned model fill ratio: {structure.mean()*100:.1f}%')\n",
    "print(f'Structure voxels: {structure.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy best model to deploy folder\n",
    "import shutil\n",
    "\n",
    "deploy_model_dir = Path('deploy/models')\n",
    "deploy_model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "best_checkpoint = OUTPUT_DIR / 'best_porous.pth'\n",
    "if best_checkpoint.exists():\n",
    "    shutil.copy(best_checkpoint, deploy_model_dir / 'v31_porous.pth')\n",
    "    print(f'Copied best model to {deploy_model_dir / \"v31_porous.pth\"}')\n",
    "else:\n",
    "    final_checkpoint = OUTPUT_DIR / 'final_porous.pth'\n",
    "    shutil.copy(final_checkpoint, deploy_model_dir / 'v31_porous.pth')\n",
    "    print(f'Copied final model to {deploy_model_dir / \"v31_porous.pth\"}')\n",
    "\n",
    "# Save config\n",
    "with open(deploy_model_dir / 'config_porous.json', 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "print(f'Saved config to {deploy_model_dir / \"config_porous.json\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model (for local use)\n",
    "from google.colab import files\n",
    "\n",
    "print('Downloading fine-tuned model...')\n",
    "files.download(str(deploy_model_dir / 'v31_porous.pth'))\n",
    "files.download(str(deploy_model_dir / 'config_porous.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Fine-tuning complete! The model has been trained with:\n",
    "\n",
    "1. **Increased thickness penalty** (30 -> 50)\n",
    "2. **Increased sparsity penalty** (30 -> 45)\n",
    "3. **New PorosityLoss** targeting 25% internal voids\n",
    "4. **New SurfaceAreaLoss** encouraging articulated forms\n",
    "5. **Reduced max_thickness** (2 -> 1)\n",
    "\n",
    "### Next Steps\n",
    "1. Download the model files\n",
    "2. Place `v31_porous.pth` and `config_porous.json` in your local `deploy/models/` folder\n",
    "3. Update `server.py` to load the new model (or add a model selector)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
