{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# NB02: Phase 1 - Core Constraints\n\n**Constraint-Based Architectural NCA**\n\n**Version:** 1.6\n**Date:** December 2025\n**Purpose:** Train Phase 1 - Core Constraints (C1A, C1B, C3A, C4B, C4C + Quality Losses)\n\n---\n\n## Aims\n\n1. Implement ConnectivityLoss (C1A) - No floating voxels\n2. Implement CantileverLoss (C1B) - Limit horizontal overhangs\n3. Implement SparsityLoss (C3A) - Prevent fill-everything solution\n4. Implement AccessReachLoss (C4B) - Structure/walkable must reach access points\n5. Implement WalkableCoverageLoss (C4C) - Walkable surfaces must develop\n6. Implement ExclusionLoss - No structure inside existing buildings\n7. Implement DensityPenalty (SIMP) - Encourage binary outputs\n8. Implement TotalVariation - Smooth surfaces\n9. Implement DiceLoss for structure growth incentive\n10. Implement WalkableDiceLoss for walkable growth incentive\n11. Train on easy scenes with all core constraints\n12. Save Phase 1 checkpoint\n\n## Success Criteria\n\n- Connectivity rate >95% on easy scenes\n- Cantilever compliance >90%\n- Fill ratio between 3-25%\n- Access reach >80%\n- Walkable coverage 20-100%\n- Overlap ratio <1% (no structure inside buildings)\n- Structure is non-blobby (distributed, not solid mass)\n- Model produces vertical growth reaching elevated access points\n\n## Dependencies\n\n- NB01_Foundation (core components)\n\n## Key Fixes\n\n**v1.6:**\n- **Perception padding**: REPLICATE padding instead of zero-padding to eliminate boundary gradient artifacts (systematic x=0 bias)\n- **Access point randomization**: Full randomization across valid locations (ground in gap, facades facing gap - not rooftops, not back facades)\n- **Axis labels**: Correct tensor dimension mapping in visualizations\n\n**v1.5:**\n- DensityPenalty (SIMP): `(s * (1-s)).mean()` - penalizes intermediate values\n- TotalVariation: Smooth surfaces\n- Quality ramp-up: Quality losses start after epoch 100\n\n**v1.4:**\n- ExclusionLoss: No structure inside existing buildings\n- Hard mask in NCA\n\n---",
   "metadata": {
    "id": "header"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Setup"
   ],
   "metadata": {
    "id": "setup_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "PROJECT_ROOT = '/content/drive/MyDrive/Constraint-NCA'\n",
    "print(f'Project root: {PROJECT_ROOT}')"
   ],
   "metadata": {
    "id": "mount_drive"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ],
   "metadata": {
    "id": "imports"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Set seeds\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ],
   "metadata": {
    "id": "seeds"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Load configuration from NB01\nwith open(f'{PROJECT_ROOT}/config.json', 'r') as f:\n    CONFIG = json.load(f)\n\n# Add Phase 1 specific config\nCONFIG.update({\n    'phase': 1,\n    'epochs': 400,\n    'steps_min': 30,\n    'steps_max': 50,\n    'difficulty': 'easy',\n    'access_type': 'mixed',  # Must include elevated access points\n    'log_every': 20,\n    'viz_every': 100,\n    'save_every': 100,\n})\n\nprint('Configuration loaded')\nprint(f\"Access type: {CONFIG['access_type']} (includes elevated access points)\")\nprint(f\"Walkable bias: {CONFIG['walkable_bias']}\")",
   "metadata": {
    "id": "config"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Copy Foundation Components from NB01\n",
    "\n",
    "*(In practice, these would be imported from a shared module. For Colab, we include them here.)*"
   ],
   "metadata": {
    "id": "foundation_header"
   }
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# PERCEPTION MODULE (from NB01 - with REPLICATE padding fix)\n# ============================================================\n\nclass Perceive3D(nn.Module):\n    \"\"\"3D Sobel perception for NCA.\n    \n    Uses REPLICATE padding to avoid boundary artifacts that cause\n    systematic growth bias toward grid edges.\n    \"\"\"\n\n    def __init__(self, n_channels: int = 8):\n        super().__init__()\n        self.n_channels = n_channels\n\n        sobel_x = self._create_sobel_kernel('x')\n        sobel_y = self._create_sobel_kernel('y')\n        sobel_z = self._create_sobel_kernel('z')\n        identity = self._create_identity_kernel()\n\n        kernels = torch.stack([identity, sobel_x, sobel_y, sobel_z], dim=0)\n        self.register_buffer('kernels', kernels)\n\n    def _create_sobel_kernel(self, direction: str) -> torch.Tensor:\n        derivative = torch.tensor([-1., 0., 1.])\n        smoothing = torch.tensor([1., 2., 1.])\n\n        if direction == 'x':\n            kernel = torch.einsum('i,j,k->ijk', smoothing, smoothing, derivative)\n        elif direction == 'y':\n            kernel = torch.einsum('i,j,k->ijk', smoothing, derivative, smoothing)\n        elif direction == 'z':\n            kernel = torch.einsum('i,j,k->ijk', derivative, smoothing, smoothing)\n        return kernel / 16.0\n\n    def _create_identity_kernel(self) -> torch.Tensor:\n        kernel = torch.zeros(3, 3, 3)\n        kernel[1, 1, 1] = 1.0\n        return kernel\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        B, C, D, H, W = x.shape\n        \n        # Use REPLICATE padding to avoid boundary artifacts\n        x_padded = F.pad(x, (1, 1, 1, 1, 1, 1), mode='replicate')\n        \n        outputs = []\n        for k in range(4):\n            kernel = self.kernels[k:k+1].unsqueeze(0).expand(C, 1, 3, 3, 3)\n            out = F.conv3d(x_padded, kernel, padding=0, groups=C)\n            outputs.append(out)\n        return torch.cat(outputs, dim=1)",
   "metadata": {
    "id": "perception"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# NCA MODEL (v1.4 - with exclusion mask for existing buildings)\n# ============================================================\n\nclass UrbanPavilionNCA(nn.Module):\n    \"\"\"Neural Cellular Automaton for urban pavilion generation.\n    \n    v1.4 FIX: Added hard mask to prevent structure/walkable inside existing buildings.\n    v1.3 FIX: Added hard mask to ensure walkable ONLY exists where structure exists.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        super().__init__()\n        self.config = config\n\n        n_channels = config['n_channels']\n        hidden_dim = config['hidden_dim']\n        perception_dim = n_channels * 4\n        n_grown = config['n_grown']\n\n        self.perceive = Perceive3D(n_channels)\n\n        self.update_net = nn.Sequential(\n            nn.Conv3d(perception_dim, hidden_dim, 1),\n            nn.ReLU(),\n            nn.Conv3d(hidden_dim, hidden_dim, 1),\n            nn.ReLU(),\n            nn.Conv3d(hidden_dim, n_grown, 1),\n        )\n\n        self._init_weights()\n\n    def _init_weights(self):\n        gain = self.config['xavier_gain']\n        for m in self.update_net:\n            if isinstance(m, nn.Conv3d):\n                nn.init.xavier_uniform_(m.weight, gain=gain)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n        last_layer = self.update_net[-1]\n        with torch.no_grad():\n            last_layer.bias[0] = self.config['structure_bias']\n            last_layer.bias[1] = self.config['walkable_bias']\n\n    def forward(self, state: torch.Tensor, steps: int = 1) -> torch.Tensor:\n        for _ in range(steps):\n            state = self._step(state)\n        return state\n\n    def _step(self, state: torch.Tensor) -> torch.Tensor:\n        B, C, D, H, W = state.shape\n        cfg = self.config\n\n        perception = self.perceive(state)\n        delta = self.update_net(perception)\n\n        if self.training:\n            fire_mask = (torch.rand(B, 1, D, H, W, device=state.device) < cfg['fire_rate']).float()\n            delta = delta * fire_mask\n\n        # Soft gate for walkable updates (gradient-friendly)\n        structure = state[:, cfg['ch_structure']:cfg['ch_structure']+1]\n        gate = torch.sigmoid(10.0 * (structure - 0.3))\n\n        delta_gated = delta.clone()\n        delta_gated = torch.cat([\n            delta[:, 0:1],  # structure delta (unchanged)\n            delta[:, 1:2] * gate,  # walkable delta (gated)\n            delta[:, 2:],  # other channels (unchanged)\n        ], dim=1)\n\n        # Apply updates to grown channels\n        grown_start = cfg['n_frozen']\n        grown_new = state[:, grown_start:] + cfg['update_scale'] * delta_gated\n        grown_new = torch.clamp(grown_new, 0.0, 1.0)\n\n        # ====== HARD MASKS (v1.4) - avoid in-place operations ======\n        \n        # Get existing buildings mask (frozen, doesn't change)\n        existing = state[:, cfg['ch_existing']:cfg['ch_existing']+1]\n        available_mask = 1.0 - existing  # Where structure CAN exist\n        \n        # Extract structure and walkable from grown channels\n        # grown channels order: structure (0), walkable (1), alive (2), hidden (3)\n        struct_new = grown_new[:, 0:1] * available_mask  # Mask out existing buildings\n        \n        # Walkable: only where structure exists AND not in existing buildings\n        walkable_mask = (struct_new > 0.3).float()  # Must be on structure\n        walk_new = grown_new[:, 1:2] * walkable_mask\n        \n        # Reconstruct grown channels (no in-place modification)\n        grown_masked = torch.cat([\n            struct_new,\n            walk_new,\n            grown_new[:, 2:],  # alive and hidden unchanged\n        ], dim=1)\n\n        # Reconstruct full state (frozen channels unchanged)\n        new_state = torch.cat([\n            state[:, :grown_start],  # frozen channels\n            grown_masked,  # masked grown channels\n        ], dim=1)\n\n        return new_state\n\n    def grow(self, seed: torch.Tensor, steps: int = 50) -> torch.Tensor:\n        self.eval()\n        with torch.no_grad():\n            return self.forward(seed, steps)",
   "metadata": {
    "id": "nca_model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# SCENE GENERATOR (v1.6 - Randomized access point placement)\n# ============================================================\n\nclass UrbanSceneGenerator:\n    \"\"\"Generate urban scenes with buildings and access points.\n    \n    v1.6 Updates:\n    - Full randomization of access point placement\n    - Access points can be anywhere on facades facing the gap, or on ground\n    - NOT inside buildings, NOT on rooftops, NOT on back facades\n    - Tracks gap_facing_x for each building to identify valid facade positions\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config\n        self.G = config['grid_size']\n        self.C = config['n_channels']\n\n    def generate(self, difficulty: str = 'easy', access_type: str = 'mixed',\n                 device: str = 'cuda') -> Tuple[torch.Tensor, dict]:\n        G = self.G\n        state = torch.zeros(1, self.C, G, G, G, device=device)\n        state[:, self.config['ch_ground'], 0, :, :] = 1.0\n\n        params = self._get_difficulty_params(difficulty)\n        building_info = self._place_buildings(state, params)\n        access_info = self._place_access_points(state, access_type, params, building_info)\n\n        metadata = {\n            'difficulty': difficulty,\n            'access_type': access_type,\n            'buildings': building_info,\n            'access_points': access_info,\n            'gap_width': params['gap_width'],\n        }\n        return state, metadata\n\n    def _get_difficulty_params(self, difficulty: str) -> dict:\n        G = self.G\n        if difficulty == 'easy':\n            return {\n                'n_buildings': 2, 'height_range': (12, 16), 'height_variance': False,\n                'width_range': (8, 12), 'gap_width': random.randint(12, 16),\n                'n_ground_access': 1, 'n_elevated_access': 1,\n            }\n        elif difficulty == 'medium':\n            return {\n                'n_buildings': 2, 'height_range': (10, 20), 'height_variance': True,\n                'width_range': (6, 10), 'gap_width': random.randint(8, 12),\n                'n_ground_access': random.randint(1, 2), 'n_elevated_access': random.randint(1, 2),\n            }\n        elif difficulty == 'hard':\n            return {\n                'n_buildings': random.randint(2, 4), 'height_range': (8, 24), 'height_variance': True,\n                'width_range': (5, 8), 'gap_width': random.randint(5, 8),\n                'n_ground_access': random.randint(2, 3), 'n_elevated_access': random.randint(2, 3),\n            }\n        else:\n            return {\n                'n_buildings': random.randint(2, 4), 'height_range': (8, 24), 'height_variance': True,\n                'width_range': (5, 12), 'gap_width': random.randint(5, 16),\n                'n_ground_access': random.randint(1, 3), 'n_elevated_access': random.randint(1, 3),\n            }\n\n    def _place_buildings(self, state: torch.Tensor, params: dict) -> list:\n        G = self.G\n        ch = self.config['ch_existing']\n        buildings = []\n        gap_width = params['gap_width']\n        gap_center = G // 2\n\n        # Building 1 (left of gap)\n        w1 = random.randint(*params['width_range'])\n        d1 = random.randint(G//2, G-2)\n        h1 = random.randint(*params['height_range'])\n        x1_end = gap_center - gap_width // 2\n        x1_start = max(0, x1_end - w1)\n        state[:, ch, :h1, :d1, x1_start:x1_end] = 1.0\n        buildings.append({\n            'x': (x1_start, x1_end), \n            'y': (0, d1), \n            'z': (0, h1),\n            'gap_facing_x': x1_end  # Facade facing the gap\n        })\n\n        # Building 2 (right of gap)\n        w2 = random.randint(*params['width_range'])\n        d2 = random.randint(G//2, G-2)\n        h2 = h1 if not params['height_variance'] else random.randint(*params['height_range'])\n        x2_start = gap_center + gap_width // 2\n        x2_end = min(G, x2_start + w2)\n        state[:, ch, :h2, :d2, x2_start:x2_end] = 1.0\n        buildings.append({\n            'x': (x2_start, x2_end), \n            'y': (0, d2), \n            'z': (0, h2),\n            'gap_facing_x': x2_start  # Facade facing the gap\n        })\n\n        return buildings\n\n    def _place_access_points(self, state: torch.Tensor, access_type: str,\n                             params: dict, buildings: list) -> list:\n        G = self.G\n        ch = self.config['ch_access']\n        access_points = []\n        \n        n_ground = params.get('n_ground_access', 1)\n        n_elevated = params.get('n_elevated_access', 1)\n        \n        # Compute gap boundaries from buildings\n        gap_x_min = min(b['gap_facing_x'] for b in buildings if b['x'][1] <= G // 2)\n        gap_x_max = max(b['gap_facing_x'] for b in buildings if b['x'][0] >= G // 2)\n        \n        # Ground access points: anywhere in the gap on the ground\n        for i in range(n_ground):\n            # Full randomization across the gap width\n            x = random.randint(gap_x_min, gap_x_max - 2)\n            # Full randomization across Y (depth)\n            y = random.randint(0, G - 3)\n            z = 0\n            \n            state[:, ch, z:z+2, y:y+2, x:x+2] = 1.0\n            access_points.append({'x': x, 'y': y, 'z': z, 'type': 'ground'})\n        \n        # Elevated access points: on building facades FACING THE GAP\n        for i in range(n_elevated):\n            # Choose a random building\n            building = random.choice(buildings)\n            bx_start, bx_end = building['x']\n            by_start, by_end = building['y']\n            bz_max = building['z'][1]\n            gap_facing_x = building['gap_facing_x']\n            \n            # Determine if this is left or right building\n            is_left_building = bx_end <= G // 2\n            \n            # Random height on the facade (not ground level, not rooftop)\n            z = random.randint(2, bz_max - 2)\n            \n            # Random depth along the facade\n            y = random.randint(by_start, by_end - 2)\n            \n            # X position: just outside the facade facing the gap\n            if is_left_building:\n                x = gap_facing_x  # Just outside right edge (facing gap)\n            else:\n                x = gap_facing_x - 1  # Just outside left edge (facing gap)\n            \n            # Clamp to valid range\n            x = max(0, min(G - 2, x))\n            y = max(0, min(G - 2, y))\n            z = max(1, min(G - 2, z))\n            \n            state[:, ch, z:z+2, y:y+2, x:x+2] = 1.0\n            access_points.append({'x': x, 'y': y, 'z': z, 'type': 'elevated'})\n\n        return access_points\n\n    def batch(self, difficulty: str, access_type: str, batch_size: int, device: str) -> torch.Tensor:\n        scenes = [self.generate(difficulty, access_type, device)[0] for _ in range(batch_size)]\n        return torch.cat(scenes, dim=0)\n\n\n# Test scene generator\nprint('Testing scene generator with randomized access points (v1.6)...')\ntest_gen = UrbanSceneGenerator(CONFIG)\ntest_scene, test_meta = test_gen.generate('easy', 'mixed', device)\nprint(f\"  Access points: {len(test_meta['access_points'])}\")\nfor ap in test_meta['access_points']:\n    print(f\"    - {ap['type']}: z={ap['z']}, y={ap['y']}, x={ap['x']}\")\nprint('  ✓ Scene generator working')",
   "metadata": {
    "id": "scene_generator"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Loss Functions"
   ],
   "metadata": {
    "id": "loss_header"
   }
  },
  {
   "cell_type": "code",
   "source": "class ConnectivityLoss(nn.Module):\n    \"\"\"\n    Constraint 1A: No floating voxels.\n\n    All structure voxels must be connected to support (ground + buildings)\n    via a continuous path of solid material.\n\n    Uses differentiable flood-fill via iterative max-pooling.\n    \"\"\"\n\n    def __init__(self, threshold: float = 0.3, iterations: int = 32):\n        super().__init__()\n        self.threshold = threshold\n        self.iterations = iterations\n\n    def forward(self, structure: torch.Tensor, support: torch.Tensor) -> torch.Tensor:\n        struct_soft = torch.sigmoid(10 * (structure - self.threshold))\n        connected = support.clone()\n\n        for _ in range(self.iterations):\n            dilated = F.max_pool3d(\n                connected.unsqueeze(1), kernel_size=3, stride=1, padding=1\n            ).squeeze(1)\n            new_connected = torch.max(connected, dilated * struct_soft)\n            if torch.allclose(connected, new_connected, atol=1e-5):\n                break\n            connected = new_connected\n\n        disconnected = structure * (1.0 - connected)\n        loss = disconnected.sum() / (structure.sum() + 1e-8)\n        return loss\n\n\nclass CantileverLoss(nn.Module):\n    \"\"\"Constraint 1B: Limit horizontal overhangs.\"\"\"\n\n    def __init__(self, max_overhang: int = 3, threshold: float = 0.3):\n        super().__init__()\n        self.max_overhang = max_overhang\n        self.threshold = threshold\n\n    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n        B, D, H, W = structure.shape\n        N = self.max_overhang\n        total_loss = 0.0\n        count = 0\n\n        for z in range(N, D):\n            layer = structure[:, z]\n            support_volume = structure[:, max(0, z-N):z]\n            support_max = support_volume.max(dim=1)[0]\n            support_dilated = F.max_pool2d(\n                support_max.unsqueeze(1), kernel_size=3, stride=1, padding=1\n            ).squeeze(1)\n            has_support = torch.sigmoid(10 * (support_dilated - self.threshold))\n            unsupported = layer * (1.0 - has_support)\n            total_loss += unsupported.mean()\n            count += 1\n\n        return total_loss / max(1, count)\n\n\nclass DiceLoss(nn.Module):\n    \"\"\"Growth incentive via Dice loss.\"\"\"\n\n    def __init__(self, smooth: float = 1.0):\n        super().__init__()\n        self.smooth = smooth\n\n    def forward(self, structure: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n        intersection = (structure * target).sum()\n        dice = (2 * intersection + self.smooth) / (\n            structure.sum() + target.sum() + self.smooth\n        )\n        return 1.0 - dice\n\n\nclass SparsityLoss(nn.Module):\n    \"\"\"\n    Constraint 3A (Baseline): Limit total volume.\n    Prevents trivial \"fill everything\" solution.\n    \"\"\"\n\n    def __init__(self, max_ratio: float = 0.25, min_ratio: float = 0.03):\n        super().__init__()\n        self.max_ratio = max_ratio\n        self.min_ratio = min_ratio\n\n    def forward(self, structure: torch.Tensor, available: torch.Tensor) -> torch.Tensor:\n        ratio = structure.sum() / (available.sum() + 1e-8)\n        over_penalty = F.relu(ratio - self.max_ratio)\n        under_penalty = 0.3 * F.relu(self.min_ratio - ratio)\n        return over_penalty + under_penalty\n\n\nclass ExclusionLoss(nn.Module):\n    \"\"\"\n    Prevent structure from growing inside existing buildings.\n    \n    Structure should NEVER overlap with existing buildings. This is a hard\n    constraint that should always be satisfied.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, structure: torch.Tensor, existing: torch.Tensor) -> torch.Tensor:\n        overlap = (structure * existing).sum()\n        loss = overlap / (structure.sum() + 1e-8)\n        return loss\n\n\n# ============================================================\n# QUALITY LOSSES (NEW v1.5 - from reference implementation)\n# ============================================================\n\nclass DensityPenalty(nn.Module):\n    \"\"\"\n    SIMP-inspired density penalty for binary outputs.\n    \n    Penalizes intermediate values (between 0 and 1), encouraging the NCA\n    to commit to either solid (1) or void (0). This prevents blobby,\n    fuzzy structures.\n    \n    Formula: mean(s * (1 - s))\n    - Maximum at s=0.5 (penalty = 0.25)\n    - Zero at s=0 or s=1\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n        # s * (1-s) is maximum at 0.5, zero at 0 and 1\n        penalty = (structure * (1.0 - structure)).mean()\n        return penalty\n\n\nclass TotalVariation3D(nn.Module):\n    \"\"\"\n    Total Variation loss for smooth 3D surfaces.\n    \n    Penalizes differences between neighboring voxels, encouraging\n    smoother, more coherent surfaces instead of noisy patterns.\n    \n    Computes sum of absolute differences along D, H, W axes.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n        # Structure shape: (B, D, H, W)\n        # Compute differences along each axis\n        tv_d = (structure[:, 1:, :, :] - structure[:, :-1, :, :]).abs().mean()\n        tv_h = (structure[:, :, 1:, :] - structure[:, :, :-1, :]).abs().mean()\n        tv_w = (structure[:, :, :, 1:] - structure[:, :, :, :-1]).abs().mean()\n        return tv_d + tv_h + tv_w\n\n\nclass AccessReachLoss(nn.Module):\n    \"\"\"\n    Constraint 4B (Baseline): Structure and walkable must reach access points.\n    \n    Critical for forcing vertical growth when elevated access points exist.\n    \"\"\"\n\n    def __init__(self, dilation_radius: int = 3):\n        super().__init__()\n        self.dilation_radius = dilation_radius\n\n    def forward(self, structure: torch.Tensor, walkable: torch.Tensor, \n                access: torch.Tensor) -> torch.Tensor:\n        # Dilate access points to create reach zone\n        kernel_size = 2 * self.dilation_radius + 1\n        access_dilated = F.max_pool3d(\n            access.unsqueeze(1), kernel_size=kernel_size, stride=1, \n            padding=self.dilation_radius\n        ).squeeze(1)\n        \n        # Structure should reach access zones\n        struct_reach = (structure * access_dilated).sum() / (access_dilated.sum() + 1e-8)\n        \n        # Walkable should also reach access zones  \n        walk_reach = (walkable * access_dilated).sum() / (access_dilated.sum() + 1e-8)\n        \n        # Combined loss (both need to reach)\n        loss = (1.0 - struct_reach) + 0.5 * (1.0 - walk_reach)\n        return loss\n\n\nclass WalkableCoverageLoss(nn.Module):\n    \"\"\"\n    Constraint 4C (Baseline): Walkable surfaces must develop on structure.\n    \n    Ensures the model creates traversable surfaces, not just structural blobs.\n    \"\"\"\n\n    def __init__(self, min_coverage: float = 0.2):\n        super().__init__()\n        self.min_coverage = min_coverage\n\n    def forward(self, structure: torch.Tensor, walkable: torch.Tensor) -> torch.Tensor:\n        # Coverage = walkable / structure\n        coverage = walkable.sum() / (structure.sum() + 1e-8)\n        \n        # Penalize if coverage is below minimum\n        loss = F.relu(self.min_coverage - coverage)\n        return loss\n\n\nclass WalkableDiceLoss(nn.Module):\n    \"\"\"\n    Direct growth incentive for walkable channel.\n    \n    Encourages walkable to grow where structure exists, especially near access points.\n    This provides positive gradient for walkable growth, not just penalty for absence.\n    \"\"\"\n\n    def __init__(self, smooth: float = 1.0):\n        super().__init__()\n        self.smooth = smooth\n\n    def forward(self, walkable: torch.Tensor, structure: torch.Tensor,\n                target: torch.Tensor) -> torch.Tensor:\n        # Walkable should grow where structure exists AND target is active\n        # target is the dilated access zone\n        walkable_target = structure * target  # Only where structure exists near access\n        \n        intersection = (walkable * walkable_target).sum()\n        dice = (2 * intersection + self.smooth) / (\n            walkable.sum() + walkable_target.sum() + self.smooth\n        )\n        return 1.0 - dice\n\n\n# Test losses\nprint('Testing loss functions...')\n\nscene_gen = UrbanSceneGenerator(CONFIG)\nscene, meta = scene_gen.generate('easy', 'mixed', device)\n\nexisting = scene[:, CONFIG['ch_existing']]\nground = scene[:, CONFIG['ch_ground']]\naccess = scene[:, CONFIG['ch_access']]\nsupport = torch.clamp(ground + existing, 0, 1)\navailable = 1.0 - existing\n\nfake_structure = torch.rand_like(ground) * 0.5\nfake_walkable = torch.rand_like(ground) * 0.3\n\nconn_loss = ConnectivityLoss()\nL_conn = conn_loss(fake_structure, support)\nprint(f'  Connectivity loss: {L_conn.item():.4f}')\n\ncant_loss = CantileverLoss()\nL_cant = cant_loss(fake_structure)\nprint(f'  Cantilever loss: {L_cant.item():.4f}')\n\ndice_loss = DiceLoss()\ntarget = F.max_pool3d(access.unsqueeze(1), 7, 1, 3).squeeze(1)\nL_dice = dice_loss(fake_structure, target)\nprint(f'  Dice loss: {L_dice.item():.4f}')\n\nsparse_loss = SparsityLoss()\nL_sparse = sparse_loss(fake_structure, available)\nprint(f'  Sparsity loss: {L_sparse.item():.4f}')\n\nexcl_loss = ExclusionLoss()\nL_excl = excl_loss(fake_structure, existing)\nprint(f'  Exclusion loss: {L_excl.item():.4f}')\n\n# NEW v1.5: Quality losses\ndensity_loss = DensityPenalty()\nL_density = density_loss(fake_structure)\nprint(f'  Density penalty: {L_density.item():.4f}')\n\ntv_loss = TotalVariation3D()\nL_tv = tv_loss(fake_structure)\nprint(f'  Total variation: {L_tv.item():.4f}')\n\nreach_loss = AccessReachLoss()\nL_reach = reach_loss(fake_structure, fake_walkable, access)\nprint(f'  Access reach loss: {L_reach.item():.4f}')\n\nwalk_cov_loss = WalkableCoverageLoss()\nL_walk_cov = walk_cov_loss(fake_structure, fake_walkable)\nprint(f'  Walkable coverage loss: {L_walk_cov.item():.4f}')\n\nwalk_dice_loss = WalkableDiceLoss()\nL_walk_dice = walk_dice_loss(fake_walkable, fake_structure, target)\nprint(f'  Walkable dice loss: {L_walk_dice.item():.4f}')\n\nprint('  ✓ All losses working')\nprint(f'\\nAccess points in test scene:')\nfor ap in meta['access_points']:\n    print(f\"  - {ap['type']}: z={ap['z']}\")",
   "metadata": {
    "id": "losses"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Phase 1 Training Loop"
   ],
   "metadata": {
    "id": "training_header"
   }
  },
  {
   "cell_type": "code",
   "source": "class Phase1Trainer:\n    \"\"\"\n    Phase 1 Trainer: Core Constraints (v1.5)\n\n    Constraints:\n        - C1A: Connectivity (no floating voxels)\n        - C1B: Cantilever (limit overhangs)\n        - C3A: Sparsity (prevent fill-everything)\n        - C4B: Access Reach (structure/walkable must reach access points)\n        - C4C: Walkable Coverage (walkable must develop on structure)\n        - Exclusion: No structure inside existing buildings\n        - Dice: Growth incentive for structure\n        - Walkable Dice: Growth incentive for walkable\n        \n    Quality Losses (NEW v1.5):\n        - DensityPenalty: Encourage binary (0 or 1) outputs\n        - TotalVariation: Smooth surfaces\n        - Ramp-up: Quality losses start after epoch 100, increase gradually\n    \"\"\"\n\n    def __init__(self, model: nn.Module, config: dict, device: str):\n        self.model = model\n        self.config = config\n        self.device = device\n\n        # Loss functions\n        self.dice_loss = DiceLoss()\n        self.walk_dice_loss = WalkableDiceLoss()\n        self.conn_loss = ConnectivityLoss()\n        self.cant_loss = CantileverLoss()\n        self.sparse_loss = SparsityLoss(max_ratio=0.25, min_ratio=0.03)\n        self.excl_loss = ExclusionLoss()\n        self.reach_loss = AccessReachLoss(dilation_radius=3)\n        self.walk_cov_loss = WalkableCoverageLoss(min_coverage=0.2)\n        \n        # NEW v1.5: Quality losses\n        self.density_loss = DensityPenalty()\n        self.tv_loss = TotalVariation3D()\n\n        # Loss weights (base weights)\n        self.weights = {\n            'dice': 10.0,\n            'walk_dice': 8.0,\n            'connectivity': 10.0,\n            'cantilever': 5.0,\n            'sparsity': 20.0,\n            'exclusion': 50.0,\n            'access_reach': 10.0,\n            'walkable_cov': 5.0,\n            # NEW v1.5: Quality weights (will be ramped up)\n            'density': 15.0,  # Encourage binary outputs\n            'tv': 2.0,        # Smooth surfaces (lower weight - don't over-smooth)\n        }\n        \n        # NEW v1.5: Quality loss ramp-up schedule\n        self.quality_start_epoch = 100   # Start quality losses after this epoch\n        self.quality_ramp_epochs = 100   # Ramp up over this many epochs\n\n        # Optimizer\n        self.optimizer = torch.optim.Adam(\n            model.parameters(),\n            lr=config['lr_initial']\n        )\n\n        # Scene generator\n        self.scene_gen = UrbanSceneGenerator(config)\n\n        # History\n        self.history = []\n\n    def _get_quality_weight(self, epoch: int) -> float:\n        \"\"\"\n        Compute quality loss weight multiplier based on epoch.\n        \n        Ramp-up schedule:\n        - Before quality_start_epoch: 0.0\n        - During ramp: linear from 0.0 to 1.0\n        - After ramp: 1.0\n        \"\"\"\n        if epoch < self.quality_start_epoch:\n            return 0.0\n        elif epoch < self.quality_start_epoch + self.quality_ramp_epochs:\n            progress = (epoch - self.quality_start_epoch) / self.quality_ramp_epochs\n            return progress\n        else:\n            return 1.0\n\n    def train_epoch(self, epoch: int) -> dict:\n        \"\"\"Train for one epoch.\"\"\"\n        self.model.train()\n        cfg = self.config\n\n        # Generate batch of scenes (with elevated access points)\n        seeds = self.scene_gen.batch(\n            cfg['difficulty'], cfg['access_type'],\n            cfg['batch_size'], self.device\n        )\n\n        # Random number of steps\n        steps = random.randint(cfg['steps_min'], cfg['steps_max'])\n\n        # Forward pass\n        final = self.model(seeds, steps=steps)\n\n        # Extract channels\n        existing = final[:, cfg['ch_existing']]\n        ground = final[:, cfg['ch_ground']]\n        access = final[:, cfg['ch_access']]\n        structure = final[:, cfg['ch_structure']]\n        walkable = final[:, cfg['ch_walkable']]\n\n        support = torch.clamp(ground + existing, 0, 1)\n        available = 1.0 - existing\n        \n        # Target for Dice: dilated access, but EXCLUDE existing buildings\n        target_raw = F.max_pool3d(access.unsqueeze(1), 7, 1, 3).squeeze(1)\n        target = target_raw * available  # Don't incentivize growth inside buildings\n\n        # Compute core losses\n        L_dice = self.dice_loss(structure, target)\n        L_walk_dice = self.walk_dice_loss(walkable, structure, target)\n        L_conn = self.conn_loss(structure, support)\n        L_cant = self.cant_loss(structure)\n        L_sparse = self.sparse_loss(structure, available)\n        L_excl = self.excl_loss(structure, existing)\n        L_reach = self.reach_loss(structure, walkable, access)\n        L_walk_cov = self.walk_cov_loss(structure, walkable)\n        \n        # NEW v1.5: Compute quality losses\n        L_density = self.density_loss(structure)\n        L_tv = self.tv_loss(structure)\n        \n        # Get quality weight multiplier for this epoch\n        quality_mult = self._get_quality_weight(epoch)\n\n        # Total loss (with ramped quality losses)\n        total_loss = (\n            self.weights['dice'] * L_dice +\n            self.weights['walk_dice'] * L_walk_dice +\n            self.weights['connectivity'] * L_conn +\n            self.weights['cantilever'] * L_cant +\n            self.weights['sparsity'] * L_sparse +\n            self.weights['exclusion'] * L_excl +\n            self.weights['access_reach'] * L_reach +\n            self.weights['walkable_cov'] * L_walk_cov +\n            # Quality losses with ramp-up\n            quality_mult * self.weights['density'] * L_density +\n            quality_mult * self.weights['tv'] * L_tv\n        )\n\n        # Backward pass\n        self.optimizer.zero_grad()\n        total_loss.backward()\n        torch.nn.utils.clip_grad_norm_(self.model.parameters(), cfg['grad_clip'])\n        self.optimizer.step()\n\n        # Compute metrics for monitoring\n        fill_ratio = structure.sum() / (available.sum() + 1e-8)\n        walk_coverage = walkable.sum() / (structure.sum() + 1e-8)\n        \n        # Track overlap with existing buildings\n        overlap_ratio = (structure * existing).sum() / (structure.sum() + 1e-8)\n\n        # Record metrics\n        metrics = {\n            'epoch': epoch,\n            'total_loss': total_loss.item(),\n            'dice': L_dice.item(),\n            'walk_dice': L_walk_dice.item(),\n            'connectivity': L_conn.item(),\n            'cantilever': L_cant.item(),\n            'sparsity': L_sparse.item(),\n            'exclusion': L_excl.item(),\n            'access_reach': L_reach.item(),\n            'walkable_cov': L_walk_cov.item(),\n            # NEW v1.5: Quality metrics\n            'density': L_density.item(),\n            'tv': L_tv.item(),\n            'quality_mult': quality_mult,\n            # Other metrics\n            'fill_ratio': fill_ratio.item(),\n            'walk_coverage': walk_coverage.item(),\n            'overlap_ratio': overlap_ratio.item(),\n            'steps': steps,\n            'structure_mean': structure.mean().item(),\n            'walkable_mean': walkable.mean().item(),\n        }\n\n        self.history.append(metrics)\n        return metrics\n\n    def evaluate(self, n_samples: int = 20) -> dict:\n        \"\"\"Evaluate model on test scenes.\"\"\"\n        self.model.eval()\n        cfg = self.config\n\n        results = []\n        with torch.no_grad():\n            for _ in range(n_samples):\n                scene, meta = self.scene_gen.generate(\n                    cfg['difficulty'], cfg['access_type'], self.device\n                )\n\n                # Grow structure\n                grown = self.model.grow(scene, steps=50)\n\n                # Extract channels\n                existing = grown[:, cfg['ch_existing']]\n                ground = grown[:, cfg['ch_ground']]\n                access = grown[:, cfg['ch_access']]\n                structure = grown[:, cfg['ch_structure']]\n                walkable = grown[:, cfg['ch_walkable']]\n                support = torch.clamp(ground + existing, 0, 1)\n                available = 1.0 - existing\n\n                # Compute connectivity rate\n                struct_binary = (structure > 0.5).float()\n                connected = support.clone()\n                for _ in range(32):\n                    dilated = F.max_pool3d(connected.unsqueeze(1), 3, 1, 1).squeeze(1)\n                    connected = torch.max(connected, dilated * struct_binary)\n\n                total_struct = struct_binary.sum().item()\n                connected_struct = (connected * struct_binary).sum().item()\n                conn_rate = connected_struct / (total_struct + 1e-8)\n\n                # Check cantilever compliance\n                cant_ok = self._check_cantilever(struct_binary)\n\n                # Compute fill ratio\n                fill_ratio = struct_binary.sum().item() / (available.sum().item() + 1e-8)\n\n                # Compute access reach\n                access_dilated = F.max_pool3d(access.unsqueeze(1), 7, 1, 3).squeeze(1)\n                struct_reach = ((structure > 0.5).float() * access_dilated).sum().item()\n                access_reach = struct_reach / (access_dilated.sum().item() + 1e-8)\n\n                # Compute walkable coverage\n                walk_coverage = walkable.sum().item() / (total_struct + 1e-8)\n\n                # Compute overlap with existing buildings\n                overlap = (struct_binary * existing).sum().item()\n                overlap_ratio = overlap / (total_struct + 1e-8)\n                \n                # NEW v1.5: Compute density penalty (for evaluation)\n                density_penalty = (structure * (1.0 - structure)).mean().item()\n\n                # Check if elevated access was reached\n                elevated_reached = False\n                for ap in meta['access_points']:\n                    if ap['type'] == 'elevated':\n                        z, y, x = ap['z'], ap['y'], ap['x']\n                        region = structure[0, max(0,z-2):z+3, max(0,y-2):y+3, max(0,x-2):x+3]\n                        if region.max() > 0.5:\n                            elevated_reached = True\n                            break\n\n                results.append({\n                    'connectivity_rate': conn_rate,\n                    'cantilever_ok': cant_ok,\n                    'voxel_count': total_struct,\n                    'fill_ratio': fill_ratio,\n                    'access_reach': access_reach,\n                    'walkable_coverage': walk_coverage,\n                    'overlap_ratio': overlap_ratio,\n                    'density_penalty': density_penalty,\n                    'elevated_reached': elevated_reached,\n                })\n\n        # Aggregate results\n        return {\n            'connectivity_rate': np.mean([r['connectivity_rate'] for r in results]),\n            'cantilever_compliance': np.mean([r['cantilever_ok'] for r in results]),\n            'avg_voxels': np.mean([r['voxel_count'] for r in results]),\n            'avg_fill_ratio': np.mean([r['fill_ratio'] for r in results]),\n            'avg_access_reach': np.mean([r['access_reach'] for r in results]),\n            'avg_walkable_coverage': np.mean([r['walkable_coverage'] for r in results]),\n            'avg_overlap_ratio': np.mean([r['overlap_ratio'] for r in results]),\n            'avg_density_penalty': np.mean([r['density_penalty'] for r in results]),\n            'elevated_reach_rate': np.mean([r['elevated_reached'] for r in results]),\n            'n_samples': n_samples,\n        }\n\n    def _check_cantilever(self, structure: torch.Tensor, max_overhang: int = 3) -> float:\n        \"\"\"Check cantilever compliance (hard threshold).\"\"\"\n        B, D, H, W = structure.shape\n        violations = 0\n        total = 0\n\n        for z in range(max_overhang, D):\n            layer = structure[:, z]\n            support_max = structure[:, max(0, z-max_overhang):z].max(dim=1)[0]\n            support_dilated = F.max_pool2d(support_max.unsqueeze(1), 3, 1, 1).squeeze(1)\n\n            unsupported = layer * (1 - (support_dilated > 0.5).float())\n            violations += unsupported.sum().item()\n            total += layer.sum().item()\n\n        compliance = 1.0 - (violations / (total + 1e-8))\n        return compliance\n\n    def save_checkpoint(self, path: str):\n        \"\"\"Save model checkpoint.\"\"\"\n        torch.save({\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'config': self.config,\n            'history': self.history,\n        }, path)\n        print(f'Checkpoint saved to {path}')",
   "metadata": {
    "id": "trainer"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Visualization Utilities"
   ],
   "metadata": {
    "id": "viz_header"
   }
  },
  {
   "cell_type": "code",
   "source": "def visualize_result(model: nn.Module, scene_gen: UrbanSceneGenerator,\n                     config: dict, device: str, title: str = 'Result'):\n    \"\"\"Visualize a grown structure with walkable surfaces.\n    \n    Axis labels reflect tensor dimensions after transpose(1,2,0):\n    - Tensor [Z, Y, X] -> Plot axes [Y, X, Z]\n    - Y = depth (into scene), X = left-right, Z = height\n    \"\"\"\n    model.eval()\n\n    scene, meta = scene_gen.generate(config['difficulty'], config['access_type'], device)\n\n    with torch.no_grad():\n        grown = model.grow(scene, steps=50)\n\n    # Extract for visualization\n    state = grown[0].cpu().numpy()\n    existing = state[config['ch_existing']] > 0.5\n    structure = state[config['ch_structure']] > 0.5\n    walkable = state[config['ch_walkable']] > 0.3\n    access = state[config['ch_access']] > 0.5\n    \n    # Check for overlap (structure inside existing buildings)\n    overlap = structure & existing\n\n    fig = plt.figure(figsize=(20, 5))\n\n    # 3D view - transpose(1,2,0) maps [Z,Y,X] -> [Y,X,Z]\n    ax1 = fig.add_subplot(141, projection='3d')\n    if existing.any():\n        ax1.voxels(existing.transpose(1, 2, 0), facecolors='gray', alpha=0.3)\n    if access.any():\n        ax1.voxels(access.transpose(1, 2, 0), facecolors='green', alpha=0.9)\n    if overlap.any():\n        # Show overlap in RED (this is a problem!)\n        ax1.voxels(overlap.transpose(1, 2, 0), facecolors='red', alpha=0.9)\n    if structure.any():\n        # Show structure that's NOT overlapping\n        struct_clean = structure & ~existing\n        if struct_clean.any():\n            ax1.voxels(struct_clean.transpose(1, 2, 0), facecolors='royalblue', alpha=0.6)\n    if walkable.any():\n        walk_only = walkable & ~existing & ~structure\n        if walk_only.any():\n            ax1.voxels(walk_only.transpose(1, 2, 0), facecolors='yellow', alpha=0.4)\n    ax1.set_title(f'{title} (3D)')\n    # Correct axis labels: tensor [Z,Y,X].transpose(1,2,0) -> plot [Y,X,Z]\n    ax1.set_xlabel('Y (depth)')\n    ax1.set_ylabel('X (left-right)')\n    ax1.set_zlabel('Z (height)')\n\n    # Plan view (top-down) - max over Z axis\n    ax2 = fig.add_subplot(142)\n    G = state.shape[1]\n    plan = np.zeros((G, G, 3))\n    plan[existing.max(axis=0)] = [0.5, 0.5, 0.5]  # Gray for existing\n    struct_clean = structure & ~existing\n    plan[struct_clean.max(axis=0)] = [0.2, 0.4, 0.8]  # Blue for clean structure\n    plan[overlap.max(axis=0)] = [1.0, 0.0, 0.0]  # RED for overlap (bad!)\n    plan[walkable.max(axis=0) & ~existing.max(axis=0)] = [0.8, 0.8, 0.2]  # Yellow for walkable\n    plan[access.max(axis=0)] = [0.2, 0.8, 0.2]  # Green for access\n    ax2.imshow(plan.transpose(1, 0, 2), origin='lower')\n    ax2.set_title(f'{title} (Plan View)')\n    ax2.set_xlabel('Y (depth)')\n    ax2.set_ylabel('X (left-right)')\n\n    # Side view (elevation) - max over Y axis\n    ax3 = fig.add_subplot(143)\n    elev = np.zeros((G, G, 3))\n    elev[existing.max(axis=1)] = [0.5, 0.5, 0.5]\n    elev[struct_clean.max(axis=1)] = [0.2, 0.4, 0.8]\n    elev[overlap.max(axis=1)] = [1.0, 0.0, 0.0]  # RED for overlap\n    elev[walkable.max(axis=1) & ~existing.max(axis=1)] = [0.8, 0.8, 0.2]\n    elev[access.max(axis=1)] = [0.2, 0.8, 0.2]\n    ax3.imshow(elev.transpose(1, 0, 2), origin='lower')\n    ax3.set_title(f'{title} (Elevation)')\n    ax3.set_xlabel('X (left-right)')\n    ax3.set_ylabel('Z (height)')\n\n    # Cross-section at mid-Y\n    ax4 = fig.add_subplot(144)\n    mid_y = G // 2\n    cross = np.zeros((G, G, 3))\n    cross[existing[:, mid_y, :]] = [0.5, 0.5, 0.5]\n    cross[struct_clean[:, mid_y, :]] = [0.2, 0.4, 0.8]\n    cross[overlap[:, mid_y, :]] = [1.0, 0.0, 0.0]\n    cross[walkable[:, mid_y, :] & ~existing[:, mid_y, :]] = [0.8, 0.8, 0.2]\n    cross[access[:, mid_y, :]] = [0.2, 0.8, 0.2]\n    ax4.imshow(cross.transpose(1, 0, 2), origin='lower')\n    ax4.set_title(f'{title} (Cross-section Y={mid_y})')\n    ax4.set_xlabel('X (left-right)')\n    ax4.set_ylabel('Z (height)')\n\n    plt.tight_layout()\n    plt.show()\n\n    # Print stats\n    struct_count = structure.sum()\n    walk_count = walkable.sum()\n    overlap_count = overlap.sum()\n    walk_cov = walk_count / (struct_count + 1e-8)\n    overlap_pct = overlap_count / (struct_count + 1e-8) * 100\n    \n    # Compute density penalty for this result\n    structure_soft = state[config['ch_structure']]\n    density_penalty = (structure_soft * (1.0 - structure_soft)).mean()\n    \n    print(f\"  Structure: {struct_count:.0f} voxels, Walkable: {walk_count:.0f}, Coverage: {walk_cov:.1%}\")\n    print(f\"  Density penalty: {density_penalty:.4f} (lower = more binary)\")\n    if overlap_count > 0:\n        print(f\"  WARNING: OVERLAP: {overlap_count:.0f} voxels ({overlap_pct:.1f}%) inside buildings!\")\n    else:\n        print(f\"  No overlap with existing buildings\")\n    print(f\"  Access points: {len(meta['access_points'])}\")\n    for ap in meta['access_points']:\n        print(f\"    - {ap['type']}: z={ap['z']}, y={ap['y']}, x={ap['x']}\")\n\n    return grown, meta\n\n\ndef plot_training_curves(history: list):\n    \"\"\"Plot training loss curves including quality metrics.\"\"\"\n    epochs = [h['epoch'] for h in history]\n\n    fig, axes = plt.subplots(2, 6, figsize=(26, 8))\n\n    # Total loss\n    axes[0, 0].plot(epochs, [h['total_loss'] for h in history])\n    axes[0, 0].set_title('Total Loss')\n    axes[0, 0].set_xlabel('Epoch')\n    axes[0, 0].set_yscale('log')\n\n    # Structural losses\n    axes[0, 1].plot(epochs, [h['dice'] for h in history], label='Dice (struct)')\n    axes[0, 1].plot(epochs, [h.get('walk_dice', 0) for h in history], label='Dice (walk)')\n    axes[0, 1].plot(epochs, [h['connectivity'] for h in history], label='Connectivity')\n    axes[0, 1].plot(epochs, [h['cantilever'] for h in history], label='Cantilever')\n    axes[0, 1].set_title('Core Losses')\n    axes[0, 1].legend()\n    axes[0, 1].set_xlabel('Epoch')\n\n    # Sparsity loss\n    axes[0, 2].plot(epochs, [h['sparsity'] for h in history], color='purple')\n    axes[0, 2].set_title('Sparsity Loss')\n    axes[0, 2].set_xlabel('Epoch')\n\n    # Exclusion loss\n    axes[0, 3].plot(epochs, [h.get('exclusion', 0) for h in history], color='red')\n    axes[0, 3].set_title('Exclusion Loss')\n    axes[0, 3].set_xlabel('Epoch')\n\n    # Density penalty\n    axes[0, 4].plot(epochs, [h.get('density', 0) for h in history], color='magenta')\n    axes[0, 4].axhline(y=0.25, color='r', linestyle='--', alpha=0.5, label='Max (all 0.5)')\n    axes[0, 4].set_title('Density Penalty (lower=binary)')\n    axes[0, 4].set_xlabel('Epoch')\n    axes[0, 4].legend()\n\n    # Total Variation\n    axes[0, 5].plot(epochs, [h.get('tv', 0) for h in history], color='cyan')\n    axes[0, 5].set_title('Total Variation')\n    axes[0, 5].set_xlabel('Epoch')\n\n    # Fill ratio\n    axes[1, 0].plot(epochs, [h['fill_ratio'] for h in history], color='orange')\n    axes[1, 0].axhline(y=0.25, color='r', linestyle='--', label='Max (25%)')\n    axes[1, 0].axhline(y=0.03, color='g', linestyle='--', label='Min (3%)')\n    axes[1, 0].set_title('Fill Ratio')\n    axes[1, 0].legend()\n    axes[1, 0].set_xlabel('Epoch')\n    axes[1, 0].set_ylim(0, 0.5)\n\n    # Walkable coverage\n    axes[1, 1].plot(epochs, [h['walk_coverage'] for h in history], color='gold')\n    axes[1, 1].axhline(y=0.2, color='g', linestyle='--', label='Min (20%)')\n    axes[1, 1].set_title('Walkable Coverage')\n    axes[1, 1].legend()\n    axes[1, 1].set_xlabel('Epoch')\n    axes[1, 1].set_ylim(0, 1.5)\n\n    # Overlap ratio\n    axes[1, 2].plot(epochs, [h.get('overlap_ratio', 0) for h in history], color='red')\n    axes[1, 2].axhline(y=0.0, color='g', linestyle='--', label='Target (0%)')\n    axes[1, 2].set_title('Overlap Ratio (should be 0!)')\n    axes[1, 2].legend()\n    axes[1, 2].set_xlabel('Epoch')\n\n    # Structure and walkable means\n    axes[1, 3].plot(epochs, [h['structure_mean'] for h in history], label='Structure')\n    axes[1, 3].plot(epochs, [h['walkable_mean'] for h in history], label='Walkable')\n    axes[1, 3].set_title('Channel Means')\n    axes[1, 3].legend()\n    axes[1, 3].set_xlabel('Epoch')\n\n    # Access reach loss\n    axes[1, 4].plot(epochs, [h['access_reach'] for h in history], color='orange')\n    axes[1, 4].set_title('Access Reach Loss')\n    axes[1, 4].set_xlabel('Epoch')\n\n    # Quality weight multiplier\n    axes[1, 5].plot(epochs, [h.get('quality_mult', 0) for h in history], color='green')\n    axes[1, 5].set_title('Quality Weight Ramp')\n    axes[1, 5].set_xlabel('Epoch')\n    axes[1, 5].set_ylim(-0.1, 1.1)\n\n    plt.tight_layout()\n    plt.show()",
   "metadata": {
    "id": "visualization"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Training"
   ],
   "metadata": {
    "id": "train_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize model and trainer\n",
    "model = UrbanPavilionNCA(CONFIG).to(device)\n",
    "trainer = Phase1Trainer(model, CONFIG, device)\n",
    "\n",
    "print(f'Model parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
    "print(f'Training for {CONFIG[\"epochs\"]} epochs')\n",
    "print(f'Difficulty: {CONFIG[\"difficulty\"]}')"
   ],
   "metadata": {
    "id": "init_training"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Visualize before training\n",
    "print('Before training:')\n",
    "visualize_result(model, trainer.scene_gen, CONFIG, device, 'Before Training')"
   ],
   "metadata": {
    "id": "before_training"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Training loop\nprint('\\nStarting Phase 1 Training (Core Constraints v1.5)...')\nprint('='*70)\nprint('Constraints: C1A (Connectivity), C1B (Cantilever), C3A (Sparsity),')\nprint('             C4B (Access Reach), C4C (Walkable Coverage)')\nprint('             Exclusion (no structure inside buildings)')\nprint('NEW v1.5:    DensityPenalty (binary outputs), TotalVariation (smooth)')\nprint('='*70)\nprint(f\"Walkable bias: {CONFIG['walkable_bias']}\")\nprint(f\"Quality losses: start epoch {trainer.quality_start_epoch}, ramp over {trainer.quality_ramp_epochs} epochs\")\nprint('='*70)\n\nfor epoch in tqdm(range(CONFIG['epochs']), desc='Training'):\n    metrics = trainer.train_epoch(epoch)\n\n    # Log progress\n    if epoch % CONFIG['log_every'] == 0:\n        overlap_pct = metrics['overlap_ratio'] * 100\n        overlap_str = f\"Ovlp: {overlap_pct:.1f}%\" if overlap_pct > 0.1 else \"Ovlp: OK\"\n        quality_str = f\"Dens: {metrics['density']:.3f}\" if metrics['quality_mult'] > 0 else \"Qual: OFF\"\n        tqdm.write(\n            f\"Epoch {epoch:4d} | Loss: {metrics['total_loss']:.3f} | \"\n            f\"Fill: {metrics['fill_ratio']:.1%} | Walk: {metrics['walk_coverage']:.1%} | \"\n            f\"{overlap_str} | {quality_str}\"\n        )\n\n    # Visualize progress\n    if epoch > 0 and epoch % CONFIG['viz_every'] == 0:\n        visualize_result(model, trainer.scene_gen, CONFIG, device, f'Epoch {epoch}')\n\n    # Save checkpoint\n    if epoch > 0 and epoch % CONFIG['save_every'] == 0:\n        trainer.save_checkpoint(f'{PROJECT_ROOT}/checkpoints/phase1_epoch{epoch}.pth')\n\nprint('='*70)\nprint('Training complete!')",
   "metadata": {
    "id": "training_loop"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Evaluation"
   ],
   "metadata": {
    "id": "eval_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot training curves\n",
    "plot_training_curves(trainer.history)"
   ],
   "metadata": {
    "id": "plot_curves"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Evaluate on test scenes\nprint('Evaluating on test scenes...')\neval_results = trainer.evaluate(n_samples=50)\n\nprint('\\n' + '='*70)\nprint('PHASE 1 EVALUATION RESULTS (v1.5)')\nprint('='*70)\nprint(f\"Connectivity Rate:     {eval_results['connectivity_rate']*100:.1f}% (target: >95%)\")\nprint(f\"Cantilever Compliance: {eval_results['cantilever_compliance']*100:.1f}% (target: >90%)\")\nprint(f\"Fill Ratio:            {eval_results['avg_fill_ratio']*100:.1f}% (target: 3-25%)\")\nprint(f\"Access Reach:          {eval_results['avg_access_reach']*100:.1f}% (target: >80%)\")\nprint(f\"Walkable Coverage:     {eval_results['avg_walkable_coverage']*100:.1f}% (target: >20%)\")\nprint(f\"Overlap Ratio:         {eval_results['avg_overlap_ratio']*100:.1f}% (target: 0%)\")\nprint(f\"Density Penalty:       {eval_results['avg_density_penalty']:.4f} (target: <0.1 = binary)\")\nprint(f\"Elevated Reach Rate:   {eval_results['elevated_reach_rate']*100:.1f}% (target: >70%)\")\nprint(f\"Average Voxel Count:   {eval_results['avg_voxels']:.0f}\")\nprint('='*70)\n\n# Check success criteria\nconn_pass = eval_results['connectivity_rate'] > 0.95\ncant_pass = eval_results['cantilever_compliance'] > 0.90\nfill_pass = 0.03 < eval_results['avg_fill_ratio'] < 0.25\nreach_pass = eval_results['avg_access_reach'] > 0.80\nwalk_pass = eval_results['avg_walkable_coverage'] > 0.20\noverlap_pass = eval_results['avg_overlap_ratio'] < 0.01\ndensity_pass = eval_results['avg_density_penalty'] < 0.1  # Binary-ish outputs\nelev_pass = eval_results['elevated_reach_rate'] > 0.70\n\nprint(f\"\\nConnectivity:    {'PASS' if conn_pass else 'FAIL'}\")\nprint(f\"Cantilever:      {'PASS' if cant_pass else 'FAIL'}\")\nprint(f\"Fill Ratio:      {'PASS' if fill_pass else 'FAIL'}\")\nprint(f\"Access Reach:    {'PASS' if reach_pass else 'FAIL'}\")\nprint(f\"Walkable Cov:    {'PASS' if walk_pass else 'FAIL'}\")\nprint(f\"No Overlap:      {'PASS' if overlap_pass else 'FAIL'}\")\nprint(f\"Binary Output:   {'PASS' if density_pass else 'FAIL'}\")\nprint(f\"Elevated Reach:  {'PASS' if elev_pass else 'FAIL'}\")\n\nall_pass = conn_pass and cant_pass and fill_pass and reach_pass and walk_pass and overlap_pass and elev_pass\nif all_pass:\n    print('\\nPhase 1 SUCCESS - Ready for Phase 2')\nelse:\n    print('\\nPhase 1 needs more training')",
   "metadata": {
    "id": "evaluation"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Visualize final results\n",
    "print('\\nFinal Results:')\n",
    "for i in range(3):\n",
    "    visualize_result(model, trainer.scene_gen, CONFIG, device, f'Final Result {i+1}')"
   ],
   "metadata": {
    "id": "final_viz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Save Outputs"
   ],
   "metadata": {
    "id": "save_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Save final checkpoint\n",
    "trainer.save_checkpoint(f'{PROJECT_ROOT}/checkpoints/phase1_structural.pth')\n",
    "\n",
    "# Save training history\n",
    "history_path = f'{PROJECT_ROOT}/logs/phase1_history.json'\n",
    "with open(history_path, 'w') as f:\n",
    "    json.dump(trainer.history, f)\n",
    "print(f'History saved to {history_path}')\n",
    "\n",
    "# Save evaluation results\n",
    "eval_path = f'{PROJECT_ROOT}/logs/phase1_eval.json'\n",
    "with open(eval_path, 'w') as f:\n",
    "    json.dump(eval_results, f, indent=2)\n",
    "print(f'Evaluation saved to {eval_path}')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('PHASE 1 COMPLETE')\n",
    "print('='*60)\n",
    "print(f\"\\nCheckpoint: {PROJECT_ROOT}/checkpoints/phase1_structural.pth\")\n",
    "print('\\nNext: NB03_Phase2_Openness')"
   ],
   "metadata": {
    "id": "save_outputs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Summary\n\n### What was implemented:\n\n1. **ConnectivityLoss (C1A)**: Differentiable flood-fill to ensure all voxels connect to support\n2. **CantileverLoss (C1B)**: Penalizes unsupported horizontal overhangs\n3. **SparsityLoss (C3A)**: Prevents \"fill everything\" solution by limiting fill ratio to 3-25%\n4. **ExclusionLoss**: Prevents structure from growing inside existing buildings\n5. **AccessReachLoss (C4B)**: Ensures structure and walkable reach all access points\n6. **WalkableCoverageLoss (C4C)**: Ensures walkable surfaces develop on structure\n7. **DiceLoss**: Growth incentive for structure toward access points\n8. **WalkableDiceLoss**: Growth incentive for walkable toward access zones\n9. **UrbanSceneGenerator**: Updated to include elevated access points (roof/facade)\n10. **Phase1Trainer**: Complete training loop with all core constraints\n\n### Key Additions (v1.5):\n\n**Problem:** Structure was a solid blob despite passing fill ratio checks.\n\n**Root Cause:** No incentive for binary (0 or 1) outputs. Voxels with values like 0.4-0.6 \ncreate fuzzy, blobby structures that technically satisfy constraints but look terrible.\n\n**Fixes:**\n1. **DensityPenalty (SIMP)**: `s * (1 - s)` penalizes values near 0.5, encourages 0 or 1\n2. **TotalVariation3D**: Penalizes differences between neighbors for smooth surfaces\n3. **Quality ramp-up**: Quality losses start at epoch 100, ramp up over 100 epochs\n   - First 100 epochs: Learn basic growth and constraints\n   - Epochs 100-200: Gradually introduce quality requirements\n   - After 200: Full quality enforcement\n\n### Quality Loss Weights:\n- **Density**: 15.0 (strong push toward binary)\n- **TV**: 2.0 (mild smoothness - don't over-smooth)\n\n### Expected Results:\n\n- Density penalty should drop below 0.1 (binary-ish outputs)\n- Structure should have cleaner edges, less fuzzy blob appearance\n- Fill ratio still 3-25%, but with more architectural character\n\n### Visualization Colors:\n- **Gray**: Existing buildings (frozen)\n- **Blue**: Generated structure (clean)\n- **RED**: Overlap - structure inside buildings (BAD!)\n- **Yellow**: Walkable surfaces\n- **Green**: Access points\n\n### Next steps (NB03):\n\n1. Load Phase 1 checkpoint\n2. Implement GroundVoidLoss (C2A)\n3. Add curriculum annealing for smooth constraint activation\n4. Train Phase 2: Street-Level Openness\n\n---\n\n*NB02_Phase1_Structural_v1.5 - December 2025*",
   "metadata": {
    "id": "summary"
   }
  }
 ]
}