{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# NB02: All Constraints Training v6.0\n",
    "\n",
    "**Constraint-Based Architectural NCA - Step B v6.0**\n",
    "\n",
    "**Version:** 6.0 (Clean)\n",
    "**Date:** December 2025\n",
    "**Purpose:** Clean implementation with only working components\n",
    "\n",
    "---\n",
    "\n",
    "## What This Version Does\n",
    "\n",
    "v6.0 is a **clean restart** removing all experimental porosity losses that don't work.\n",
    "\n",
    "### Removed (Useless)\n",
    "- CorridorPorosityLoss\n",
    "- LocalPorosityLoss\n",
    "- InteriorVoidLoss\n",
    "- CorridorBlobPenalty\n",
    "- MultiScaleLocalPorosityLoss\n",
    "- LowZFarFromBuildingSuppressionLoss\n",
    "\n",
    "### Kept (Working)\n",
    "- LocalLegalityLoss\n",
    "- CorridorCoverageLoss (A: fill corridor)\n",
    "- CorridorSpillLoss (B: stay in corridor)\n",
    "- GroundOpennessLoss\n",
    "- ThicknessLoss\n",
    "- SparsityLoss\n",
    "- FacadeContactLoss\n",
    "- AccessConnectivityLoss\n",
    "- LoadPathLoss\n",
    "- CantileverLoss\n",
    "- DensityPenalty\n",
    "- TotalVariation3D\n",
    "\n",
    "### Config Reset\n",
    "- corridor_width: 4 (was 1)\n",
    "- vertical_envelope: 3 (was 1)\n",
    "- Balanced weights\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "PROJECT_ROOT = '/content/drive/MyDrive/Constraint-NCA'\n",
    "print(f'Project root: {PROJECT_ROOT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "from typing import Dict, Tuple, List\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base config\n",
    "with open(f'{PROJECT_ROOT}/config_step_b.json', 'r') as f:\n",
    "    CONFIG = json.load(f)\n",
    "\n",
    "# v6.0 CLEAN configuration\n",
    "CONFIG.update({\n",
    "    'epochs': 500,\n",
    "    'steps_min': 30,\n",
    "    'steps_max': 50,\n",
    "    'difficulty': 'easy',\n",
    "    'log_every': 20,\n",
    "    'viz_every': 100,\n",
    "    'save_every': 100,\n",
    "    # CLEAN CONFIG - sensible defaults\n",
    "    'corridor_width': 4,\n",
    "    'max_thickness': 2,\n",
    "    'max_facade_contact': 0.15,\n",
    "    'vertical_envelope': 3,\n",
    "})\n",
    "\n",
    "print('v6.0 CLEAN Configuration')\n",
    "print(f\"  corridor_width: {CONFIG['corridor_width']}\")\n",
    "print(f\"  max_thickness: {CONFIG['max_thickness']}\")\n",
    "print(f\"  vertical_envelope: {CONFIG['vertical_envelope']}\")\n",
    "print(f\"  epochs: {CONFIG['epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. Core Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceive3D(nn.Module):\n",
    "    \"\"\"3D Sobel perception.\"\"\"\n",
    "\n",
    "    def __init__(self, n_channels: int = 8):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        sobel_x = self._create_sobel_kernel('x')\n",
    "        sobel_y = self._create_sobel_kernel('y')\n",
    "        sobel_z = self._create_sobel_kernel('z')\n",
    "        identity = self._create_identity_kernel()\n",
    "        kernels = torch.stack([identity, sobel_x, sobel_y, sobel_z], dim=0)\n",
    "        self.register_buffer('kernels', kernels)\n",
    "\n",
    "    def _create_sobel_kernel(self, direction: str) -> torch.Tensor:\n",
    "        derivative = torch.tensor([-1., 0., 1.])\n",
    "        smoothing = torch.tensor([1., 2., 1.])\n",
    "        if direction == 'x':\n",
    "            kernel = torch.einsum('i,j,k->ijk', smoothing, smoothing, derivative)\n",
    "        elif direction == 'y':\n",
    "            kernel = torch.einsum('i,j,k->ijk', smoothing, derivative, smoothing)\n",
    "        elif direction == 'z':\n",
    "            kernel = torch.einsum('i,j,k->ijk', derivative, smoothing, smoothing)\n",
    "        return kernel / 16.0\n",
    "\n",
    "    def _create_identity_kernel(self) -> torch.Tensor:\n",
    "        kernel = torch.zeros(3, 3, 3)\n",
    "        kernel[1, 1, 1] = 1.0\n",
    "        return kernel\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, C, D, H, W = x.shape\n",
    "        x_padded = F.pad(x, (1, 1, 1, 1, 1, 1), mode='replicate')\n",
    "        outputs = []\n",
    "        for k in range(4):\n",
    "            kernel = self.kernels[k:k+1].unsqueeze(0).expand(C, 1, 3, 3, 3)\n",
    "            out = F.conv3d(x_padded, kernel, padding=0, groups=C)\n",
    "            outputs.append(out)\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanPavilionNCA(nn.Module):\n",
    "    \"\"\"Neural Cellular Automaton for urban pavilion generation.\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        n_channels = config['n_channels']\n",
    "        hidden_dim = config['hidden_dim']\n",
    "        perception_dim = n_channels * 4\n",
    "        n_grown = config['n_grown']\n",
    "\n",
    "        self.perceive = Perceive3D(n_channels)\n",
    "        self.update_net = nn.Sequential(\n",
    "            nn.Conv3d(perception_dim, hidden_dim, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(hidden_dim, hidden_dim, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(hidden_dim, n_grown, 1),\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        gain = self.config['xavier_gain']\n",
    "        for m in self.update_net:\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=gain)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "        last_layer = self.update_net[-1]\n",
    "        with torch.no_grad():\n",
    "            last_layer.bias[0] = self.config['structure_bias']\n",
    "            last_layer.bias[1] = self.config['surface_bias']\n",
    "\n",
    "    def forward(self, state: torch.Tensor, steps: int = 1) -> torch.Tensor:\n",
    "        for _ in range(steps):\n",
    "            state = self._step(state)\n",
    "        return state\n",
    "\n",
    "    def _step(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        B, C, D, H, W = state.shape\n",
    "        cfg = self.config\n",
    "        perception = self.perceive(state)\n",
    "        delta = self.update_net(perception)\n",
    "\n",
    "        if self.training:\n",
    "            fire_mask = (torch.rand(B, 1, D, H, W, device=state.device) < cfg['fire_rate']).float()\n",
    "            delta = delta * fire_mask\n",
    "\n",
    "        grown_start = cfg['n_frozen']\n",
    "        grown_new = state[:, grown_start:] + cfg['update_scale'] * delta\n",
    "        grown_new = torch.clamp(grown_new, 0.0, 1.0)\n",
    "\n",
    "        existing = state[:, cfg['ch_existing']:cfg['ch_existing']+1]\n",
    "        available_mask = 1.0 - existing\n",
    "        struct_new = grown_new[:, 0:1] * available_mask\n",
    "        grown_masked = torch.cat([struct_new, grown_new[:, 1:]], dim=1)\n",
    "        new_state = torch.cat([state[:, :grown_start], grown_masked], dim=1)\n",
    "        return new_state\n",
    "\n",
    "    def grow(self, seed: torch.Tensor, steps: int = 50) -> torch.Tensor:\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.forward(seed, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanSceneGenerator:\n",
    "    \"\"\"Generate urban scenes.\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        self.config = config\n",
    "        self.G = config['grid_size']\n",
    "        self.C = config['n_channels']\n",
    "\n",
    "    def generate(self, difficulty: str = 'easy', device: str = 'cuda') -> Tuple[torch.Tensor, dict]:\n",
    "        G = self.G\n",
    "        cfg = self.config\n",
    "        state = torch.zeros(1, self.C, G, G, G, device=device)\n",
    "        state[:, cfg['ch_ground'], 0, :, :] = 1.0\n",
    "\n",
    "        params = self._get_difficulty_params(difficulty)\n",
    "        building_info = self._place_buildings(state, params)\n",
    "        access_info = self._place_access_points(state, params, building_info)\n",
    "        anchor_info = self._generate_anchor_zones(state, params, building_info, access_info)\n",
    "\n",
    "        metadata = {\n",
    "            'difficulty': difficulty,\n",
    "            'buildings': building_info,\n",
    "            'access_points': access_info,\n",
    "            'anchor_zones': anchor_info,\n",
    "        }\n",
    "        return state, metadata\n",
    "\n",
    "    def _get_difficulty_params(self, difficulty: str) -> dict:\n",
    "        G = self.G\n",
    "        if difficulty == 'easy':\n",
    "            return {\n",
    "                'n_buildings': 2, 'height_range': (12, 16), 'height_variance': False,\n",
    "                'width_range': (8, 12), 'gap_width': random.randint(14, 18),\n",
    "                'n_ground_access': 1, 'n_elevated_access': 1, 'anchor_budget': 0.10,\n",
    "            }\n",
    "        elif difficulty == 'medium':\n",
    "            return {\n",
    "                'n_buildings': 2, 'height_range': (10, 20), 'height_variance': True,\n",
    "                'width_range': (6, 10), 'gap_width': random.randint(10, 14),\n",
    "                'n_ground_access': random.randint(1, 2), 'n_elevated_access': random.randint(1, 2),\n",
    "                'anchor_budget': 0.07,\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'n_buildings': random.randint(2, 4), 'height_range': (8, 24), 'height_variance': True,\n",
    "                'width_range': (5, 8), 'gap_width': random.randint(6, 10),\n",
    "                'n_ground_access': random.randint(2, 3), 'n_elevated_access': random.randint(2, 3),\n",
    "                'anchor_budget': 0.05,\n",
    "            }\n",
    "\n",
    "    def _place_buildings(self, state: torch.Tensor, params: dict) -> list:\n",
    "        G = self.G\n",
    "        ch = self.config['ch_existing']\n",
    "        buildings = []\n",
    "        gap_width = params['gap_width']\n",
    "        gap_center = G // 2\n",
    "\n",
    "        w1 = random.randint(*params['width_range'])\n",
    "        d1 = random.randint(G//2, G-2)\n",
    "        h1 = random.randint(*params['height_range'])\n",
    "        x1_end = gap_center - gap_width // 2\n",
    "        x1_start = max(0, x1_end - w1)\n",
    "        state[:, ch, :h1, :d1, x1_start:x1_end] = 1.0\n",
    "        buildings.append({'x': (x1_start, x1_end), 'y': (0, d1), 'z': (0, h1),\n",
    "                         'gap_facing_x': x1_end, 'side': 'left'})\n",
    "\n",
    "        w2 = random.randint(*params['width_range'])\n",
    "        d2 = random.randint(G//2, G-2)\n",
    "        h2 = h1 if not params['height_variance'] else random.randint(*params['height_range'])\n",
    "        x2_start = gap_center + gap_width // 2\n",
    "        x2_end = min(G, x2_start + w2)\n",
    "        state[:, ch, :h2, :d2, x2_start:x2_end] = 1.0\n",
    "        buildings.append({'x': (x2_start, x2_end), 'y': (0, d2), 'z': (0, h2),\n",
    "                         'gap_facing_x': x2_start, 'side': 'right'})\n",
    "        return buildings\n",
    "\n",
    "    def _place_access_points(self, state: torch.Tensor, params: dict, buildings: list) -> list:\n",
    "        G = self.G\n",
    "        ch = self.config['ch_access']\n",
    "        access_points = []\n",
    "        left_buildings = [b for b in buildings if b['side'] == 'left']\n",
    "        right_buildings = [b for b in buildings if b['side'] == 'right']\n",
    "        gap_x_min = max(b['gap_facing_x'] for b in left_buildings) if left_buildings else 0\n",
    "        gap_x_max = min(b['gap_facing_x'] for b in right_buildings) if right_buildings else G\n",
    "\n",
    "        for i in range(params.get('n_ground_access', 1)):\n",
    "            x = random.randint(gap_x_min + 1, gap_x_max - 3)\n",
    "            y = random.randint(0, G - 3)\n",
    "            state[:, ch, 0:2, y:y+2, x:x+2] = 1.0\n",
    "            access_points.append({'x': x, 'y': y, 'z': 0, 'type': 'ground'})\n",
    "\n",
    "        for i in range(params.get('n_elevated_access', 1)):\n",
    "            building = random.choice(buildings)\n",
    "            bz_max = building['z'][1]\n",
    "            is_left = building['side'] == 'left'\n",
    "            z = random.randint(3, max(4, bz_max - 2))\n",
    "            y = random.randint(building['y'][0], min(building['y'][1] - 2, building['y'][0] + G//3))\n",
    "            x = building['x'][1] if is_left else building['x'][0] - 2\n",
    "            x = max(0, min(G - 2, x))\n",
    "            state[:, ch, z:z+2, y:y+2, x:x+2] = 1.0\n",
    "            access_points.append({'x': x, 'y': y, 'z': z, 'type': 'elevated'})\n",
    "        return access_points\n",
    "\n",
    "    def _generate_anchor_zones(self, state: torch.Tensor, params: dict,\n",
    "                               buildings: list, access_points: list) -> dict:\n",
    "        G = self.G\n",
    "        ch = self.config['ch_anchors']\n",
    "        street_levels = self.config['street_levels']\n",
    "        existing = state[:, self.config['ch_existing'], 0, :, :]\n",
    "        street_mask = 1.0 - existing\n",
    "        anchors = torch.zeros(1, 1, G, G, G, device=state.device)\n",
    "\n",
    "        for ap in access_points:\n",
    "            if ap['type'] == 'ground':\n",
    "                x, y = ap['x'], ap['y']\n",
    "                for z in range(street_levels):\n",
    "                    anchors[:, 0, z, max(0,y-2):min(G,y+4), max(0,x-2):min(G,x+4)] = 1.0\n",
    "\n",
    "        for building in buildings:\n",
    "            by_start, by_end = building['y']\n",
    "            gap_x = building['gap_facing_x']\n",
    "            is_left = building['side'] == 'left'\n",
    "            x_start = gap_x if is_left else gap_x - 1\n",
    "            x_end = gap_x + 1 if is_left else gap_x\n",
    "            for z in range(street_levels):\n",
    "                anchors[:, 0, z, by_start:min(by_start+4, by_end), max(0,x_start):min(G,x_end)] = 1.0\n",
    "\n",
    "        for z in range(street_levels):\n",
    "            anchors[:, 0, z, :, :] *= street_mask\n",
    "        state[:, ch:ch+1, :, :, :] = anchors\n",
    "        return {'total_area': (anchors > 0.5).sum().item()}\n",
    "\n",
    "    def batch(self, difficulty: str, batch_size: int, device: str) -> torch.Tensor:\n",
    "        scenes = [self.generate(difficulty, device)[0] for _ in range(batch_size)]\n",
    "        return torch.cat(scenes, dim=0)\n",
    "\n",
    "print('Core components defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 3. Corridor Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_access_centroids(access_channel: torch.Tensor, threshold: float = 0.5) -> List[Tuple[int, int, int]]:\n",
    "    \"\"\"Find centroids of access point regions.\"\"\"\n",
    "    binary = (access_channel > threshold).float()\n",
    "    if binary.sum() == 0:\n",
    "        return []\n",
    "    centroids = []\n",
    "    positions = (binary > 0).nonzero(as_tuple=False)\n",
    "    if len(positions) == 0:\n",
    "        return []\n",
    "\n",
    "    used = set()\n",
    "    for idx in range(len(positions)):\n",
    "        if idx in used:\n",
    "            continue\n",
    "        pos = positions[idx]\n",
    "        cluster = [pos]\n",
    "        used.add(idx)\n",
    "        for idx2 in range(idx + 1, len(positions)):\n",
    "            if idx2 in used:\n",
    "                continue\n",
    "            pos2 = positions[idx2]\n",
    "            dist = (pos - pos2).abs().sum().item()\n",
    "            if dist <= 4:\n",
    "                cluster.append(pos2)\n",
    "                used.add(idx2)\n",
    "        cluster = torch.stack(cluster).float()\n",
    "        centroid = cluster.mean(dim=0).long()\n",
    "        centroids.append((centroid[0].item(), centroid[1].item(), centroid[2].item()))\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def compute_distance_field_3d(start_points: List[Tuple[int, int, int]],\n",
    "                               legal_mask: torch.Tensor, max_iters: int = 64) -> torch.Tensor:\n",
    "    \"\"\"Compute distance field from start points.\"\"\"\n",
    "    D, H, W = legal_mask.shape\n",
    "    device = legal_mask.device\n",
    "    distance = torch.full((D, H, W), float('inf'), device=device)\n",
    "\n",
    "    for z, y, x in start_points:\n",
    "        if 0 <= z < D and 0 <= y < H and 0 <= x < W:\n",
    "            distance[z, y, x] = 0\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        dist_4d = distance.unsqueeze(0).unsqueeze(0)\n",
    "        expanded = -F.max_pool3d(-dist_4d, 3, 1, 1).squeeze(0).squeeze(0)\n",
    "        expanded = expanded + 1\n",
    "        new_distance = torch.where(legal_mask > 0.5, torch.min(distance, expanded), distance)\n",
    "        if torch.allclose(distance, new_distance, atol=1e-5):\n",
    "            break\n",
    "        distance = new_distance\n",
    "    return distance\n",
    "\n",
    "\n",
    "def compute_corridor_target(seed_state: torch.Tensor, config: dict,\n",
    "                            corridor_width: int = 4, vertical_envelope: int = 3) -> torch.Tensor:\n",
    "    \"\"\"Compute 3D corridor target from SEED state.\"\"\"\n",
    "    cfg = config\n",
    "    G = cfg['grid_size']\n",
    "    device = seed_state.device\n",
    "    B = seed_state.shape[0]\n",
    "    corridors = torch.zeros(B, G, G, G, device=device)\n",
    "\n",
    "    for b in range(B):\n",
    "        access = seed_state[b, cfg['ch_access']]\n",
    "        existing = seed_state[b, cfg['ch_existing']]\n",
    "        legal_mask = 1.0 - existing\n",
    "        centroids = find_access_centroids(access)\n",
    "\n",
    "        if len(centroids) < 2:\n",
    "            dilated = F.max_pool3d(access.unsqueeze(0).unsqueeze(0),\n",
    "                                   2*corridor_width+1, 1, corridor_width)\n",
    "            corridors[b] = dilated.squeeze() * legal_mask\n",
    "            continue\n",
    "\n",
    "        corridor_mask = torch.zeros(G, G, G, device=device)\n",
    "        for i, j in combinations(range(len(centroids)), 2):\n",
    "            start, end = centroids[i], centroids[j]\n",
    "            dist_from_start = compute_distance_field_3d([start], legal_mask)\n",
    "            dist_from_end = compute_distance_field_3d([end], legal_mask)\n",
    "            total_dist = dist_from_start[end[0], end[1], end[2]]\n",
    "            if total_dist == float('inf'):\n",
    "                continue\n",
    "            path_cost = dist_from_start + dist_from_end\n",
    "            slack = corridor_width * 2\n",
    "            on_path = (path_cost <= total_dist + slack).float()\n",
    "            corridor_mask = torch.max(corridor_mask, on_path)\n",
    "\n",
    "        if corridor_mask.sum() > 0:\n",
    "            corridor_4d = corridor_mask.unsqueeze(0).unsqueeze(0)\n",
    "            dilated = F.max_pool3d(corridor_4d, 2*corridor_width+1, 1, corridor_width)\n",
    "            corridor_dilated = dilated.squeeze()\n",
    "\n",
    "            # Vertical envelope\n",
    "            if vertical_envelope > 0:\n",
    "                for z in range(G):\n",
    "                    z_min = max(0, z - vertical_envelope)\n",
    "                    z_max = min(G, z + vertical_envelope + 1)\n",
    "                    if corridor_dilated[z_min:z_max].max(dim=0)[0].any():\n",
    "                        corridor_dilated[z] = torch.max(\n",
    "                            corridor_dilated[z],\n",
    "                            corridor_dilated[z_min:z_max].max(dim=0)[0] * 0.8\n",
    "                        )\n",
    "            corridors[b] = corridor_dilated * legal_mask\n",
    "        else:\n",
    "            dilated = F.max_pool3d(access.unsqueeze(0).unsqueeze(0),\n",
    "                                   2*corridor_width+1, 1, corridor_width)\n",
    "            corridors[b] = dilated.squeeze() * legal_mask\n",
    "    return corridors\n",
    "\n",
    "print('Corridor computation defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 4. Loss Functions (CLEAN - 12 losses only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalLegalityLoss(nn.Module):\n",
    "    \"\"\"Per-voxel legality enforcement.\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.street_levels = config['street_levels']\n",
    "\n",
    "    def compute_legality_field(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        cfg = self.config\n",
    "        G = cfg['grid_size']\n",
    "        existing = state[:, cfg['ch_existing']]\n",
    "        anchors = state[:, cfg['ch_anchors']]\n",
    "        B = state.shape[0]\n",
    "        device = state.device\n",
    "\n",
    "        z_indices = torch.arange(G, device=device).view(1, G, 1, 1).expand(B, G, G, G)\n",
    "        above_street = (z_indices >= self.street_levels).float()\n",
    "        at_street = (z_indices < self.street_levels).float()\n",
    "        position_legality = above_street + at_street * anchors\n",
    "        legality = (1 - existing) * position_legality\n",
    "        return torch.clamp(legality, 0, 1)\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        structure = state[:, self.config['ch_structure']]\n",
    "        legality = self.compute_legality_field(state)\n",
    "        illegal_structure = structure * (1 - legality)\n",
    "        return illegal_structure.sum() / (structure.sum() + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorridorCoverageLoss(nn.Module):\n",
    "    \"\"\"(A) Penalize UNFILLED corridor - model must cover the target.\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, structure: torch.Tensor, corridor_target: torch.Tensor) -> torch.Tensor:\n",
    "        unfilled = corridor_target * (1 - structure)\n",
    "        return unfilled.sum() / (corridor_target.sum() + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorridorSpillLoss(nn.Module):\n",
    "    \"\"\"(B) Penalize structure OUTSIDE corridor.\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict, absolute_weight: float = 0.01):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.absolute_weight = absolute_weight\n",
    "\n",
    "    def forward(self, structure: torch.Tensor, corridor_target: torch.Tensor,\n",
    "                legality_field: torch.Tensor) -> torch.Tensor:\n",
    "        outside = structure * (1 - corridor_target) * legality_field\n",
    "        ratio_penalty = outside.sum() / (structure.sum() + 1e-8)\n",
    "        G = self.config['grid_size']\n",
    "        absolute_penalty = outside.sum() / (G * G * G)\n",
    "        return ratio_penalty + self.absolute_weight * absolute_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroundOpennessLoss(nn.Module):\n",
    "    \"\"\"Keep street level open except where corridor requires.\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.street_levels = config['street_levels']\n",
    "\n",
    "    def forward(self, structure: torch.Tensor, corridor_target: torch.Tensor,\n",
    "                legality_field: torch.Tensor) -> torch.Tensor:\n",
    "        sl = self.street_levels\n",
    "        ground_structure = structure[:, :sl, :, :]\n",
    "        ground_corridor = corridor_target[:, :sl, :, :]\n",
    "        ground_legal = legality_field[:, :sl, :, :]\n",
    "        unnecessary_ground = ground_structure * (1 - ground_corridor) * ground_legal\n",
    "        return unnecessary_ground.sum() / (ground_structure.sum() + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThicknessLoss(nn.Module):\n",
    "    \"\"\"Penalize blob-like thick structures.\"\"\"\n",
    "\n",
    "    def __init__(self, max_thickness: int = 2):\n",
    "        super().__init__()\n",
    "        self.max_thickness = max_thickness\n",
    "\n",
    "    def erode_3d(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_4d = x.unsqueeze(1) if x.dim() == 4 else x.unsqueeze(0).unsqueeze(0)\n",
    "        eroded = -F.max_pool3d(-x_4d, 3, 1, 1)\n",
    "        return eroded.squeeze(1) if x.dim() == 4 else eroded.squeeze(0).squeeze(0)\n",
    "\n",
    "    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n",
    "        struct_soft = torch.sigmoid(10 * (structure - 0.3))\n",
    "        core = struct_soft\n",
    "        for _ in range(self.max_thickness):\n",
    "            core = self.erode_3d(core)\n",
    "        return core.sum() / (struct_soft.sum() + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparsityLoss(nn.Module):\n",
    "    \"\"\"Volume limit with squared penalty.\"\"\"\n",
    "\n",
    "    def __init__(self, max_ratio: float = 0.15, min_ratio: float = 0.05):\n",
    "        super().__init__()\n",
    "        self.max_ratio = max_ratio\n",
    "        self.min_ratio = min_ratio\n",
    "\n",
    "    def forward(self, structure: torch.Tensor, available: torch.Tensor) -> torch.Tensor:\n",
    "        ratio = structure.sum() / (available.sum() + 1e-8)\n",
    "        over = F.relu(ratio - self.max_ratio)\n",
    "        over_penalty = over ** 2 * 100\n",
    "        under_penalty = 3.0 * F.relu(self.min_ratio - ratio)\n",
    "        return over_penalty + under_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacadeContactLoss(nn.Module):\n",
    "    \"\"\"Limit facade contact.\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict, max_contact_ratio: float = 0.15):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.max_contact_ratio = max_contact_ratio\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        cfg = self.config\n",
    "        structure = state[:, cfg['ch_structure']]\n",
    "        existing = state[:, cfg['ch_existing']]\n",
    "        dilated = F.max_pool3d(existing.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "        facade_zone = torch.clamp(dilated - existing, 0, 1)\n",
    "        contact = (structure * facade_zone).sum()\n",
    "        contact_ratio = contact / (structure.sum() + 1e-8)\n",
    "        return F.relu(contact_ratio - self.max_contact_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccessConnectivityLoss(nn.Module):\n",
    "    \"\"\"Street connectivity from access points.\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict, iterations: int = 32):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.street_levels = config['street_levels']\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        cfg = self.config\n",
    "        sl = self.street_levels\n",
    "        structure = state[:, cfg['ch_structure'], :sl, :, :]\n",
    "        existing = state[:, cfg['ch_existing'], :sl, :, :]\n",
    "        access = state[:, cfg['ch_access'], :sl, :, :]\n",
    "\n",
    "        void_mask = (1 - structure) * (1 - existing)\n",
    "        access_seed = F.max_pool3d(access.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "        connected = access_seed * void_mask\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            dilated = F.max_pool3d(connected.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "            new_connected = torch.max(connected, dilated * void_mask)\n",
    "            if torch.allclose(connected, new_connected, atol=1e-5):\n",
    "                break\n",
    "            connected = new_connected\n",
    "\n",
    "        access_locations = (access > 0.5).float()\n",
    "        reachable = (connected * access_locations).sum()\n",
    "        return 1 - (reachable / (access_locations.sum() + 1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadPathLoss(nn.Module):\n",
    "    \"\"\"Structural load path connectivity.\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict, iterations: int = 32):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.street_levels = config['street_levels']\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        cfg = self.config\n",
    "        sl = self.street_levels\n",
    "        structure = state[:, cfg['ch_structure']]\n",
    "        existing = state[:, cfg['ch_existing']]\n",
    "        anchors = state[:, cfg['ch_anchors']]\n",
    "\n",
    "        support_street = torch.max(existing[:, :sl, :, :], anchors[:, :sl, :, :])\n",
    "        support_above = existing[:, sl:, :, :]\n",
    "        support = torch.cat([support_street, support_above], dim=1)\n",
    "\n",
    "        connected = support.clone()\n",
    "        struct_soft = torch.sigmoid(10 * (structure - 0.3))\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            dilated = F.max_pool3d(connected.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "            new_connected = torch.max(connected, dilated * struct_soft)\n",
    "            if torch.allclose(connected, new_connected, atol=1e-5):\n",
    "                break\n",
    "            connected = new_connected\n",
    "\n",
    "        elevated = structure[:, sl:, :, :]\n",
    "        elevated_connected = connected[:, sl:, :, :]\n",
    "        unsupported = elevated * (1 - elevated_connected)\n",
    "        return unsupported.sum() / (elevated.sum() + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CantileverLoss(nn.Module):\n",
    "    \"\"\"Limit horizontal overhangs.\"\"\"\n",
    "\n",
    "    def __init__(self, max_overhang: int = 3):\n",
    "        super().__init__()\n",
    "        self.max_overhang = max_overhang\n",
    "\n",
    "    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n",
    "        B, D, H, W = structure.shape\n",
    "        N = self.max_overhang\n",
    "        total_loss = 0.0\n",
    "        count = 0\n",
    "        for z in range(N, D):\n",
    "            layer = structure[:, z]\n",
    "            support_volume = structure[:, max(0, z-N):z]\n",
    "            support_max = support_volume.max(dim=1)[0]\n",
    "            support_dilated = F.max_pool2d(support_max.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "            has_support = torch.sigmoid(10 * (support_dilated - 0.3))\n",
    "            unsupported = layer * (1.0 - has_support)\n",
    "            total_loss += unsupported.mean()\n",
    "            count += 1\n",
    "        return total_loss / max(1, count)\n",
    "\n",
    "\n",
    "class DensityPenalty(nn.Module):\n",
    "    \"\"\"Binary output incentive.\"\"\"\n",
    "    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n",
    "        return (structure * (1.0 - structure)).mean()\n",
    "\n",
    "\n",
    "class TotalVariation3D(nn.Module):\n",
    "    \"\"\"Smoothness.\"\"\"\n",
    "    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n",
    "        tv_d = (structure[:, 1:, :, :] - structure[:, :-1, :, :]).abs().mean()\n",
    "        tv_h = (structure[:, :, 1:, :] - structure[:, :, :-1, :]).abs().mean()\n",
    "        tv_w = (structure[:, :, :, 1:] - structure[:, :, :, :-1]).abs().mean()\n",
    "        return tv_d + tv_h + tv_w\n",
    "\n",
    "\n",
    "print('All 12 loss functions defined (CLEAN)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 5. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_legality_compliance(state, config):\n",
    "    legality_loss = LocalLegalityLoss(config)\n",
    "    legality_field = legality_loss.compute_legality_field(state)\n",
    "    structure = state[:, config['ch_structure']]\n",
    "    return (structure * legality_field).sum() / (structure.sum() + 1e-8)\n",
    "\n",
    "def compute_corridor_coverage(structure, corridor_target):\n",
    "    filled = (structure * corridor_target).sum()\n",
    "    return filled / (corridor_target.sum() + 1e-8)\n",
    "\n",
    "def compute_corridor_spill(structure, corridor_target, legality_field):\n",
    "    outside = structure * (1 - corridor_target) * legality_field\n",
    "    return outside.sum() / (structure.sum() + 1e-8)\n",
    "\n",
    "def compute_ground_openness(structure, corridor_target, legality_field, config):\n",
    "    sl = config['street_levels']\n",
    "    ground_struct = structure[:, :sl, :, :]\n",
    "    ground_corr = corridor_target[:, :sl, :, :]\n",
    "    in_corridor = (ground_struct * ground_corr).sum()\n",
    "    return in_corridor / (ground_struct.sum() + 1e-8)\n",
    "\n",
    "def compute_thickness_compliance(state, config):\n",
    "    structure = state[:, config['ch_structure']]\n",
    "    thickness_loss = ThicknessLoss(config.get('max_thickness', 2))\n",
    "    return 1.0 - thickness_loss(structure).item()\n",
    "\n",
    "def compute_facade_contact(state, config):\n",
    "    structure = state[:, config['ch_structure']]\n",
    "    existing = state[:, config['ch_existing']]\n",
    "    dilated = F.max_pool3d(existing.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "    facade_zone = torch.clamp(dilated - existing, 0, 1)\n",
    "    return (structure * facade_zone).sum() / (structure.sum() + 1e-8)\n",
    "\n",
    "def compute_load_path_compliance(state, config):\n",
    "    loadpath = LoadPathLoss(config)\n",
    "    return 1.0 - loadpath(state)\n",
    "\n",
    "def compute_access_reachability(state, config):\n",
    "    access_conn = AccessConnectivityLoss(config)\n",
    "    return 1.0 - access_conn(state)\n",
    "\n",
    "def compute_fill_ratio(state, config):\n",
    "    structure = state[:, config['ch_structure']]\n",
    "    existing = state[:, config['ch_existing']]\n",
    "    available = 1.0 - existing\n",
    "    return structure.sum() / (available.sum() + 1e-8)\n",
    "\n",
    "print('Metrics defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 6. Trainer (CLEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanTrainerV6:\n",
    "    \"\"\"Step B v6.0 Trainer - Clean implementation.\"\"\"\n",
    "\n",
    "    def __init__(self, model: nn.Module, config: dict, device: str):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "\n",
    "        # 12 losses only\n",
    "        self.legality_loss = LocalLegalityLoss(config)\n",
    "        self.coverage_loss = CorridorCoverageLoss(config)\n",
    "        self.spill_loss = CorridorSpillLoss(config)\n",
    "        self.ground_loss = GroundOpennessLoss(config)\n",
    "        self.thickness_loss = ThicknessLoss(config.get('max_thickness', 2))\n",
    "        self.sparsity_loss = SparsityLoss()\n",
    "        self.facade_loss = FacadeContactLoss(config, config.get('max_facade_contact', 0.15))\n",
    "        self.access_conn_loss = AccessConnectivityLoss(config)\n",
    "        self.loadpath_loss = LoadPathLoss(config)\n",
    "        self.cantilever_loss = CantileverLoss()\n",
    "        self.density_loss = DensityPenalty()\n",
    "        self.tv_loss = TotalVariation3D()\n",
    "\n",
    "        # CLEAN weights - balanced\n",
    "        self.weights = {\n",
    "            'legality': 30.0,\n",
    "            'coverage': 25.0,\n",
    "            'spill': 25.0,\n",
    "            'ground': 15.0,\n",
    "            'thickness': 20.0,\n",
    "            'sparsity': 25.0,\n",
    "            'facade': 10.0,\n",
    "            'access_conn': 15.0,\n",
    "            'loadpath': 8.0,\n",
    "            'cantilever': 5.0,\n",
    "            'density': 3.0,\n",
    "            'tv': 1.0,\n",
    "        }\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=config['lr_initial'])\n",
    "        self.scene_gen = UrbanSceneGenerator(config)\n",
    "        self.history = []\n",
    "\n",
    "    def train_epoch(self, epoch: int) -> dict:\n",
    "        self.model.train()\n",
    "        cfg = self.config\n",
    "\n",
    "        seeds = self.scene_gen.batch(cfg['difficulty'], cfg['batch_size'], self.device)\n",
    "\n",
    "        # Corridor from SEED\n",
    "        with torch.no_grad():\n",
    "            corridor_target = compute_corridor_target(\n",
    "                seeds, cfg,\n",
    "                corridor_width=cfg.get('corridor_width', 4),\n",
    "                vertical_envelope=cfg.get('vertical_envelope', 3)\n",
    "            )\n",
    "\n",
    "        steps = random.randint(cfg['steps_min'], cfg['steps_max'])\n",
    "        final = self.model(seeds, steps=steps)\n",
    "\n",
    "        structure = final[:, cfg['ch_structure']]\n",
    "        existing = final[:, cfg['ch_existing']]\n",
    "        available = 1.0 - existing\n",
    "        legality_field = self.legality_loss.compute_legality_field(final)\n",
    "\n",
    "        # Compute losses\n",
    "        L_legality = self.legality_loss(final)\n",
    "        L_coverage = self.coverage_loss(structure, corridor_target)\n",
    "        L_spill = self.spill_loss(structure, corridor_target, legality_field)\n",
    "        L_ground = self.ground_loss(structure, corridor_target, legality_field)\n",
    "        L_thickness = self.thickness_loss(structure)\n",
    "        L_sparsity = self.sparsity_loss(structure, available)\n",
    "        L_facade = self.facade_loss(final)\n",
    "        L_access_conn = self.access_conn_loss(final)\n",
    "        L_loadpath = self.loadpath_loss(final)\n",
    "        L_cant = self.cantilever_loss(structure)\n",
    "        L_density = self.density_loss(structure)\n",
    "        L_tv = self.tv_loss(structure)\n",
    "\n",
    "        total_loss = (\n",
    "            self.weights['legality'] * L_legality +\n",
    "            self.weights['coverage'] * L_coverage +\n",
    "            self.weights['spill'] * L_spill +\n",
    "            self.weights['ground'] * L_ground +\n",
    "            self.weights['thickness'] * L_thickness +\n",
    "            self.weights['sparsity'] * L_sparsity +\n",
    "            self.weights['facade'] * L_facade +\n",
    "            self.weights['access_conn'] * L_access_conn +\n",
    "            self.weights['loadpath'] * L_loadpath +\n",
    "            self.weights['cantilever'] * L_cant +\n",
    "            self.weights['density'] * L_density +\n",
    "            self.weights['tv'] * L_tv\n",
    "        )\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), cfg['grad_clip'])\n",
    "        self.optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            metrics = {\n",
    "                'epoch': epoch,\n",
    "                'total_loss': total_loss.item(),\n",
    "                'L_coverage': L_coverage.item(),\n",
    "                'L_spill': L_spill.item(),\n",
    "                'L_thickness': L_thickness.item(),\n",
    "                'coverage': compute_corridor_coverage(structure, corridor_target).item(),\n",
    "                'spill': compute_corridor_spill(structure, corridor_target, legality_field).item(),\n",
    "                'thickness': compute_thickness_compliance(final, cfg),\n",
    "                'fill_ratio': compute_fill_ratio(final, cfg).item(),\n",
    "                'legality': compute_legality_compliance(final, cfg).item(),\n",
    "                'loadpath': compute_load_path_compliance(final, cfg).item(),\n",
    "                'access_reach': compute_access_reachability(final, cfg).item(),\n",
    "            }\n",
    "        self.history.append(metrics)\n",
    "        return metrics\n",
    "\n",
    "    def evaluate(self, n_samples: int = 50) -> dict:\n",
    "        self.model.eval()\n",
    "        cfg = self.config\n",
    "        results = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(n_samples):\n",
    "                scene, _ = self.scene_gen.generate(cfg['difficulty'], self.device)\n",
    "                corridor_target = compute_corridor_target(\n",
    "                    scene, cfg,\n",
    "                    corridor_width=cfg.get('corridor_width', 4),\n",
    "                    vertical_envelope=cfg.get('vertical_envelope', 3)\n",
    "                )\n",
    "                grown = self.model.grow(scene, steps=50)\n",
    "                structure = grown[:, cfg['ch_structure']]\n",
    "                legality_field = self.legality_loss.compute_legality_field(grown)\n",
    "\n",
    "                results.append({\n",
    "                    'legality': compute_legality_compliance(grown, cfg).item(),\n",
    "                    'coverage': compute_corridor_coverage(structure, corridor_target).item(),\n",
    "                    'spill': compute_corridor_spill(structure, corridor_target, legality_field).item(),\n",
    "                    'thickness': compute_thickness_compliance(grown, cfg),\n",
    "                    'facade': compute_facade_contact(grown, cfg).item(),\n",
    "                    'loadpath': compute_load_path_compliance(grown, cfg).item(),\n",
    "                    'access_reach': compute_access_reachability(grown, cfg).item(),\n",
    "                    'fill_ratio': compute_fill_ratio(grown, cfg).item(),\n",
    "                })\n",
    "\n",
    "        return {f'avg_{k}': np.mean([r[k] for r in results]) for k in results[0].keys()}\n",
    "\n",
    "    def save_checkpoint(self, path: str):\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'history': self.history,\n",
    "        }, path)\n",
    "        print(f'Saved: {path}')\n",
    "\n",
    "print('CleanTrainerV6 defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## 7. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_result(model, scene_gen, config, device, title='Result'):\n",
    "    model.eval()\n",
    "    scene, _ = scene_gen.generate(config['difficulty'], device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        corridor_target = compute_corridor_target(\n",
    "            scene, config,\n",
    "            corridor_width=config.get('corridor_width', 4),\n",
    "            vertical_envelope=config.get('vertical_envelope', 3)\n",
    "        )\n",
    "        grown = model.grow(scene, steps=50)\n",
    "\n",
    "    cfg = config\n",
    "    s = grown[0].cpu().numpy()\n",
    "    G = s.shape[1]\n",
    "\n",
    "    existing = s[cfg['ch_existing']] > 0.5\n",
    "    access = s[cfg['ch_access']] > 0.5\n",
    "    structure = s[cfg['ch_structure']] > 0.5\n",
    "    corridor = corridor_target[0].cpu().numpy() > 0.5\n",
    "    legality_field = LocalLegalityLoss(config).compute_legality_field(grown)[0].cpu().numpy()\n",
    "\n",
    "    in_corridor = structure & corridor & (legality_field >= 0.5)\n",
    "    outside_corridor = structure & ~corridor & (legality_field >= 0.5)\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 4))\n",
    "\n",
    "    ax1 = fig.add_subplot(141, projection='3d')\n",
    "    if existing.any():\n",
    "        ax1.voxels(existing.transpose(1,2,0), facecolors='gray', alpha=0.3)\n",
    "    if access.any():\n",
    "        ax1.voxels(access.transpose(1,2,0), facecolors='green', alpha=0.9)\n",
    "    if outside_corridor.any():\n",
    "        ax1.voxels(outside_corridor.transpose(1,2,0), facecolors='orange', alpha=0.6)\n",
    "    if in_corridor.any():\n",
    "        ax1.voxels(in_corridor.transpose(1,2,0), facecolors='royalblue', alpha=0.6)\n",
    "    ax1.set_title(f'{title}')\n",
    "\n",
    "    ax2 = fig.add_subplot(142)\n",
    "    plan = np.zeros((G,G,3))\n",
    "    plan[existing[0,:,:]] = [0.5,0.5,0.5]\n",
    "    plan[corridor[0,:,:] & ~existing[0,:,:]] = [0.8,0.9,1.0]\n",
    "    plan[in_corridor.max(axis=0)] = [0.2,0.4,0.8]\n",
    "    plan[outside_corridor.max(axis=0)] = [1.0,0.6,0.2]\n",
    "    plan[access.max(axis=0)] = [0.2,0.8,0.2]\n",
    "    ax2.imshow(plan.transpose(1,0,2), origin='lower')\n",
    "    ax2.set_title('Ground Level')\n",
    "\n",
    "    ax3 = fig.add_subplot(143)\n",
    "    elev = np.zeros((G,G,3))\n",
    "    elev[existing.max(axis=1)] = [0.5,0.5,0.5]\n",
    "    elev[in_corridor.max(axis=1)] = [0.2,0.4,0.8]\n",
    "    elev[outside_corridor.max(axis=1)] = [1.0,0.6,0.2]\n",
    "    elev[access.max(axis=1)] = [0.2,0.8,0.2]\n",
    "    ax3.imshow(elev.transpose(1,0,2), origin='lower')\n",
    "    ax3.set_title('Elevation')\n",
    "\n",
    "    ax4 = fig.add_subplot(144)\n",
    "    ax4.axis('off')\n",
    "    struct_t = grown[:, config['ch_structure']]\n",
    "    leg_f = LocalLegalityLoss(config).compute_legality_field(grown)\n",
    "\n",
    "    cov = compute_corridor_coverage(struct_t, corridor_target).item()\n",
    "    spl = compute_corridor_spill(struct_t, corridor_target, leg_f).item()\n",
    "    thk = compute_thickness_compliance(grown, config)\n",
    "    fill = compute_fill_ratio(grown, config).item()\n",
    "    load = compute_load_path_compliance(grown, config).item()\n",
    "\n",
    "    text = f\"\"\"METRICS\n",
    "Coverage: {cov*100:.1f}% {'PASS' if cov>0.7 else 'FAIL'}\n",
    "Spill: {spl*100:.1f}% {'PASS' if spl<0.2 else 'FAIL'}\n",
    "Thickness: {thk*100:.1f}% {'PASS' if thk>0.9 else 'FAIL'}\n",
    "Fill: {fill*100:.1f}% {'PASS' if 0.05<fill<0.15 else 'FAIL'}\n",
    "LoadPath: {load*100:.1f}% {'PASS' if load>0.95 else 'FAIL'}\n",
    "\"\"\"\n",
    "    ax4.text(0.1, 0.9, text, transform=ax4.transAxes, fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return grown\n",
    "\n",
    "\n",
    "def plot_training_curves(history):\n",
    "    epochs = [h['epoch'] for h in history]\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "    axes[0,0].plot(epochs, [h['total_loss'] for h in history])\n",
    "    axes[0,0].set_title('Total Loss')\n",
    "    axes[0,0].set_yscale('log')\n",
    "\n",
    "    axes[0,1].plot(epochs, [h['coverage'] for h in history], 'b-')\n",
    "    axes[0,1].axhline(0.70, color='k', linestyle='--')\n",
    "    axes[0,1].set_title('Coverage (>70%)')\n",
    "    axes[0,1].set_ylim(0, 1.1)\n",
    "\n",
    "    axes[0,2].plot(epochs, [h['spill'] for h in history], 'orange')\n",
    "    axes[0,2].axhline(0.20, color='k', linestyle='--')\n",
    "    axes[0,2].set_title('Spill (<20%)')\n",
    "    axes[0,2].set_ylim(0, 1.1)\n",
    "\n",
    "    axes[1,0].plot(epochs, [h['thickness'] for h in history], 'purple')\n",
    "    axes[1,0].axhline(0.90, color='k', linestyle='--')\n",
    "    axes[1,0].set_title('Thickness (>90%)')\n",
    "    axes[1,0].set_ylim(0, 1.1)\n",
    "\n",
    "    axes[1,1].plot(epochs, [h['fill_ratio'] for h in history], 'g-')\n",
    "    axes[1,1].axhline(0.15, color='r', linestyle='--')\n",
    "    axes[1,1].axhline(0.05, color='g', linestyle='--')\n",
    "    axes[1,1].set_title('Fill Ratio (5-15%)')\n",
    "    axes[1,1].set_ylim(0, 0.35)\n",
    "\n",
    "    axes[1,2].plot(epochs, [h['loadpath'] for h in history], 'm-')\n",
    "    axes[1,2].axhline(0.95, color='k', linestyle='--')\n",
    "    axes[1,2].set_title('LoadPath (>95%)')\n",
    "    axes[1,2].set_ylim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print('Visualization defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## 8. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "model = UrbanPavilionNCA(CONFIG).to(device)\n",
    "trainer = CleanTrainerV6(model, CONFIG, device)\n",
    "\n",
    "print(f'Parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
    "print(f'\\nv6.0 CLEAN - 12 losses only')\n",
    "print(f'Weights: {trainer.weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before training\n",
    "visualize_result(model, trainer.scene_gen, CONFIG, device, 'Before Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "print('='*60)\n",
    "print('STEP B v6.0 TRAINING - CLEAN')\n",
    "print('='*60)\n",
    "\n",
    "for epoch in tqdm(range(CONFIG['epochs']), desc='Training'):\n",
    "    metrics = trainer.train_epoch(epoch)\n",
    "\n",
    "    if epoch % CONFIG['log_every'] == 0:\n",
    "        tqdm.write(\n",
    "            f\"E{epoch:4d} | Loss:{metrics['total_loss']:.1f} | \"\n",
    "            f\"Cov:{metrics['coverage']*100:.0f}% | \"\n",
    "            f\"Spl:{metrics['spill']*100:.0f}% | \"\n",
    "            f\"Thk:{metrics['thickness']*100:.0f}% | \"\n",
    "            f\"Fill:{metrics['fill_ratio']*100:.1f}%\"\n",
    "        )\n",
    "\n",
    "    if epoch > 0 and epoch % CONFIG['viz_every'] == 0:\n",
    "        visualize_result(model, trainer.scene_gen, CONFIG, device, f'Epoch {epoch}')\n",
    "\n",
    "    if epoch > 0 and epoch % CONFIG['save_every'] == 0:\n",
    "        trainer.save_checkpoint(f\"{PROJECT_ROOT}/step_b/checkpoints/v6_epoch_{epoch}.pth\")\n",
    "\n",
    "print('Training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "## 9. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(trainer.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print('Evaluating on 50 samples...')\n",
    "eval_results = trainer.evaluate(n_samples=50)\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('STEP B v6.0 EVALUATION')\n",
    "print('='*60)\n",
    "\n",
    "targets = {\n",
    "    'legality': (0.99, '>'),\n",
    "    'coverage': (0.70, '>'),\n",
    "    'spill': (0.20, '<'),\n",
    "    'thickness': (0.90, '>'),\n",
    "    'facade': (0.15, '<'),\n",
    "    'loadpath': (0.95, '>'),\n",
    "    'access_reach': (0.90, '>'),\n",
    "    'fill_ratio': (0.15, '<'),\n",
    "}\n",
    "\n",
    "for metric, (target, op) in targets.items():\n",
    "    val = eval_results[f'avg_{metric}']\n",
    "    if op == '>':\n",
    "        passed = val > target\n",
    "        print(f\"{metric:15s}: {val*100:5.1f}% {'PASS' if passed else 'FAIL'} (>{target*100:.0f}%)\")\n",
    "    else:\n",
    "        passed = val < target\n",
    "        print(f\"{metric:15s}: {val*100:5.1f}% {'PASS' if passed else 'FAIL'} (<{target*100:.0f}%)\")\n",
    "\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final visualizations\n",
    "for i in range(3):\n",
    "    visualize_result(model, trainer.scene_gen, CONFIG, device, f'Final {i+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final\n",
    "trainer.save_checkpoint(f\"{PROJECT_ROOT}/step_b/checkpoints/v6_final.pth\")\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
