{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# NB02: All Constraints Training v2.0\n",
    "\n",
    "**Constraint-Based Architectural NCA - Step B v2.0**\n",
    "\n",
    "**Version:** 2.0 (Ontology Revision)  \n",
    "**Date:** December 2025  \n",
    "**Purpose:** Fix degenerate attractor via loss ontology restructuring\n",
    "\n",
    "---\n",
    "\n",
    "## Why v2.0? Ontology Problem Identified\n",
    "\n",
    "v1.0-v1.1 produced **stable degenerate attractors** because:\n",
    "1. **Legality was global** - Scalar ratios can be gamed\n",
    "2. **Growth was misaligned** - Incentives conflicted with rules\n",
    "3. **Connectivity was boundary-seeded** - Perimeter corridor exploit\n",
    "4. **Structure was mass-based** - No causal load paths\n",
    "\n",
    "## v2.0 Core Principle\n",
    "\n",
    "**Every constraint must be LOCAL and CAUSAL.**\n",
    "\n",
    "## New Loss Architecture\n",
    "\n",
    "| Category | Loss | Replaces | Weight |\n",
    "|----------|------|----------|--------|\n",
    "| **Legality** | LocalLegality | StreetVoid + Anchor | 30.0 |\n",
    "| **Growth** | AlignedGrowth | Dice | 25.0 |\n",
    "| **Structure** | LoadPath | Support + Connectivity | 20.0 |\n",
    "| **Circulation** | AccessConnectivity | StreetConnectivity | 15.0 |\n",
    "| **Massing** | Sparsity | - | 15.0 |\n",
    "| **Structure** | Cantilever | - | 5.0 |\n",
    "| **Quality** | Density | - | 3.0 |\n",
    "| **Quality** | TV | - | 1.0 |\n",
    "\n",
    "## Success Criteria\n",
    "\n",
    "| Metric | Target |\n",
    "|--------|--------|\n",
    "| Legality | 100% (all structure in legal zones) |\n",
    "| Growth alignment | >80% in legal target |\n",
    "| Load path | >95% connected to support |\n",
    "| Access connectivity | >90% mutual reachability |\n",
    "| Fill ratio | 5-15% |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "PROJECT_ROOT = '/content/drive/MyDrive/Constraint-NCA'\n",
    "print(f'Project root: {PROJECT_ROOT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Step B configuration\n",
    "with open(f'{PROJECT_ROOT}/config_step_b.json', 'r') as f:\n",
    "    CONFIG = json.load(f)\n",
    "\n",
    "# Training configuration\n",
    "CONFIG.update({\n",
    "    'epochs': 400,\n",
    "    'steps_min': 30,\n",
    "    'steps_max': 50,\n",
    "    'difficulty': 'easy',\n",
    "    'log_every': 20,\n",
    "    'viz_every': 100,\n",
    "    'save_every': 100,\n",
    "})\n",
    "\n",
    "print('Configuration loaded')\n",
    "print(f\"Difficulty: {CONFIG['difficulty']}\")\n",
    "print(f\"Epochs: {CONFIG['epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. Foundation Components (Unchanged from v1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PERCEPTION MODULE\n",
    "# ============================================================\n",
    "\n",
    "class Perceive3D(nn.Module):\n",
    "    \"\"\"3D Sobel perception with replicate padding.\"\"\"\n",
    "\n",
    "    def __init__(self, n_channels: int = 8):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        sobel_x = self._create_sobel_kernel('x')\n",
    "        sobel_y = self._create_sobel_kernel('y')\n",
    "        sobel_z = self._create_sobel_kernel('z')\n",
    "        identity = self._create_identity_kernel()\n",
    "\n",
    "        kernels = torch.stack([identity, sobel_x, sobel_y, sobel_z], dim=0)\n",
    "        self.register_buffer('kernels', kernels)\n",
    "\n",
    "    def _create_sobel_kernel(self, direction: str) -> torch.Tensor:\n",
    "        derivative = torch.tensor([-1., 0., 1.])\n",
    "        smoothing = torch.tensor([1., 2., 1.])\n",
    "\n",
    "        if direction == 'x':\n",
    "            kernel = torch.einsum('i,j,k->ijk', smoothing, smoothing, derivative)\n",
    "        elif direction == 'y':\n",
    "            kernel = torch.einsum('i,j,k->ijk', smoothing, derivative, smoothing)\n",
    "        elif direction == 'z':\n",
    "            kernel = torch.einsum('i,j,k->ijk', derivative, smoothing, smoothing)\n",
    "        return kernel / 16.0\n",
    "\n",
    "    def _create_identity_kernel(self) -> torch.Tensor:\n",
    "        kernel = torch.zeros(3, 3, 3)\n",
    "        kernel[1, 1, 1] = 1.0\n",
    "        return kernel\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, C, D, H, W = x.shape\n",
    "        x_padded = F.pad(x, (1, 1, 1, 1, 1, 1), mode='replicate')\n",
    "        \n",
    "        outputs = []\n",
    "        for k in range(4):\n",
    "            kernel = self.kernels[k:k+1].unsqueeze(0).expand(C, 1, 3, 3, 3)\n",
    "            out = F.conv3d(x_padded, kernel, padding=0, groups=C)\n",
    "            outputs.append(out)\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# NCA MODEL\n",
    "# ============================================================\n",
    "\n",
    "class UrbanPavilionNCA(nn.Module):\n",
    "    \"\"\"Neural Cellular Automaton for urban pavilion generation.\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        n_channels = config['n_channels']\n",
    "        hidden_dim = config['hidden_dim']\n",
    "        perception_dim = n_channels * 4\n",
    "        n_grown = config['n_grown']\n",
    "\n",
    "        self.perceive = Perceive3D(n_channels)\n",
    "\n",
    "        self.update_net = nn.Sequential(\n",
    "            nn.Conv3d(perception_dim, hidden_dim, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(hidden_dim, hidden_dim, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(hidden_dim, n_grown, 1),\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        gain = self.config['xavier_gain']\n",
    "        for m in self.update_net:\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=gain)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "        last_layer = self.update_net[-1]\n",
    "        with torch.no_grad():\n",
    "            last_layer.bias[0] = self.config['structure_bias']\n",
    "            last_layer.bias[1] = self.config['surface_bias']\n",
    "\n",
    "    def forward(self, state: torch.Tensor, steps: int = 1) -> torch.Tensor:\n",
    "        for _ in range(steps):\n",
    "            state = self._step(state)\n",
    "        return state\n",
    "\n",
    "    def _step(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        B, C, D, H, W = state.shape\n",
    "        cfg = self.config\n",
    "\n",
    "        perception = self.perceive(state)\n",
    "        delta = self.update_net(perception)\n",
    "\n",
    "        if self.training:\n",
    "            fire_mask = (torch.rand(B, 1, D, H, W, device=state.device) < cfg['fire_rate']).float()\n",
    "            delta = delta * fire_mask\n",
    "\n",
    "        grown_start = cfg['n_frozen']\n",
    "        grown_new = state[:, grown_start:] + cfg['update_scale'] * delta\n",
    "        grown_new = torch.clamp(grown_new, 0.0, 1.0)\n",
    "\n",
    "        # Hard mask: no structure inside buildings\n",
    "        existing = state[:, cfg['ch_existing']:cfg['ch_existing']+1]\n",
    "        available_mask = 1.0 - existing\n",
    "        struct_new = grown_new[:, 0:1] * available_mask\n",
    "        \n",
    "        grown_masked = torch.cat([struct_new, grown_new[:, 1:]], dim=1)\n",
    "        new_state = torch.cat([state[:, :grown_start], grown_masked], dim=1)\n",
    "\n",
    "        return new_state\n",
    "\n",
    "    def grow(self, seed: torch.Tensor, steps: int = 50) -> torch.Tensor:\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.forward(seed, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SCENE GENERATOR\n",
    "# ============================================================\n",
    "\n",
    "class UrbanSceneGenerator:\n",
    "    \"\"\"Generate urban scenes with buildings, access points, and anchor zones.\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        self.config = config\n",
    "        self.G = config['grid_size']\n",
    "        self.C = config['n_channels']\n",
    "\n",
    "    def generate(self, difficulty: str = 'easy',\n",
    "                 device: str = 'cuda') -> Tuple[torch.Tensor, dict]:\n",
    "        G = self.G\n",
    "        cfg = self.config\n",
    "        \n",
    "        state = torch.zeros(1, self.C, G, G, G, device=device)\n",
    "        state[:, cfg['ch_ground'], 0, :, :] = 1.0\n",
    "\n",
    "        params = self._get_difficulty_params(difficulty)\n",
    "        building_info = self._place_buildings(state, params)\n",
    "        access_info = self._place_access_points(state, params, building_info)\n",
    "        anchor_info = self._generate_anchor_zones(state, params, building_info, access_info)\n",
    "\n",
    "        metadata = {\n",
    "            'difficulty': difficulty,\n",
    "            'buildings': building_info,\n",
    "            'access_points': access_info,\n",
    "            'anchor_zones': anchor_info,\n",
    "            'gap_width': params['gap_width'],\n",
    "        }\n",
    "        \n",
    "        return state, metadata\n",
    "\n",
    "    def _get_difficulty_params(self, difficulty: str) -> dict:\n",
    "        G = self.G\n",
    "        if difficulty == 'easy':\n",
    "            return {\n",
    "                'n_buildings': 2, 'height_range': (12, 16), 'height_variance': False,\n",
    "                'width_range': (8, 12), 'gap_width': random.randint(14, 18),\n",
    "                'n_ground_access': 1, 'n_elevated_access': 1, 'anchor_budget': 0.10,\n",
    "            }\n",
    "        elif difficulty == 'medium':\n",
    "            return {\n",
    "                'n_buildings': 2, 'height_range': (10, 20), 'height_variance': True,\n",
    "                'width_range': (6, 10), 'gap_width': random.randint(10, 14),\n",
    "                'n_ground_access': random.randint(1, 2), 'n_elevated_access': random.randint(1, 2),\n",
    "                'anchor_budget': 0.07,\n",
    "            }\n",
    "        else:  # hard\n",
    "            return {\n",
    "                'n_buildings': random.randint(2, 4), 'height_range': (8, 24), 'height_variance': True,\n",
    "                'width_range': (5, 8), 'gap_width': random.randint(6, 10),\n",
    "                'n_ground_access': random.randint(2, 3), 'n_elevated_access': random.randint(2, 3),\n",
    "                'anchor_budget': 0.05,\n",
    "            }\n",
    "\n",
    "    def _place_buildings(self, state: torch.Tensor, params: dict) -> list:\n",
    "        G = self.G\n",
    "        ch = self.config['ch_existing']\n",
    "        buildings = []\n",
    "        gap_width = params['gap_width']\n",
    "        gap_center = G // 2\n",
    "\n",
    "        w1 = random.randint(*params['width_range'])\n",
    "        d1 = random.randint(G//2, G-2)\n",
    "        h1 = random.randint(*params['height_range'])\n",
    "        x1_end = gap_center - gap_width // 2\n",
    "        x1_start = max(0, x1_end - w1)\n",
    "        state[:, ch, :h1, :d1, x1_start:x1_end] = 1.0\n",
    "        buildings.append({'x': (x1_start, x1_end), 'y': (0, d1), 'z': (0, h1),\n",
    "                         'gap_facing_x': x1_end, 'side': 'left'})\n",
    "\n",
    "        w2 = random.randint(*params['width_range'])\n",
    "        d2 = random.randint(G//2, G-2)\n",
    "        h2 = h1 if not params['height_variance'] else random.randint(*params['height_range'])\n",
    "        x2_start = gap_center + gap_width // 2\n",
    "        x2_end = min(G, x2_start + w2)\n",
    "        state[:, ch, :h2, :d2, x2_start:x2_end] = 1.0\n",
    "        buildings.append({'x': (x2_start, x2_end), 'y': (0, d2), 'z': (0, h2),\n",
    "                         'gap_facing_x': x2_start, 'side': 'right'})\n",
    "\n",
    "        return buildings\n",
    "\n",
    "    def _place_access_points(self, state: torch.Tensor, params: dict, buildings: list) -> list:\n",
    "        G = self.G\n",
    "        ch = self.config['ch_access']\n",
    "        access_points = []\n",
    "        \n",
    "        left_buildings = [b for b in buildings if b['side'] == 'left']\n",
    "        right_buildings = [b for b in buildings if b['side'] == 'right']\n",
    "        gap_x_min = max(b['gap_facing_x'] for b in left_buildings) if left_buildings else 0\n",
    "        gap_x_max = min(b['gap_facing_x'] for b in right_buildings) if right_buildings else G\n",
    "        \n",
    "        for i in range(params.get('n_ground_access', 1)):\n",
    "            x = random.randint(gap_x_min + 1, gap_x_max - 3)\n",
    "            y = random.randint(0, G - 3)\n",
    "            state[:, ch, 0:2, y:y+2, x:x+2] = 1.0\n",
    "            access_points.append({'x': x, 'y': y, 'z': 0, 'type': 'ground'})\n",
    "        \n",
    "        for i in range(params.get('n_elevated_access', 1)):\n",
    "            building = random.choice(buildings)\n",
    "            bz_max = building['z'][1]\n",
    "            is_left = building['side'] == 'left'\n",
    "            \n",
    "            z = random.randint(3, max(4, bz_max - 2))\n",
    "            y = random.randint(building['y'][0], min(building['y'][1] - 2, building['y'][0] + G//3))\n",
    "            x = building['x'][1] if is_left else building['x'][0] - 2\n",
    "            x = max(0, min(G - 2, x))\n",
    "            \n",
    "            state[:, ch, z:z+2, y:y+2, x:x+2] = 1.0\n",
    "            access_points.append({'x': x, 'y': y, 'z': z, 'type': 'elevated'})\n",
    "\n",
    "        return access_points\n",
    "\n",
    "    def _generate_anchor_zones(self, state: torch.Tensor, params: dict,\n",
    "                               buildings: list, access_points: list) -> dict:\n",
    "        G = self.G\n",
    "        ch = self.config['ch_anchors']\n",
    "        street_levels = self.config['street_levels']\n",
    "        \n",
    "        existing = state[:, self.config['ch_existing'], 0, :, :]\n",
    "        street_mask = 1.0 - existing\n",
    "        total_street_area = street_mask.sum().item()\n",
    "        max_anchor_area = int(total_street_area * params['anchor_budget'])\n",
    "        \n",
    "        anchors = torch.zeros(1, 1, G, G, G, device=state.device)\n",
    "        current_anchor_area = 0\n",
    "        \n",
    "        for ap in access_points:\n",
    "            if ap['type'] == 'ground':\n",
    "                x, y = ap['x'], ap['y']\n",
    "                for z in range(street_levels):\n",
    "                    anchors[:, 0, z, max(0,y-1):min(G,y+3), max(0,x-1):min(G,x+3)] = 1.0\n",
    "        \n",
    "        for building in buildings:\n",
    "            by_start, by_end = building['y']\n",
    "            gap_x = building['gap_facing_x']\n",
    "            is_left = building['side'] == 'left'\n",
    "            x_start = gap_x if is_left else gap_x - 1\n",
    "            x_end = gap_x + 1 if is_left else gap_x\n",
    "            for z in range(street_levels):\n",
    "                anchors[:, 0, z, by_start:by_end, max(0,x_start):min(G,x_end)] = 1.0\n",
    "        \n",
    "        for z in range(street_levels):\n",
    "            anchors[:, 0, z, :, :] *= street_mask\n",
    "        \n",
    "        state[:, ch:ch+1, :, :, :] = anchors\n",
    "        final_anchor_area = (anchors > 0.5).sum().item()\n",
    "        \n",
    "        return {'total_area': final_anchor_area, 'budget': max_anchor_area,\n",
    "                'budget_ratio': params['anchor_budget'], 'street_area': total_street_area}\n",
    "\n",
    "    def batch(self, difficulty: str, batch_size: int, device: str) -> torch.Tensor:\n",
    "        scenes = [self.generate(difficulty, device)[0] for _ in range(batch_size)]\n",
    "        return torch.cat(scenes, dim=0)\n",
    "\n",
    "\n",
    "print('Foundation components loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 3. v2.0 Loss Functions (Ontology Revision)\n",
    "\n",
    "### Key Changes from v1.x\n",
    "\n",
    "| Old Loss | Problem | New Loss | Fix |\n",
    "|----------|---------|----------|-----|\n",
    "| StreetVoidLoss | Global ratio, gameable | LocalLegalityLoss | Per-voxel field |\n",
    "| AnchorBudgetLoss | Normalized, gameable | LocalLegalityLoss | Per-voxel field |\n",
    "| DiceLoss | Not aligned with legality | AlignedGrowthLoss | Legal âˆ© Access |\n",
    "| StreetConnectivityLoss | Boundary-seeded | AccessConnectivityLoss | Access-seeded |\n",
    "| SupportRatioLoss | Mass-based | LoadPathLoss | Causal path tracing |\n",
    "| ConnectivityLoss | Includes ground | LoadPathLoss | Buildings + anchors only |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CONSTRAINT 1: LOCAL LEGALITY LOSS (NEW - REPLACES VOID + ANCHOR)\n# ============================================================\n\nclass LocalLegalityLoss(nn.Module):\n    \"\"\"Per-voxel legality enforcement.\n    \n    REPLACES: StreetVoidLoss, AnchorBudgetLoss\n    \n    Every voxel has a binary legality value:\n    - Legal (1): Above street level, OR in anchor zone at street level\n    - Illegal (0): At street level AND outside anchors, OR inside buildings\n    \n    Key insight: No global ratios to game. Each illegal voxel is penalized directly.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        super().__init__()\n        self.config = config\n        self.street_levels = config['street_levels']\n\n    def compute_legality_field(self, state: torch.Tensor) -> torch.Tensor:\n        \"\"\"Compute per-voxel legality (1 = legal, 0 = illegal).\n        \n        Rules:\n        - Inside buildings: ILLEGAL\n        - At street level (z < 2) outside anchors: ILLEGAL\n        - At street level (z < 2) inside anchors: LEGAL\n        - Above street level (z >= 2) outside buildings: LEGAL\n        \"\"\"\n        cfg = self.config\n        G = cfg['grid_size']\n        street_levels = self.street_levels\n\n        existing = state[:, cfg['ch_existing']]\n        anchors = state[:, cfg['ch_anchors']]\n\n        # Create height mask (1 for above street, 0 for street level)\n        # Using broadcasting instead of in-place operations\n        B = state.shape[0]\n        device = state.device\n        \n        # Create z-coordinate tensor\n        z_indices = torch.arange(G, device=device).view(1, G, 1, 1).expand(B, G, G, G)\n        \n        # Above street level mask (z >= street_levels)\n        above_street = (z_indices >= street_levels).float()\n        \n        # At street level mask (z < street_levels)\n        at_street = (z_indices < street_levels).float()\n        \n        # Position legality:\n        # - Above street: always legal (1)\n        # - At street: legal only in anchors\n        position_legality = above_street + at_street * anchors\n        \n        # Final legality = not in buildings AND position is legal\n        legality = (1 - existing) * position_legality\n        legality = torch.clamp(legality, 0, 1)\n\n        return legality\n\n    def forward(self, state: torch.Tensor) -> torch.Tensor:\n        cfg = self.config\n        structure = state[:, cfg['ch_structure']]\n\n        legality = self.compute_legality_field(state)\n\n        # Direct per-voxel penalty: structure in illegal zones\n        illegal_structure = structure * (1 - legality)\n\n        # Normalize by total structure (but NOT in a way that can be gamed)\n        # Key: numerator increases with violations, can't be reduced by adding more structure\n        return illegal_structure.sum() / (structure.sum() + 1e-8)\n\n\nprint('LocalLegalityLoss defined (replaces StreetVoid + AnchorBudget)')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONSTRAINT 2: ALIGNED GROWTH LOSS (NEW - REPLACES DICE)\n",
    "# ============================================================\n",
    "\n",
    "class AlignedGrowthLoss(nn.Module):\n",
    "    \"\"\"Growth incentive aligned with legality.\n",
    "    \n",
    "    REPLACES: DiceLoss, AccessReachLoss, ElevatedBonus\n",
    "    \n",
    "    Growth is rewarded ONLY in zones that are BOTH:\n",
    "    1. Near access points (functionally useful)\n",
    "    2. Legal (permitted by constraints)\n",
    "    \n",
    "    Key insight: Growth incentive and legality point the same direction.\n",
    "    The model cannot be rewarded for illegal growth.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: dict, dilation_radius: int = 5):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.dilation_radius = dilation_radius\n",
    "\n",
    "    def forward(self, state: torch.Tensor, legality_field: torch.Tensor) -> torch.Tensor:\n",
    "        cfg = self.config\n",
    "        structure = state[:, cfg['ch_structure']]\n",
    "        access = state[:, cfg['ch_access']]\n",
    "        existing = state[:, cfg['ch_existing']]\n",
    "        G = cfg['grid_size']\n",
    "\n",
    "        # Dilate access points to create influence zone\n",
    "        k = 2 * self.dilation_radius + 1\n",
    "        access_zone = F.max_pool3d(access.unsqueeze(1), k, 1, self.dilation_radius).squeeze(1)\n",
    "\n",
    "        # Legal growth target = access zone AND legal AND not in buildings\n",
    "        available = 1.0 - existing\n",
    "        legal_target = access_zone * legality_field * available\n",
    "\n",
    "        # Optional: height weighting to encourage elevated structures\n",
    "        z_coords = torch.arange(G, device=state.device).float()\n",
    "        height_weight = (z_coords / G).view(1, G, 1, 1).expand(1, G, G, G)\n",
    "        legal_target_weighted = legal_target * (1 + 0.5 * height_weight)\n",
    "\n",
    "        # Dice loss toward legal target only\n",
    "        intersection = (structure * legal_target_weighted).sum()\n",
    "        dice = (2 * intersection + 1) / (structure.sum() + legal_target_weighted.sum() + 1)\n",
    "\n",
    "        return 1 - dice\n",
    "\n",
    "\n",
    "print('AlignedGrowthLoss defined (replaces Dice + AccessReach + ElevatedBonus)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONSTRAINT 3: ACCESS CONNECTIVITY LOSS (NEW - REPLACES STREET CONN)\n",
    "# ============================================================\n",
    "\n",
    "class AccessConnectivityLoss(nn.Module):\n",
    "    \"\"\"Street connectivity seeded from access points.\n",
    "    \n",
    "    REPLACES: StreetConnectivityLoss\n",
    "    \n",
    "    Measures whether all access points are mutually reachable\n",
    "    through the void network, NOT just boundary-to-boundary.\n",
    "    \n",
    "    Key insight: A thin perimeter corridor no longer helps.\n",
    "    Connectivity is functional (access-to-access), not topological.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: dict, iterations: int = 32):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.street_levels = config['street_levels']\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        cfg = self.config\n",
    "        street_levels = self.street_levels\n",
    "\n",
    "        # Get relevant channels at street level\n",
    "        structure = state[:, cfg['ch_structure'], :street_levels, :, :]\n",
    "        existing = state[:, cfg['ch_existing'], :street_levels, :, :]\n",
    "        access = state[:, cfg['ch_access'], :street_levels, :, :]\n",
    "\n",
    "        # Void mask = not structure AND not existing buildings\n",
    "        void_mask = (1 - structure) * (1 - existing)\n",
    "\n",
    "        # Seed from ACCESS POINTS (not boundaries!)\n",
    "        # Dilate access slightly to ensure seed overlaps with void\n",
    "        access_seed = F.max_pool3d(access.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "        connected = access_seed * void_mask\n",
    "\n",
    "        # Flood fill through void\n",
    "        for _ in range(self.iterations):\n",
    "            dilated = F.max_pool3d(connected.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "            new_connected = torch.max(connected, dilated * void_mask)\n",
    "            if torch.allclose(connected, new_connected, atol=1e-5):\n",
    "                break\n",
    "            connected = new_connected\n",
    "\n",
    "        # Check: can we reach ALL access points from each other?\n",
    "        access_locations = (access > 0.5).float()\n",
    "        reachable = (connected * access_locations).sum()\n",
    "        total_access = access_locations.sum() + 1e-8\n",
    "\n",
    "        # Loss = fraction of access points NOT reachable from the flood\n",
    "        return 1 - (reachable / total_access)\n",
    "\n",
    "\n",
    "print('AccessConnectivityLoss defined (replaces StreetConnectivityLoss)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CONSTRAINT 4: LOAD PATH LOSS (NEW - REPLACES SUPPORT + CONNECTIVITY)\n# ============================================================\n\nclass LoadPathLoss(nn.Module):\n    \"\"\"Structural load path connectivity.\n    \n    REPLACES: SupportRatioLoss, ConnectivityLoss\n    \n    Elevated mass must be connected to ground support (anchors + buildings)\n    through continuous structure - not just co-existing.\n    \n    Key insight: Mass statistics can be gamed. Load paths cannot.\n    This traces actual structural paths, not just counts voxels.\n    \"\"\"\n\n    def __init__(self, config: dict, iterations: int = 32):\n        super().__init__()\n        self.config = config\n        self.street_levels = config['street_levels']\n        self.iterations = iterations\n\n    def forward(self, state: torch.Tensor) -> torch.Tensor:\n        cfg = self.config\n        street_levels = self.street_levels\n        G = cfg['grid_size']\n\n        structure = state[:, cfg['ch_structure']]\n        existing = state[:, cfg['ch_existing']]\n        anchors = state[:, cfg['ch_anchors']]\n\n        # Valid support = buildings + anchors (at street level only)\n        # NOT free ground! This is the key fix.\n        # Use cat instead of in-place assignment to avoid gradient issues\n        B = state.shape[0]\n        device = state.device\n        \n        # At street level: support = max(existing, anchors)\n        support_street = torch.max(\n            existing[:, :street_levels, :, :],\n            anchors[:, :street_levels, :, :]\n        )\n        \n        # Above street level: support = existing buildings only\n        support_above = existing[:, street_levels:, :, :]\n        \n        # Concatenate to form full support tensor (no in-place ops)\n        support = torch.cat([support_street, support_above], dim=1)\n\n        # Flood fill through STRUCTURE from support\n        # This traces load paths, not just checks adjacency\n        connected = support.clone()\n        \n        # Use soft threshold for gradient flow\n        struct_soft = torch.sigmoid(10 * (structure - 0.3))\n\n        for _ in range(self.iterations):\n            dilated = F.max_pool3d(connected.unsqueeze(1), 3, 1, 1).squeeze(1)\n            # Can only spread through structure\n            new_connected = torch.max(connected, dilated * struct_soft)\n            if torch.allclose(connected, new_connected, atol=1e-5):\n                break\n            connected = new_connected\n\n        # Elevated structure = structure at z >= street_levels\n        elevated = structure[:, street_levels:, :, :]\n        elevated_connected = connected[:, street_levels:, :, :]\n\n        # Loss = elevated structure NOT connected to support via load path\n        unsupported = elevated * (1 - elevated_connected)\n\n        return unsupported.sum() / (elevated.sum() + 1e-8)\n\n\nprint('LoadPathLoss defined (replaces SupportRatio + Connectivity)')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONSTRAINT 5: CANTILEVER LOSS (UNCHANGED)\n",
    "# ============================================================\n",
    "\n",
    "class CantileverLoss(nn.Module):\n",
    "    \"\"\"Limit horizontal overhangs.\n",
    "    \n",
    "    Each voxel must have support within N voxels below.\n",
    "    Works together with LoadPath:\n",
    "    - Cantilever: local support requirement\n",
    "    - LoadPath: global path to ground requirement\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_overhang: int = 3, threshold: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.max_overhang = max_overhang\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n",
    "        B, D, H, W = structure.shape\n",
    "        N = self.max_overhang\n",
    "        total_loss = 0.0\n",
    "        count = 0\n",
    "\n",
    "        for z in range(N, D):\n",
    "            layer = structure[:, z]\n",
    "            support_volume = structure[:, max(0, z-N):z]\n",
    "            support_max = support_volume.max(dim=1)[0]\n",
    "            support_dilated = F.max_pool2d(support_max.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "            has_support = torch.sigmoid(10 * (support_dilated - self.threshold))\n",
    "            unsupported = layer * (1.0 - has_support)\n",
    "            total_loss += unsupported.mean()\n",
    "            count += 1\n",
    "\n",
    "        return total_loss / max(1, count)\n",
    "\n",
    "\n",
    "print('CantileverLoss defined (unchanged)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONSTRAINT 6: SPARSITY LOSS (UNCHANGED)\n",
    "# ============================================================\n",
    "\n",
    "class SparsityLoss(nn.Module):\n",
    "    \"\"\"Limit total volume (5-15% fill ratio).\"\"\"\n",
    "\n",
    "    def __init__(self, max_ratio: float = 0.15, min_ratio: float = 0.05, \n",
    "                 under_coef: float = 3.0):\n",
    "        super().__init__()\n",
    "        self.max_ratio = max_ratio\n",
    "        self.min_ratio = min_ratio\n",
    "        self.under_coef = under_coef\n",
    "\n",
    "    def forward(self, structure: torch.Tensor, available: torch.Tensor) -> torch.Tensor:\n",
    "        ratio = structure.sum() / (available.sum() + 1e-8)\n",
    "        over_penalty = F.relu(ratio - self.max_ratio)\n",
    "        under_penalty = self.under_coef * F.relu(self.min_ratio - ratio)\n",
    "        return over_penalty + under_penalty\n",
    "\n",
    "\n",
    "print('SparsityLoss defined (unchanged)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# QUALITY LOSSES (REDUCED WEIGHTS)\n",
    "# ============================================================\n",
    "\n",
    "class DensityPenalty(nn.Module):\n",
    "    \"\"\"SIMP density penalty for binary outputs.\"\"\"\n",
    "    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n",
    "        return (structure * (1.0 - structure)).mean()\n",
    "\n",
    "\n",
    "class TotalVariation3D(nn.Module):\n",
    "    \"\"\"Total variation for smooth surfaces.\"\"\"\n",
    "    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n",
    "        tv_d = (structure[:, 1:, :, :] - structure[:, :-1, :, :]).abs().mean()\n",
    "        tv_h = (structure[:, :, 1:, :] - structure[:, :, :-1, :]).abs().mean()\n",
    "        tv_w = (structure[:, :, :, 1:] - structure[:, :, :, :-1]).abs().mean()\n",
    "        return tv_d + tv_h + tv_w\n",
    "\n",
    "\n",
    "print('Quality losses defined (with reduced weights)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all v2.0 losses\n",
    "print('Testing v2.0 loss functions...')\n",
    "print('='*60)\n",
    "\n",
    "scene_gen = UrbanSceneGenerator(CONFIG)\n",
    "scene, meta = scene_gen.generate('easy', device)\n",
    "\n",
    "# Add test structure\n",
    "test_state = scene.clone()\n",
    "# Legal elevated structure\n",
    "test_state[:, CONFIG['ch_structure'], 2:10, 10:20, 12:20] = 0.6\n",
    "# Some ground contact in anchors\n",
    "anchors = test_state[:, CONFIG['ch_anchors']]\n",
    "test_state[:, CONFIG['ch_structure'], 0:2, :, :] = 0.6 * anchors[:, 0:2, :, :]\n",
    "# Add some illegal ground structure for testing\n",
    "test_state[:, CONFIG['ch_structure'], 0, 15:18, 15:18] = 0.5\n",
    "\n",
    "structure = test_state[:, CONFIG['ch_structure']]\n",
    "existing = test_state[:, CONFIG['ch_existing']]\n",
    "available = 1.0 - existing\n",
    "\n",
    "# Test LocalLegalityLoss\n",
    "legality_loss = LocalLegalityLoss(CONFIG)\n",
    "legality_field = legality_loss.compute_legality_field(test_state)\n",
    "L_legality = legality_loss(test_state)\n",
    "print(f'LocalLegality: {L_legality.item():.4f}')\n",
    "print(f'  Legality field coverage: {legality_field.mean().item():.2%}')\n",
    "\n",
    "# Test AlignedGrowthLoss\n",
    "growth_loss = AlignedGrowthLoss(CONFIG)\n",
    "L_growth = growth_loss(test_state, legality_field)\n",
    "print(f'AlignedGrowth: {L_growth.item():.4f}')\n",
    "\n",
    "# Test AccessConnectivityLoss\n",
    "access_conn_loss = AccessConnectivityLoss(CONFIG)\n",
    "L_access_conn = access_conn_loss(test_state)\n",
    "print(f'AccessConnectivity: {L_access_conn.item():.4f}')\n",
    "\n",
    "# Test LoadPathLoss\n",
    "loadpath_loss = LoadPathLoss(CONFIG)\n",
    "L_loadpath = loadpath_loss(test_state)\n",
    "print(f'LoadPath: {L_loadpath.item():.4f}')\n",
    "\n",
    "# Test unchanged losses\n",
    "L_cant = CantileverLoss()(structure)\n",
    "print(f'Cantilever: {L_cant.item():.4f}')\n",
    "\n",
    "L_sparse = SparsityLoss()(structure, available)\n",
    "print(f'Sparsity: {L_sparse.item():.4f}')\n",
    "\n",
    "L_density = DensityPenalty()(structure)\n",
    "print(f'Density: {L_density.item():.4f}')\n",
    "\n",
    "L_tv = TotalVariation3D()(structure)\n",
    "print(f'TV: {L_tv.item():.4f}')\n",
    "\n",
    "print('='*60)\n",
    "print('All 8 v2.0 loss functions working')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 4. Evaluation Metrics (v2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_legality_compliance(state: torch.Tensor, config: dict) -> torch.Tensor:\n",
    "    \"\"\"Fraction of structure that is in legal zones.\n",
    "    Target: 100%\n",
    "    \"\"\"\n",
    "    legality_loss = LocalLegalityLoss(config)\n",
    "    legality_field = legality_loss.compute_legality_field(state)\n",
    "    structure = state[:, config['ch_structure']]\n",
    "    \n",
    "    legal_structure = (structure * legality_field).sum()\n",
    "    total_structure = structure.sum() + 1e-8\n",
    "    \n",
    "    return legal_structure / total_structure\n",
    "\n",
    "\n",
    "def compute_growth_alignment(state: torch.Tensor, config: dict) -> torch.Tensor:\n",
    "    \"\"\"Fraction of structure in legal target zones.\n",
    "    Target: >80%\n",
    "    \"\"\"\n",
    "    legality_loss = LocalLegalityLoss(config)\n",
    "    legality_field = legality_loss.compute_legality_field(state)\n",
    "    \n",
    "    structure = state[:, config['ch_structure']]\n",
    "    access = state[:, config['ch_access']]\n",
    "    existing = state[:, config['ch_existing']]\n",
    "    \n",
    "    # Access zone\n",
    "    access_zone = F.max_pool3d(access.unsqueeze(1), 11, 1, 5).squeeze(1)\n",
    "    available = 1.0 - existing\n",
    "    \n",
    "    # Legal target\n",
    "    legal_target = access_zone * legality_field * available\n",
    "    \n",
    "    # Structure in legal target\n",
    "    aligned = (structure * legal_target).sum()\n",
    "    total = structure.sum() + 1e-8\n",
    "    \n",
    "    return aligned / total\n",
    "\n",
    "\n",
    "def compute_load_path_compliance(state: torch.Tensor, config: dict) -> torch.Tensor:\n",
    "    \"\"\"Fraction of elevated structure connected via load path.\n",
    "    Target: >95%\n",
    "    \"\"\"\n",
    "    loadpath = LoadPathLoss(config)\n",
    "    loss = loadpath(state)\n",
    "    return 1.0 - loss\n",
    "\n",
    "\n",
    "def compute_access_reachability(state: torch.Tensor, config: dict) -> torch.Tensor:\n",
    "    \"\"\"Fraction of access points mutually reachable.\n",
    "    Target: >90%\n",
    "    \"\"\"\n",
    "    access_conn = AccessConnectivityLoss(config)\n",
    "    loss = access_conn(state)\n",
    "    return 1.0 - loss\n",
    "\n",
    "\n",
    "def compute_fill_ratio(state: torch.Tensor, config: dict) -> torch.Tensor:\n",
    "    \"\"\"Total volume ratio.\n",
    "    Target: 5-15%\n",
    "    \"\"\"\n",
    "    structure = state[:, config['ch_structure']]\n",
    "    existing = state[:, config['ch_existing']]\n",
    "    available = 1.0 - existing\n",
    "    return structure.sum() / (available.sum() + 1e-8)\n",
    "\n",
    "\n",
    "print('v2.0 evaluation metrics defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 5. Trainer (v2.0 Ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OntologyTrainer:\n",
    "    \"\"\"Step B v2.0 Trainer: Ontology-revised loss functions.\n",
    "    \n",
    "    Key changes from v1.x:\n",
    "    - LocalLegalityLoss replaces StreetVoid + Anchor (per-voxel, not global)\n",
    "    - AlignedGrowthLoss replaces Dice (growth aligned with legality)\n",
    "    - AccessConnectivityLoss replaces StreetConn (access-seeded, not boundary)\n",
    "    - LoadPathLoss replaces Support + Connectivity (causal paths, not mass)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: nn.Module, config: dict, device: str):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "\n",
    "        # v2.0 loss functions\n",
    "        self.legality_loss = LocalLegalityLoss(config)\n",
    "        self.growth_loss = AlignedGrowthLoss(config, dilation_radius=5)\n",
    "        self.access_conn_loss = AccessConnectivityLoss(config)\n",
    "        self.loadpath_loss = LoadPathLoss(config)\n",
    "        self.cantilever_loss = CantileverLoss()\n",
    "        self.sparsity_loss = SparsityLoss(max_ratio=0.15, min_ratio=0.05, under_coef=3.0)\n",
    "        self.density_loss = DensityPenalty()\n",
    "        self.tv_loss = TotalVariation3D()\n",
    "\n",
    "        # v2.0 weights (from CONSTRAINT_SPECS v3.0)\n",
    "        self.weights = {\n",
    "            'legality': 30.0,       # Per-voxel legality (replaces void + anchor)\n",
    "            'growth': 25.0,         # Aligned growth (replaces dice)\n",
    "            'loadpath': 20.0,       # Load path (replaces support + connectivity)\n",
    "            'access_conn': 15.0,    # Access connectivity (replaces street conn)\n",
    "            'sparsity': 15.0,       # Volume bounds\n",
    "            'cantilever': 5.0,      # Local overhang\n",
    "            'density': 3.0,         # Binary (reduced from 5)\n",
    "            'tv': 1.0,              # Smoothness\n",
    "        }\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=config['lr_initial'])\n",
    "        self.scene_gen = UrbanSceneGenerator(config)\n",
    "        self.history = []\n",
    "\n",
    "    def train_epoch(self, epoch: int) -> dict:\n",
    "        self.model.train()\n",
    "        cfg = self.config\n",
    "\n",
    "        # Generate batch\n",
    "        seeds = self.scene_gen.batch(cfg['difficulty'], cfg['batch_size'], self.device)\n",
    "        steps = random.randint(cfg['steps_min'], cfg['steps_max'])\n",
    "\n",
    "        # Forward pass\n",
    "        final = self.model(seeds, steps=steps)\n",
    "\n",
    "        # Extract channels\n",
    "        structure = final[:, cfg['ch_structure']]\n",
    "        existing = final[:, cfg['ch_existing']]\n",
    "        available = 1.0 - existing\n",
    "\n",
    "        # Compute legality field (used by multiple losses)\n",
    "        legality_field = self.legality_loss.compute_legality_field(final)\n",
    "\n",
    "        # Compute v2.0 losses\n",
    "        L_legality = self.legality_loss(final)\n",
    "        L_growth = self.growth_loss(final, legality_field)\n",
    "        L_access_conn = self.access_conn_loss(final)\n",
    "        L_loadpath = self.loadpath_loss(final)\n",
    "        L_cant = self.cantilever_loss(structure)\n",
    "        L_sparse = self.sparsity_loss(structure, available)\n",
    "        L_density = self.density_loss(structure)\n",
    "        L_tv = self.tv_loss(structure)\n",
    "\n",
    "        # Total loss with v2.0 weights\n",
    "        total_loss = (\n",
    "            self.weights['legality'] * L_legality +\n",
    "            self.weights['growth'] * L_growth +\n",
    "            self.weights['loadpath'] * L_loadpath +\n",
    "            self.weights['access_conn'] * L_access_conn +\n",
    "            self.weights['sparsity'] * L_sparse +\n",
    "            self.weights['cantilever'] * L_cant +\n",
    "            self.weights['density'] * L_density +\n",
    "            self.weights['tv'] * L_tv\n",
    "        )\n",
    "\n",
    "        # Backward pass\n",
    "        self.optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), cfg['grad_clip'])\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Compute metrics\n",
    "        with torch.no_grad():\n",
    "            legality_compliance = compute_legality_compliance(final, cfg).item()\n",
    "            growth_alignment = compute_growth_alignment(final, cfg).item()\n",
    "            loadpath_compliance = compute_load_path_compliance(final, cfg).item()\n",
    "            access_reachability = compute_access_reachability(final, cfg).item()\n",
    "            fill_ratio = compute_fill_ratio(final, cfg).item()\n",
    "\n",
    "        metrics = {\n",
    "            'epoch': epoch,\n",
    "            'total_loss': total_loss.item(),\n",
    "            # Losses\n",
    "            'L_legality': L_legality.item(),\n",
    "            'L_growth': L_growth.item(),\n",
    "            'L_loadpath': L_loadpath.item(),\n",
    "            'L_access_conn': L_access_conn.item(),\n",
    "            'L_sparsity': L_sparse.item(),\n",
    "            'L_cantilever': L_cant.item(),\n",
    "            'L_density': L_density.item(),\n",
    "            'L_tv': L_tv.item(),\n",
    "            # Metrics\n",
    "            'legality_compliance': legality_compliance,\n",
    "            'growth_alignment': growth_alignment,\n",
    "            'loadpath_compliance': loadpath_compliance,\n",
    "            'access_reachability': access_reachability,\n",
    "            'fill_ratio': fill_ratio,\n",
    "            'steps': steps,\n",
    "        }\n",
    "\n",
    "        self.history.append(metrics)\n",
    "        return metrics\n",
    "\n",
    "    def evaluate(self, n_samples: int = 20) -> dict:\n",
    "        self.model.eval()\n",
    "        cfg = self.config\n",
    "        results = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(n_samples):\n",
    "                scene, meta = self.scene_gen.generate(cfg['difficulty'], self.device)\n",
    "                grown = self.model.grow(scene, steps=50)\n",
    "                \n",
    "                results.append({\n",
    "                    'legality': compute_legality_compliance(grown, cfg).item(),\n",
    "                    'growth_align': compute_growth_alignment(grown, cfg).item(),\n",
    "                    'loadpath': compute_load_path_compliance(grown, cfg).item(),\n",
    "                    'access_reach': compute_access_reachability(grown, cfg).item(),\n",
    "                    'fill_ratio': compute_fill_ratio(grown, cfg).item(),\n",
    "                })\n",
    "\n",
    "        return {\n",
    "            'avg_legality': np.mean([r['legality'] for r in results]),\n",
    "            'avg_growth_alignment': np.mean([r['growth_align'] for r in results]),\n",
    "            'avg_loadpath': np.mean([r['loadpath'] for r in results]),\n",
    "            'avg_access_reach': np.mean([r['access_reach'] for r in results]),\n",
    "            'avg_fill_ratio': np.mean([r['fill_ratio'] for r in results]),\n",
    "            'n_samples': n_samples,\n",
    "        }\n",
    "\n",
    "    def save_checkpoint(self, path: str):\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'history': self.history,\n",
    "            'weights': self.weights,\n",
    "        }, path)\n",
    "        print(f'Checkpoint saved: {path}')\n",
    "\n",
    "\n",
    "print('OntologyTrainer defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 6. Visualization (Updated for v2.0 Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_v2_result(model, scene_gen, config, device, title='Result'):\n",
    "    \"\"\"Visualize grown structure with v2.0 metrics.\"\"\"\n",
    "    model.eval()\n",
    "    scene, meta = scene_gen.generate(config['difficulty'], device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        grown = model.grow(scene, steps=50)\n",
    "    \n",
    "    cfg = config\n",
    "    s = grown[0].cpu().numpy()\n",
    "    G = s.shape[1]\n",
    "    street_levels = cfg['street_levels']\n",
    "    \n",
    "    existing = s[cfg['ch_existing']] > 0.5\n",
    "    access = s[cfg['ch_access']] > 0.5\n",
    "    anchors = s[cfg['ch_anchors']] > 0.5\n",
    "    structure = s[cfg['ch_structure']] > 0.5\n",
    "    \n",
    "    # Compute legality field for visualization\n",
    "    legality_loss = LocalLegalityLoss(config)\n",
    "    legality_field = legality_loss.compute_legality_field(grown)[0].cpu().numpy()\n",
    "    \n",
    "    # Illegal structure = structure in illegal zones\n",
    "    illegal = structure & (legality_field < 0.5)\n",
    "    legal_struct = structure & (legality_field >= 0.5)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 5))\n",
    "    \n",
    "    # 3D View\n",
    "    ax1 = fig.add_subplot(141, projection='3d')\n",
    "    if existing.any():\n",
    "        ax1.voxels(existing.transpose(1,2,0), facecolors='gray', alpha=0.3)\n",
    "    if anchors.any():\n",
    "        anchor_disp = anchors.copy()\n",
    "        anchor_disp[street_levels:,:,:] = False\n",
    "        if anchor_disp.any():\n",
    "            ax1.voxels(anchor_disp.transpose(1,2,0), facecolors='yellow', alpha=0.3)\n",
    "    if access.any():\n",
    "        ax1.voxels(access.transpose(1,2,0), facecolors='green', alpha=0.9)\n",
    "    if illegal.any():\n",
    "        ax1.voxels(illegal.transpose(1,2,0), facecolors='red', alpha=0.9)\n",
    "    if legal_struct.any():\n",
    "        ax1.voxels(legal_struct.transpose(1,2,0), facecolors='royalblue', alpha=0.6)\n",
    "    ax1.set_xlabel('Y'); ax1.set_ylabel('X'); ax1.set_zlabel('Z')\n",
    "    ax1.set_title(f'{title} (3D)')\n",
    "    \n",
    "    # Ground level\n",
    "    ax2 = fig.add_subplot(142)\n",
    "    plan = np.zeros((G,G,3))\n",
    "    plan[existing[0,:,:]] = [0.5,0.5,0.5]\n",
    "    plan[anchors[0,:,:] & ~existing[0,:,:]] = [1,1,0.5]\n",
    "    plan[legal_struct.max(axis=0)] = [0.2,0.4,0.8]\n",
    "    plan[illegal[0,:,:]] = [1,0,0]\n",
    "    plan[access.max(axis=0)] = [0.2,0.8,0.2]\n",
    "    ax2.imshow(plan.transpose(1,0,2), origin='lower')\n",
    "    ax2.set_title('Ground Level')\n",
    "    \n",
    "    # Elevation\n",
    "    ax3 = fig.add_subplot(143)\n",
    "    elev = np.zeros((G,G,3))\n",
    "    elev[existing.max(axis=1)] = [0.5,0.5,0.5]\n",
    "    elev[legal_struct.max(axis=1)] = [0.2,0.4,0.8]\n",
    "    elev[illegal.max(axis=1)] = [1,0,0]\n",
    "    elev[access.max(axis=1)] = [0.2,0.8,0.2]\n",
    "    ax3.imshow(elev.transpose(1,0,2), origin='lower')\n",
    "    ax3.set_title('Elevation')\n",
    "    \n",
    "    # v2.0 Metrics\n",
    "    ax4 = fig.add_subplot(144)\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    legality = compute_legality_compliance(grown, config).item()\n",
    "    growth_align = compute_growth_alignment(grown, config).item()\n",
    "    loadpath = compute_load_path_compliance(grown, config).item()\n",
    "    access_reach = compute_access_reachability(grown, config).item()\n",
    "    fill = compute_fill_ratio(grown, config).item()\n",
    "    \n",
    "    status_legal = 'PASS' if legality > 0.99 else 'FAIL'\n",
    "    status_growth = 'PASS' if growth_align > 0.80 else 'FAIL'\n",
    "    status_load = 'PASS' if loadpath > 0.95 else 'FAIL'\n",
    "    status_access = 'PASS' if access_reach > 0.90 else 'FAIL'\n",
    "    status_fill = 'PASS' if 0.05 < fill < 0.15 else 'FAIL'\n",
    "    \n",
    "    text = f\"\"\"STEP B v2.0 METRICS\n",
    "\n",
    "Legality: {legality*100:.1f}% [{status_legal}]\n",
    "(Target: 100%)\n",
    "\n",
    "Growth Alignment: {growth_align*100:.1f}% [{status_growth}]\n",
    "(Target: >80%)\n",
    "\n",
    "Load Path: {loadpath*100:.1f}% [{status_load}]\n",
    "(Target: >95%)\n",
    "\n",
    "Access Reach: {access_reach*100:.1f}% [{status_access}]\n",
    "(Target: >90%)\n",
    "\n",
    "Fill Ratio: {fill*100:.1f}% [{status_fill}]\n",
    "(Target: 5-15%)\n",
    "\n",
    "---\n",
    "Legal struct: {legal_struct.sum():.0f}\n",
    "Illegal struct: {illegal.sum():.0f}\n",
    "\"\"\"\n",
    "    ax4.text(0.1, 0.9, text, transform=ax4.transAxes, fontsize=10,\n",
    "             verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return grown, meta\n",
    "\n",
    "\n",
    "def plot_v2_training_curves(history):\n",
    "    \"\"\"Plot v2.0 training curves.\"\"\"\n",
    "    epochs = [h['epoch'] for h in history]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20, 8))\n",
    "    \n",
    "    # Total loss\n",
    "    axes[0,0].plot(epochs, [h['total_loss'] for h in history])\n",
    "    axes[0,0].set_title('Total Loss')\n",
    "    axes[0,0].set_yscale('log')\n",
    "    \n",
    "    # Legality loss\n",
    "    axes[0,1].plot(epochs, [h['L_legality'] for h in history], 'r-')\n",
    "    axes[0,1].set_title('Legality Loss')\n",
    "    \n",
    "    # Growth loss\n",
    "    axes[0,2].plot(epochs, [h['L_growth'] for h in history], 'g-')\n",
    "    axes[0,2].set_title('Growth Loss')\n",
    "    \n",
    "    # LoadPath loss\n",
    "    axes[0,3].plot(epochs, [h['L_loadpath'] for h in history], 'purple')\n",
    "    axes[0,3].set_title('LoadPath Loss')\n",
    "    \n",
    "    # Legality compliance\n",
    "    axes[1,0].plot(epochs, [h['legality_compliance'] for h in history], 'r-')\n",
    "    axes[1,0].axhline(1.0, color='k', linestyle='--', label='Target')\n",
    "    axes[1,0].set_title('Legality Compliance')\n",
    "    axes[1,0].set_ylim(0, 1.1)\n",
    "    \n",
    "    # Growth alignment\n",
    "    axes[1,1].plot(epochs, [h['growth_alignment'] for h in history], 'g-')\n",
    "    axes[1,1].axhline(0.80, color='k', linestyle='--', label='Target')\n",
    "    axes[1,1].set_title('Growth Alignment')\n",
    "    axes[1,1].set_ylim(0, 1.1)\n",
    "    \n",
    "    # LoadPath compliance\n",
    "    axes[1,2].plot(epochs, [h['loadpath_compliance'] for h in history], 'purple')\n",
    "    axes[1,2].axhline(0.95, color='k', linestyle='--', label='Target')\n",
    "    axes[1,2].set_title('LoadPath Compliance')\n",
    "    axes[1,2].set_ylim(0, 1.1)\n",
    "    \n",
    "    # Fill ratio\n",
    "    axes[1,3].plot(epochs, [h['fill_ratio'] for h in history], 'orange')\n",
    "    axes[1,3].axhline(0.15, color='r', linestyle='--', label='Max')\n",
    "    axes[1,3].axhline(0.05, color='g', linestyle='--', label='Min')\n",
    "    axes[1,3].set_title('Fill Ratio')\n",
    "    axes[1,3].set_ylim(0, 0.25)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print('v2.0 visualization functions defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "model = UrbanPavilionNCA(CONFIG).to(device)\n",
    "trainer = OntologyTrainer(model, CONFIG, device)\n",
    "\n",
    "print(f'Model parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
    "print(f\"Difficulty: {CONFIG['difficulty']}\")\n",
    "print(f\"Epochs: {CONFIG['epochs']}\")\n",
    "print()\n",
    "print('v2.0 Loss Weights:')\n",
    "for name, weight in trainer.weights.items():\n",
    "    print(f'  {name}: {weight}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before training\n",
    "print('Before training:')\n",
    "visualize_v2_result(model, trainer.scene_gen, CONFIG, device, 'Before Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print('\\n' + '='*70)\n",
    "print('STEP B TRAINING v2.0: ONTOLOGY REVISION')\n",
    "print('='*70)\n",
    "print('NEW LOSSES:')\n",
    "print('  - LocalLegality (per-voxel, not global ratio)')\n",
    "print('  - AlignedGrowth (legal AND access zones)')\n",
    "print('  - AccessConnectivity (access-seeded, not boundary)')\n",
    "print('  - LoadPath (causal paths, not mass statistics)')\n",
    "print('='*70)\n",
    "\n",
    "for epoch in tqdm(range(CONFIG['epochs']), desc='Training'):\n",
    "    metrics = trainer.train_epoch(epoch)\n",
    "    \n",
    "    if epoch % CONFIG['log_every'] == 0:\n",
    "        tqdm.write(\n",
    "            f\"Epoch {epoch:4d} | Loss: {metrics['total_loss']:.2f} | \"\n",
    "            f\"Legal: {metrics['legality_compliance']*100:.0f}% | \"\n",
    "            f\"Fill: {metrics['fill_ratio']*100:.1f}% | \"\n",
    "            f\"Load: {metrics['loadpath_compliance']*100:.0f}%\"\n",
    "        )\n",
    "    \n",
    "    if epoch > 0 and epoch % CONFIG['viz_every'] == 0:\n",
    "        visualize_v2_result(model, trainer.scene_gen, CONFIG, device, f'Epoch {epoch}')\n",
    "    \n",
    "    if epoch > 0 and epoch % CONFIG['save_every'] == 0:\n",
    "        trainer.save_checkpoint(f\"{PROJECT_ROOT}/step_b/checkpoints/v2_epoch_{epoch}.pth\")\n",
    "\n",
    "print('='*70)\n",
    "print('Training complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot curves\n",
    "plot_v2_training_curves(trainer.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print('Evaluating...')\n",
    "eval_results = trainer.evaluate(n_samples=50)\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('STEP B v2.0 EVALUATION RESULTS')\n",
    "print('='*70)\n",
    "\n",
    "legal_pass = eval_results['avg_legality'] > 0.99\n",
    "growth_pass = eval_results['avg_growth_alignment'] > 0.80\n",
    "load_pass = eval_results['avg_loadpath'] > 0.95\n",
    "access_pass = eval_results['avg_access_reach'] > 0.90\n",
    "fill_pass = 0.05 < eval_results['avg_fill_ratio'] < 0.15\n",
    "\n",
    "print(f\"Legality:         {eval_results['avg_legality']*100:.1f}% {'PASS' if legal_pass else 'FAIL'} (target 100%)\")\n",
    "print(f\"Growth Alignment: {eval_results['avg_growth_alignment']*100:.1f}% {'PASS' if growth_pass else 'FAIL'} (target >80%)\")\n",
    "print(f\"Load Path:        {eval_results['avg_loadpath']*100:.1f}% {'PASS' if load_pass else 'FAIL'} (target >95%)\")\n",
    "print(f\"Access Reach:     {eval_results['avg_access_reach']*100:.1f}% {'PASS' if access_pass else 'FAIL'} (target >90%)\")\n",
    "print(f\"Fill Ratio:       {eval_results['avg_fill_ratio']*100:.1f}% {'PASS' if fill_pass else 'FAIL'} (target 5-15%)\")\n",
    "print('='*70)\n",
    "\n",
    "all_pass = legal_pass and growth_pass and load_pass and access_pass and fill_pass\n",
    "if all_pass:\n",
    "    print('\\nALL CRITERIA PASSED - Ready for medium difficulty')\n",
    "else:\n",
    "    print('\\nSome criteria not met - Analyze for potential new attractors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final visualizations\n",
    "print('\\nFinal Results:')\n",
    "for i in range(3):\n",
    "    visualize_v2_result(model, trainer.scene_gen, CONFIG, device, f'Final {i+1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "## 9. Save Final Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final\n",
    "trainer.save_checkpoint(f\"{PROJECT_ROOT}/step_b/checkpoints/v2_ontology_easy.pth\")\n",
    "\n",
    "# Save history\n",
    "with open(f\"{PROJECT_ROOT}/step_b/logs/v2_training_history.json\", 'w') as f:\n",
    "    json.dump(trainer.history, f)\n",
    "\n",
    "# Save eval\n",
    "with open(f\"{PROJECT_ROOT}/step_b/logs/v2_evaluation.json\", 'w') as f:\n",
    "    json.dump(eval_results, f, indent=2)\n",
    "\n",
    "print('\\nAll outputs saved')\n",
    "print(f\"Checkpoint: {PROJECT_ROOT}/step_b/checkpoints/v2_ontology_easy.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-35",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Step B Training v2.0 - Ontology Revision\n",
    "\n",
    "**Problem in v1.x:** Stable degenerate attractor formed because:\n",
    "- Global ratios could be gamed\n",
    "- Growth incentives conflicted with legality\n",
    "- Boundary-seeded connectivity allowed perimeter exploit\n",
    "- Mass-based structural metrics ignored load paths\n",
    "\n",
    "**Solution:** Complete loss ontology restructure.\n",
    "\n",
    "### Loss Changes\n",
    "\n",
    "| Old Loss | Problem | New Loss | Fix |\n",
    "|----------|---------|----------|-----|\n",
    "| StreetVoidLoss | Global ratio | LocalLegalityLoss | Per-voxel field |\n",
    "| AnchorBudgetLoss | Normalized | LocalLegalityLoss | Per-voxel field |\n",
    "| DiceLoss | Misaligned | AlignedGrowthLoss | Legal âˆ© Access |\n",
    "| StreetConnectivityLoss | Boundary seeds | AccessConnectivityLoss | Access seeds |\n",
    "| SupportRatioLoss | Mass statistics | LoadPathLoss | Causal paths |\n",
    "| ConnectivityLoss | Ground as support | LoadPathLoss | Buildings + anchors |\n",
    "\n",
    "### Weight Summary\n",
    "\n",
    "| Loss | Weight | Purpose |\n",
    "|------|--------|----------|\n",
    "| LocalLegality | 30.0 | Per-voxel legality |\n",
    "| AlignedGrowth | 25.0 | Growth in legal zones |\n",
    "| LoadPath | 20.0 | Structural causality |\n",
    "| AccessConnectivity | 15.0 | Functional circulation |\n",
    "| Sparsity | 15.0 | Volume bounds |\n",
    "| Cantilever | 5.0 | Local support |\n",
    "| Density | 3.0 | Binary output |\n",
    "| TV | 1.0 | Smoothness |\n",
    "\n",
    "### Success Criteria\n",
    "\n",
    "| Metric | Target |\n",
    "|--------|--------|\n",
    "| Legality | 100% |\n",
    "| Growth alignment | >80% |\n",
    "| Load path | >95% |\n",
    "| Access reach | >90% |\n",
    "| Fill ratio | 5-15% |\n",
    "\n",
    "---\n",
    "\n",
    "*NB02_AllConstraints_v2.0 - Ontology Revision - December 2025*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}