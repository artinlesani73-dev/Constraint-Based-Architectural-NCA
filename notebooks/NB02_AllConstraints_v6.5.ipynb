{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB02: All Constraints Training v6.5\n",
    "\n",
    "**Version:** 6.5 (2-Phase Curriculum + Extended Training)\n",
    "**Date:** December 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Why v6.3/v6.4 Had Phase Transition Problems\n",
    "\n",
    "| Problem | Root Cause | Result |\n",
    "|---------|------------|--------|\n",
    "| No growth 0-350 epochs | Competing losses created \"no growth\" attractor | Wasted 70% of training |\n",
    "| Sudden explosion at ~360 | Breaking out of attractor had no guidance | Chaotic uncontrolled growth |\n",
    "| Never learned discipline | Only 140 epochs after breakout | Grew OUTSIDE corridor |\n",
    "\n",
    "## v6.5 Solution: 2-Phase Curriculum Learning\n",
    "\n",
    "| Phase | Epochs | Spill Weight | Goal |\n",
    "|-------|--------|--------------|------|\n",
    "| Growth | 0-600 | 0 \u2192 10 | Learn to grow WITHOUT harsh penalties |\n",
    "| Sculpting | 600-1500 | 10 \u2192 50 (sqrt) | Guide existing growth INTO corridor |\n",
    "\n",
    "**Key Insight**: First let model learn HOW to grow, THEN teach WHERE to grow.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "PROJECT_ROOT = '/content/drive/MyDrive/Constraint-NCA'\n",
    "print(f'Project root: {PROJECT_ROOT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "from typing import Dict, Tuple, List\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import combinations\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base config\n",
    "with open(f'{PROJECT_ROOT}/config_step_b.json', 'r') as f:\n",
    "    CONFIG = json.load(f)\n",
    "\n",
    "# v6.5 CONFIGURATION - 2-PHASE CURRICULUM\n",
    "CONFIG.update({\n",
    "    # Extended training\n",
    "    'epochs': 1500,           # 3x longer than v6.3/v6.4\n",
    "    'steps_min': 30,\n",
    "    'steps_max': 50,\n",
    "    'difficulty': 'easy',\n",
    "    'log_every': 20,\n",
    "    'viz_every': 150,         # Less frequent viz for longer training\n",
    "    'save_every': 300,\n",
    "    \n",
    "    # Corridor parameters\n",
    "    'corridor_width': 3,\n",
    "    'max_thickness': 2,\n",
    "    'max_facade_contact': 0.15,\n",
    "    'vertical_envelope': 1,\n",
    "    'lr_initial': 5e-4,\n",
    "    \n",
    "    # v6.5 CURRICULUM PARAMETERS\n",
    "    'growth_phase_end': 600,      # End of growth phase\n",
    "    'sculpt_phase_end': 1500,     # End of sculpting phase (= total epochs)\n",
    "    'spill_weight_min': 0.0,      # Spill weight at epoch 0\n",
    "    'spill_weight_growth': 10.0,  # Spill weight at end of growth phase\n",
    "    'spill_weight_max': 50.0,     # Spill weight at end of sculpting phase\n",
    "})\n",
    "\n",
    "print('='*60)\n",
    "print('v6.5 Configuration: 2-PHASE CURRICULUM')\n",
    "print('='*60)\n",
    "print(f\"  epochs: {CONFIG['epochs']} (was 500)\")\n",
    "print(f\"  growth_phase: 0-{CONFIG['growth_phase_end']} (spill 0\u219210)\")\n",
    "print(f\"  sculpt_phase: {CONFIG['growth_phase_end']}-{CONFIG['sculpt_phase_end']} (spill 10\u219250)\")\n",
    "print('  Sculpting uses sqrt-weighted distance')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceive3D(nn.Module):\n",
    "    def __init__(self, n_channels: int = 8):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        sobel_x = self._create_sobel_kernel('x')\n",
    "        sobel_y = self._create_sobel_kernel('y')\n",
    "        sobel_z = self._create_sobel_kernel('z')\n",
    "        identity = self._create_identity_kernel()\n",
    "        kernels = torch.stack([identity, sobel_x, sobel_y, sobel_z], dim=0)\n",
    "        self.register_buffer('kernels', kernels)\n",
    "\n",
    "    def _create_sobel_kernel(self, direction: str) -> torch.Tensor:\n",
    "        derivative = torch.tensor([-1., 0., 1.])\n",
    "        smoothing = torch.tensor([1., 2., 1.])\n",
    "        if direction == 'x':\n",
    "            kernel = torch.einsum('i,j,k->ijk', smoothing, smoothing, derivative)\n",
    "        elif direction == 'y':\n",
    "            kernel = torch.einsum('i,j,k->ijk', smoothing, derivative, smoothing)\n",
    "        elif direction == 'z':\n",
    "            kernel = torch.einsum('i,j,k->ijk', derivative, smoothing, smoothing)\n",
    "        return kernel / 16.0\n",
    "\n",
    "    def _create_identity_kernel(self) -> torch.Tensor:\n",
    "        kernel = torch.zeros(3, 3, 3)\n",
    "        kernel[1, 1, 1] = 1.0\n",
    "        return kernel\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, C, D, H, W = x.shape\n",
    "        x_padded = F.pad(x, (1, 1, 1, 1, 1, 1), mode='replicate')\n",
    "        outputs = []\n",
    "        for k in range(4):\n",
    "            kernel = self.kernels[k:k+1].unsqueeze(0).expand(C, 1, 3, 3, 3)\n",
    "            out = F.conv3d(x_padded, kernel, padding=0, groups=C)\n",
    "            outputs.append(out)\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanPavilionNCA(nn.Module):\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        n_channels = config['n_channels']\n",
    "        hidden_dim = config['hidden_dim']\n",
    "        perception_dim = n_channels * 4\n",
    "        n_grown = config['n_grown']\n",
    "\n",
    "        self.perceive = Perceive3D(n_channels)\n",
    "        self.update_net = nn.Sequential(\n",
    "            nn.Conv3d(perception_dim, hidden_dim, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(hidden_dim, hidden_dim, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(hidden_dim, n_grown, 1),\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        gain = self.config['xavier_gain']\n",
    "        for m in self.update_net:\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=gain)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "        last_layer = self.update_net[-1]\n",
    "        with torch.no_grad():\n",
    "            last_layer.bias[0] = self.config['structure_bias']\n",
    "            last_layer.bias[1] = self.config['surface_bias']\n",
    "\n",
    "    def forward(self, state: torch.Tensor, steps: int = 1) -> torch.Tensor:\n",
    "        for _ in range(steps):\n",
    "            state = self._step(state)\n",
    "        return state\n",
    "\n",
    "    def _step(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        B, C, D, H, W = state.shape\n",
    "        cfg = self.config\n",
    "        perception = self.perceive(state)\n",
    "        delta = self.update_net(perception)\n",
    "\n",
    "        if self.training:\n",
    "            fire_mask = (torch.rand(B, 1, D, H, W, device=state.device) < cfg['fire_rate']).float()\n",
    "            delta = delta * fire_mask\n",
    "\n",
    "        grown_start = cfg['n_frozen']\n",
    "        grown_new = state[:, grown_start:] + cfg['update_scale'] * delta\n",
    "        grown_new = torch.clamp(grown_new, 0.0, 1.0)\n",
    "\n",
    "        existing = state[:, cfg['ch_existing']:cfg['ch_existing']+1]\n",
    "        available_mask = 1.0 - existing\n",
    "        struct_new = grown_new[:, 0:1] * available_mask\n",
    "        grown_masked = torch.cat([struct_new, grown_new[:, 1:]], dim=1)\n",
    "        return torch.cat([state[:, :grown_start], grown_masked], dim=1)\n",
    "\n",
    "    def grow(self, seed: torch.Tensor, steps: int = 50) -> torch.Tensor:\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.forward(seed, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrbanSceneGenerator:\n",
    "    def __init__(self, config: dict):\n",
    "        self.config = config\n",
    "        self.G = config['grid_size']\n",
    "        self.C = config['n_channels']\n",
    "\n",
    "    def generate(self, difficulty: str = 'easy', device: str = 'cuda') -> Tuple[torch.Tensor, dict]:\n",
    "        G = self.G\n",
    "        cfg = self.config\n",
    "        state = torch.zeros(1, self.C, G, G, G, device=device)\n",
    "        state[:, cfg['ch_ground'], 0, :, :] = 1.0\n",
    "\n",
    "        params = self._get_difficulty_params(difficulty)\n",
    "        building_info = self._place_buildings(state, params)\n",
    "        access_info = self._place_access_points(state, params, building_info)\n",
    "        self._generate_anchor_zones(state, params, building_info, access_info)\n",
    "        return state, {'difficulty': difficulty, 'buildings': building_info, 'access_points': access_info}\n",
    "\n",
    "    def _get_difficulty_params(self, difficulty: str) -> dict:\n",
    "        if difficulty == 'easy':\n",
    "            return {'n_buildings': 2, 'height_range': (12, 16), 'height_variance': False,\n",
    "                    'width_range': (8, 12), 'gap_width': random.randint(14, 18),\n",
    "                    'n_ground_access': 1, 'n_elevated_access': 1, 'anchor_budget': 0.10}\n",
    "        elif difficulty == 'medium':\n",
    "            return {'n_buildings': 2, 'height_range': (10, 20), 'height_variance': True,\n",
    "                    'width_range': (6, 10), 'gap_width': random.randint(10, 14),\n",
    "                    'n_ground_access': random.randint(1, 2), 'n_elevated_access': random.randint(1, 2),\n",
    "                    'anchor_budget': 0.07}\n",
    "        else:\n",
    "            return {'n_buildings': random.randint(2, 4), 'height_range': (8, 24), 'height_variance': True,\n",
    "                    'width_range': (5, 8), 'gap_width': random.randint(6, 10),\n",
    "                    'n_ground_access': random.randint(2, 3), 'n_elevated_access': random.randint(2, 3),\n",
    "                    'anchor_budget': 0.05}\n",
    "\n",
    "    def _place_buildings(self, state: torch.Tensor, params: dict) -> list:\n",
    "        G = self.G\n",
    "        ch = self.config['ch_existing']\n",
    "        buildings = []\n",
    "        gap_width = params['gap_width']\n",
    "        gap_center = G // 2\n",
    "\n",
    "        w1 = random.randint(*params['width_range'])\n",
    "        d1 = random.randint(G//2, G-2)\n",
    "        h1 = random.randint(*params['height_range'])\n",
    "        x1_end = gap_center - gap_width // 2\n",
    "        x1_start = max(0, x1_end - w1)\n",
    "        state[:, ch, :h1, :d1, x1_start:x1_end] = 1.0\n",
    "        buildings.append({'x': (x1_start, x1_end), 'y': (0, d1), 'z': (0, h1), 'gap_facing_x': x1_end, 'side': 'left'})\n",
    "\n",
    "        w2 = random.randint(*params['width_range'])\n",
    "        d2 = random.randint(G//2, G-2)\n",
    "        h2 = h1 if not params['height_variance'] else random.randint(*params['height_range'])\n",
    "        x2_start = gap_center + gap_width // 2\n",
    "        x2_end = min(G, x2_start + w2)\n",
    "        state[:, ch, :h2, :d2, x2_start:x2_end] = 1.0\n",
    "        buildings.append({'x': (x2_start, x2_end), 'y': (0, d2), 'z': (0, h2), 'gap_facing_x': x2_start, 'side': 'right'})\n",
    "        return buildings\n",
    "\n",
    "    def _place_access_points(self, state: torch.Tensor, params: dict, buildings: list) -> list:\n",
    "        G = self.G\n",
    "        ch = self.config['ch_access']\n",
    "        access_points = []\n",
    "        left_buildings = [b for b in buildings if b['side'] == 'left']\n",
    "        right_buildings = [b for b in buildings if b['side'] == 'right']\n",
    "        gap_x_min = max(b['gap_facing_x'] for b in left_buildings) if left_buildings else 0\n",
    "        gap_x_max = min(b['gap_facing_x'] for b in right_buildings) if right_buildings else G\n",
    "\n",
    "        for _ in range(params.get('n_ground_access', 1)):\n",
    "            x = random.randint(gap_x_min + 1, gap_x_max - 3)\n",
    "            y = random.randint(0, G - 3)\n",
    "            state[:, ch, 0:2, y:y+2, x:x+2] = 1.0\n",
    "            access_points.append({'x': x, 'y': y, 'z': 0, 'type': 'ground'})\n",
    "\n",
    "        for _ in range(params.get('n_elevated_access', 1)):\n",
    "            building = random.choice(buildings)\n",
    "            bz_max = building['z'][1]\n",
    "            is_left = building['side'] == 'left'\n",
    "            z = random.randint(3, max(4, bz_max - 2))\n",
    "            y = random.randint(building['y'][0], min(building['y'][1] - 2, building['y'][0] + G//3))\n",
    "            x = building['x'][1] if is_left else building['x'][0] - 2\n",
    "            x = max(0, min(G - 2, x))\n",
    "            state[:, ch, z:z+2, y:y+2, x:x+2] = 1.0\n",
    "            access_points.append({'x': x, 'y': y, 'z': z, 'type': 'elevated'})\n",
    "        return access_points\n",
    "\n",
    "    def _generate_anchor_zones(self, state: torch.Tensor, params: dict, buildings: list, access_points: list):\n",
    "        G = self.G\n",
    "        ch = self.config['ch_anchors']\n",
    "        sl = self.config['street_levels']\n",
    "        existing = state[:, self.config['ch_existing'], 0, :, :]\n",
    "        street_mask = 1.0 - existing\n",
    "        anchors = torch.zeros(1, 1, G, G, G, device=state.device)\n",
    "\n",
    "        for ap in access_points:\n",
    "            if ap['type'] == 'ground':\n",
    "                x, y = ap['x'], ap['y']\n",
    "                for z in range(sl):\n",
    "                    anchors[:, 0, z, max(0,y-2):min(G,y+4), max(0,x-2):min(G,x+4)] = 1.0\n",
    "\n",
    "        for building in buildings:\n",
    "            by_start, by_end = building['y']\n",
    "            gap_x = building['gap_facing_x']\n",
    "            is_left = building['side'] == 'left'\n",
    "            x_start = gap_x if is_left else gap_x - 1\n",
    "            x_end = gap_x + 1 if is_left else gap_x\n",
    "            for z in range(sl):\n",
    "                anchors[:, 0, z, by_start:min(by_start+4, by_end), max(0,x_start):min(G,x_end)] = 1.0\n",
    "\n",
    "        for z in range(sl):\n",
    "            anchors[:, 0, z, :, :] *= street_mask\n",
    "        state[:, ch:ch+1, :, :, :] = anchors\n",
    "\n",
    "    def batch(self, difficulty: str, batch_size: int, device: str) -> torch.Tensor:\n",
    "        return torch.cat([self.generate(difficulty, device)[0] for _ in range(batch_size)], dim=0)\n",
    "\n",
    "print('Core components defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Corridor + SDF Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_access_centroids(access_channel: torch.Tensor) -> List[Tuple[int, int, int]]:\n",
    "    binary = (access_channel > 0.5).float()\n",
    "    if binary.sum() == 0:\n",
    "        return []\n",
    "    centroids = []\n",
    "    positions = (binary > 0).nonzero(as_tuple=False)\n",
    "    if len(positions) == 0:\n",
    "        return []\n",
    "\n",
    "    used = set()\n",
    "    for idx in range(len(positions)):\n",
    "        if idx in used:\n",
    "            continue\n",
    "        pos = positions[idx]\n",
    "        cluster = [pos]\n",
    "        used.add(idx)\n",
    "        for idx2 in range(idx + 1, len(positions)):\n",
    "            if idx2 in used:\n",
    "                continue\n",
    "            if (pos - positions[idx2]).abs().sum().item() <= 4:\n",
    "                cluster.append(positions[idx2])\n",
    "                used.add(idx2)\n",
    "        cluster = torch.stack(cluster).float()\n",
    "        centroid = cluster.mean(dim=0).long()\n",
    "        centroids.append((centroid[0].item(), centroid[1].item(), centroid[2].item()))\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def compute_distance_field_3d(start_points: List[Tuple[int, int, int]],\n",
    "                               legal_mask: torch.Tensor, max_iters: int = 64) -> torch.Tensor:\n",
    "    D, H, W = legal_mask.shape\n",
    "    device = legal_mask.device\n",
    "    distance = torch.full((D, H, W), float('inf'), device=device)\n",
    "\n",
    "    for z, y, x in start_points:\n",
    "        if 0 <= z < D and 0 <= y < H and 0 <= x < W:\n",
    "            distance[z, y, x] = 0\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        dist_4d = distance.unsqueeze(0).unsqueeze(0)\n",
    "        expanded = -F.max_pool3d(-dist_4d, 3, 1, 1).squeeze(0).squeeze(0) + 1\n",
    "        new_distance = torch.where(legal_mask > 0.5, torch.min(distance, expanded), distance)\n",
    "        if torch.allclose(distance, new_distance, atol=1e-5):\n",
    "            break\n",
    "        distance = new_distance\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_corridor_and_sdf(seed_state: torch.Tensor, config: dict,\n",
    "                             corridor_width: int = 3, vertical_envelope: int = 1) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Compute corridor target AND signed distance field.\"\"\"\n",
    "    cfg = config\n",
    "    G = cfg['grid_size']\n",
    "    device = seed_state.device\n",
    "    B = seed_state.shape[0]\n",
    "    corridors = torch.zeros(B, G, G, G, device=device)\n",
    "    sdfs = torch.zeros(B, G, G, G, device=device)\n",
    "\n",
    "    for b in range(B):\n",
    "        access = seed_state[b, cfg['ch_access']]\n",
    "        existing = seed_state[b, cfg['ch_existing']]\n",
    "        legal_mask = 1.0 - existing\n",
    "        centroids = find_access_centroids(access)\n",
    "\n",
    "        if len(centroids) < 2:\n",
    "            dilated = F.max_pool3d(access.unsqueeze(0).unsqueeze(0),\n",
    "                                   2*corridor_width+1, 1, corridor_width)\n",
    "            corridor = dilated.squeeze() * legal_mask\n",
    "            corridors[b] = corridor\n",
    "            corridor_points = (corridor > 0.5).nonzero(as_tuple=False).tolist()\n",
    "            if corridor_points:\n",
    "                corridor_points = [(p[0], p[1], p[2]) for p in corridor_points]\n",
    "                dist_outside = compute_distance_field_3d(corridor_points, legal_mask)\n",
    "                sdfs[b] = dist_outside * (1 - corridor) - corridor\n",
    "            continue\n",
    "\n",
    "        corridor_mask = torch.zeros(G, G, G, device=device)\n",
    "        for i, j in combinations(range(len(centroids)), 2):\n",
    "            start, end = centroids[i], centroids[j]\n",
    "            dist_from_start = compute_distance_field_3d([start], legal_mask)\n",
    "            dist_from_end = compute_distance_field_3d([end], legal_mask)\n",
    "            total_dist = dist_from_start[end[0], end[1], end[2]]\n",
    "            if total_dist == float('inf'):\n",
    "                continue\n",
    "            path_cost = dist_from_start + dist_from_end\n",
    "            slack = corridor_width\n",
    "            on_path = (path_cost <= total_dist + slack).float()\n",
    "            corridor_mask = torch.max(corridor_mask, on_path)\n",
    "\n",
    "        if corridor_mask.sum() > 0:\n",
    "            corridor_4d = corridor_mask.unsqueeze(0).unsqueeze(0)\n",
    "            dilated = F.max_pool3d(corridor_4d, 2*corridor_width+1, 1, corridor_width)\n",
    "            corridor_dilated = dilated.squeeze()\n",
    "\n",
    "            if vertical_envelope > 0:\n",
    "                for z in range(G):\n",
    "                    z_min = max(0, z - vertical_envelope)\n",
    "                    z_max = min(G, z + vertical_envelope + 1)\n",
    "                    local_max = corridor_dilated[z_min:z_max].max(dim=0)[0]\n",
    "                    if local_max.any():\n",
    "                        corridor_dilated[z] = torch.max(corridor_dilated[z], local_max * 0.5)\n",
    "\n",
    "            corridor = corridor_dilated * legal_mask\n",
    "            corridors[b] = corridor\n",
    "\n",
    "            corridor_points = (corridor > 0.5).nonzero(as_tuple=False).tolist()\n",
    "            corridor_points = [(p[0], p[1], p[2]) for p in corridor_points]\n",
    "            \n",
    "            if corridor_points:\n",
    "                dist_to_corridor = compute_distance_field_3d(corridor_points, legal_mask)\n",
    "                dist_to_corridor = torch.clamp(dist_to_corridor, 0, G)\n",
    "                sdf = dist_to_corridor * (1 - corridor) - corridor * 1.0\n",
    "                sdfs[b] = sdf\n",
    "        else:\n",
    "            dilated = F.max_pool3d(access.unsqueeze(0).unsqueeze(0),\n",
    "                                   2*corridor_width+1, 1, corridor_width)\n",
    "            corridors[b] = dilated.squeeze() * legal_mask\n",
    "\n",
    "    return corridors, sdfs\n",
    "\n",
    "print('Corridor + SDF computation defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loss Functions (v6.5 with Progressive Spill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalLegalityLoss(nn.Module):\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.street_levels = config['street_levels']\n",
    "\n",
    "    def compute_legality_field(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        cfg = self.config\n",
    "        G = cfg['grid_size']\n",
    "        existing = state[:, cfg['ch_existing']]\n",
    "        anchors = state[:, cfg['ch_anchors']]\n",
    "        B = state.shape[0]\n",
    "        device = state.device\n",
    "\n",
    "        z_indices = torch.arange(G, device=device).view(1, G, 1, 1).expand(B, G, G, G)\n",
    "        above_street = (z_indices >= self.street_levels).float()\n",
    "        at_street = (z_indices < self.street_levels).float()\n",
    "        position_legality = above_street + at_street * anchors\n",
    "        return torch.clamp((1 - existing) * position_legality, 0, 1)\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        structure = state[:, self.config['ch_structure']]\n",
    "        legality = self.compute_legality_field(state)\n",
    "        illegal = structure * (1 - legality)\n",
    "        return illegal.sum() / (structure.sum() + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorridorCoverageLoss(nn.Module):\n",
    "    \"\"\"(A) Fill the corridor - POSITIVE incentive to grow.\"\"\"\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, structure: torch.Tensor, corridor_target: torch.Tensor) -> torch.Tensor:\n",
    "        unfilled = corridor_target * (1 - structure)\n",
    "        return unfilled.sum() / (corridor_target.sum() + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressiveSpillLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    v6.5: Progressive SDF-based spill loss.\n",
    "    \n",
    "    - Growth phase: use_sqrt=False, linear distance / 5\n",
    "    - Sculpting phase: use_sqrt=True, sqrt(distance) for harsher penalty\n",
    "    \n",
    "    This allows growth to happen first, then guides it.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, structure: torch.Tensor, sdf: torch.Tensor,\n",
    "                legality_field: torch.Tensor, use_sqrt: bool = False) -> torch.Tensor:\n",
    "        # SDF > 0 means outside corridor\n",
    "        distance_outside = F.relu(sdf)\n",
    "        \n",
    "        if use_sqrt:\n",
    "            # Sculpting phase: sqrt weighting (harsher on far voxels)\n",
    "            weighted_distance = torch.sqrt(distance_outside.clamp(min=1.0) / 5.0)\n",
    "        else:\n",
    "            # Growth phase: gentle linear weighting\n",
    "            weighted_distance = distance_outside / 5.0 + 1.0\n",
    "        \n",
    "        # Penalty = structure * distance_weight * legality\n",
    "        spill_penalty = structure * weighted_distance * legality_field * (sdf > 0).float()\n",
    "        \n",
    "        return spill_penalty.sum() / (structure.sum() + 1e-8)\n",
    "\n",
    "\n",
    "print('ProgressiveSpillLoss: uses sqrt in sculpting phase for harsher gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroundOpennessLoss(nn.Module):\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.sl = config['street_levels']\n",
    "\n",
    "    def forward(self, structure: torch.Tensor, corridor_target: torch.Tensor,\n",
    "                legality_field: torch.Tensor) -> torch.Tensor:\n",
    "        ground_struct = structure[:, :self.sl, :, :]\n",
    "        ground_corr = corridor_target[:, :self.sl, :, :]\n",
    "        ground_legal = legality_field[:, :self.sl, :, :]\n",
    "        unnecessary = ground_struct * (1 - ground_corr) * ground_legal\n",
    "        return unnecessary.sum() / (ground_struct.sum() + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThicknessLoss(nn.Module):\n",
    "    def __init__(self, max_thickness: int = 2):\n",
    "        super().__init__()\n",
    "        self.max_thickness = max_thickness\n",
    "\n",
    "    def erode_3d(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_4d = x.unsqueeze(1) if x.dim() == 4 else x.unsqueeze(0).unsqueeze(0)\n",
    "        eroded = -F.max_pool3d(-x_4d, 3, 1, 1)\n",
    "        return eroded.squeeze(1) if x.dim() == 4 else eroded.squeeze(0).squeeze(0)\n",
    "\n",
    "    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n",
    "        soft = torch.sigmoid(10 * (structure - 0.3))\n",
    "        core = soft\n",
    "        for _ in range(self.max_thickness):\n",
    "            core = self.erode_3d(core)\n",
    "        return core.sum() / (soft.sum() + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparsityLoss(nn.Module):\n",
    "    \"\"\"Encourages structure to stay within fill ratio bounds.\"\"\"\n",
    "\n",
    "    def __init__(self, max_ratio: float = 0.15, min_ratio: float = 0.05):\n",
    "        super().__init__()\n",
    "        self.max_ratio = max_ratio\n",
    "        self.min_ratio = min_ratio\n",
    "\n",
    "    def forward(self, structure: torch.Tensor, available: torch.Tensor) -> torch.Tensor:\n",
    "        ratio = structure.sum() / (available.sum() + 1e-8)\n",
    "        \n",
    "        # Over-fill penalty\n",
    "        over = F.relu(ratio - self.max_ratio)\n",
    "        over_penalty = over * 50\n",
    "        \n",
    "        # Under-fill penalty (force minimum growth)\n",
    "        under = F.relu(self.min_ratio - ratio)\n",
    "        under_penalty = under * 20.0\n",
    "        \n",
    "        return over_penalty + under_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacadeContactLoss(nn.Module):\n",
    "    def __init__(self, config: dict, max_contact: float = 0.15):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.max_contact = max_contact\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        cfg = self.config\n",
    "        structure = state[:, cfg['ch_structure']]\n",
    "        existing = state[:, cfg['ch_existing']]\n",
    "        dilated = F.max_pool3d(existing.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "        facade = torch.clamp(dilated - existing, 0, 1)\n",
    "        contact = (structure * facade).sum() / (structure.sum() + 1e-8)\n",
    "        return F.relu(contact - self.max_contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccessConnectivityLoss(nn.Module):\n",
    "    def __init__(self, config: dict, iterations: int = 32):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.sl = config['street_levels']\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        cfg = self.config\n",
    "        structure = state[:, cfg['ch_structure'], :self.sl, :, :]\n",
    "        existing = state[:, cfg['ch_existing'], :self.sl, :, :]\n",
    "        access = state[:, cfg['ch_access'], :self.sl, :, :]\n",
    "\n",
    "        void = (1 - structure) * (1 - existing)\n",
    "        seed = F.max_pool3d(access.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "        connected = seed * void\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            dilated = F.max_pool3d(connected.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "            new_connected = torch.max(connected, dilated * void)\n",
    "            if torch.allclose(connected, new_connected, atol=1e-5):\n",
    "                break\n",
    "            connected = new_connected\n",
    "\n",
    "        access_locs = (access > 0.5).float()\n",
    "        reachable = (connected * access_locs).sum()\n",
    "        return 1 - (reachable / (access_locs.sum() + 1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadPathLoss(nn.Module):\n",
    "    def __init__(self, config: dict, iterations: int = 32):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.sl = config['street_levels']\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        cfg = self.config\n",
    "        structure = state[:, cfg['ch_structure']]\n",
    "        existing = state[:, cfg['ch_existing']]\n",
    "        anchors = state[:, cfg['ch_anchors']]\n",
    "\n",
    "        support_street = torch.max(existing[:, :self.sl], anchors[:, :self.sl])\n",
    "        support = torch.cat([support_street, existing[:, self.sl:]], dim=1)\n",
    "\n",
    "        connected = support.clone()\n",
    "        soft = torch.sigmoid(10 * (structure - 0.3))\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            dilated = F.max_pool3d(connected.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "            new_connected = torch.max(connected, dilated * soft)\n",
    "            if torch.allclose(connected, new_connected, atol=1e-5):\n",
    "                break\n",
    "            connected = new_connected\n",
    "\n",
    "        elevated = structure[:, self.sl:]\n",
    "        unsupported = elevated * (1 - connected[:, self.sl:])\n",
    "        return unsupported.sum() / (elevated.sum() + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CantileverLoss(nn.Module):\n",
    "    def __init__(self, max_overhang: int = 3):\n",
    "        super().__init__()\n",
    "        self.N = max_overhang\n",
    "\n",
    "    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n",
    "        B, D, H, W = structure.shape\n",
    "        total = 0.0\n",
    "        count = 0\n",
    "        for z in range(self.N, D):\n",
    "            layer = structure[:, z]\n",
    "            support = structure[:, max(0, z-self.N):z].max(dim=1)[0]\n",
    "            support_d = F.max_pool2d(support.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "            has_support = torch.sigmoid(10 * (support_d - 0.3))\n",
    "            unsupported = layer * (1 - has_support)\n",
    "            total += unsupported.mean()\n",
    "            count += 1\n",
    "        return total / max(1, count)\n",
    "\n",
    "\n",
    "class DensityPenalty(nn.Module):\n",
    "    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n",
    "        return (structure * (1 - structure)).mean()\n",
    "\n",
    "\n",
    "class TotalVariation3D(nn.Module):\n",
    "    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n",
    "        return (structure[:, 1:] - structure[:, :-1]).abs().mean() + \\\n",
    "               (structure[:, :, 1:] - structure[:, :, :-1]).abs().mean() + \\\n",
    "               (structure[:, :, :, 1:] - structure[:, :, :, :-1]).abs().mean()\n",
    "\n",
    "\n",
    "print('All losses defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_legality(state, config):\n",
    "    leg = LocalLegalityLoss(config)\n",
    "    field = leg.compute_legality_field(state)\n",
    "    struct = state[:, config['ch_structure']]\n",
    "    return (struct * field).sum() / (struct.sum() + 1e-8)\n",
    "\n",
    "def compute_coverage(struct, corridor):\n",
    "    return (struct * corridor).sum() / (corridor.sum() + 1e-8)\n",
    "\n",
    "def compute_spill(struct, corridor, legality):\n",
    "    outside = struct * (1 - corridor) * legality\n",
    "    return outside.sum() / (struct.sum() + 1e-8)\n",
    "\n",
    "def compute_thickness(state, config):\n",
    "    struct = state[:, config['ch_structure']]\n",
    "    loss = ThicknessLoss(config.get('max_thickness', 2))\n",
    "    return 1.0 - loss(struct).item()\n",
    "\n",
    "def compute_fill(state, config):\n",
    "    struct = state[:, config['ch_structure']]\n",
    "    existing = state[:, config['ch_existing']]\n",
    "    available = 1.0 - existing\n",
    "    return struct.sum() / (available.sum() + 1e-8)\n",
    "\n",
    "def compute_loadpath(state, config):\n",
    "    return 1.0 - LoadPathLoss(config)(state)\n",
    "\n",
    "def compute_access_reach(state, config):\n",
    "    return 1.0 - AccessConnectivityLoss(config)(state)\n",
    "\n",
    "def compute_facade(state, config):\n",
    "    struct = state[:, config['ch_structure']]\n",
    "    existing = state[:, config['ch_existing']]\n",
    "    dilated = F.max_pool3d(existing.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "    facade = torch.clamp(dilated - existing, 0, 1)\n",
    "    return (struct * facade).sum() / (struct.sum() + 1e-8)\n",
    "\n",
    "print('Metrics defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Trainer v6.5 (2-Phase Curriculum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerV65:\n",
    "    \"\"\"\n",
    "    v6.5 Trainer with 2-PHASE CURRICULUM LEARNING.\n",
    "    \n",
    "    Phase 1 (Growth): epochs 0-600\n",
    "      - Spill weight: 0 -> 10 (gentle, allow exploration)\n",
    "      - Focus: Learn HOW to grow structure\n",
    "    \n",
    "    Phase 2 (Sculpting): epochs 600-1500\n",
    "      - Spill weight: 10 -> 50 with sqrt distance\n",
    "      - Focus: Guide growth INTO corridor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: nn.Module, config: dict, device: str):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "\n",
    "        self.legality_loss = LocalLegalityLoss(config)\n",
    "        self.coverage_loss = CorridorCoverageLoss(config)\n",
    "        self.spill_loss = ProgressiveSpillLoss(config)\n",
    "        self.ground_loss = GroundOpennessLoss(config)\n",
    "        self.thickness_loss = ThicknessLoss(config.get('max_thickness', 2))\n",
    "        self.sparsity_loss = SparsityLoss()\n",
    "        self.facade_loss = FacadeContactLoss(config)\n",
    "        self.access_loss = AccessConnectivityLoss(config)\n",
    "        self.loadpath_loss = LoadPathLoss(config)\n",
    "        self.cantilever_loss = CantileverLoss()\n",
    "        self.density_loss = DensityPenalty()\n",
    "        self.tv_loss = TotalVariation3D()\n",
    "\n",
    "        # Base weights (spill weight is dynamic)\n",
    "        self.weights = {\n",
    "            'legality': 30.0,\n",
    "            'coverage': 45.0,\n",
    "            'ground': 10.0,\n",
    "            'thickness': 15.0,\n",
    "            'sparsity': 30.0,\n",
    "            'facade': 8.0,\n",
    "            'access': 15.0,\n",
    "            'loadpath': 8.0,\n",
    "            'cantilever': 5.0,\n",
    "            'density': 3.0,\n",
    "            'tv': 1.0,\n",
    "        }\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=config['lr_initial'])\n",
    "        self.scene_gen = UrbanSceneGenerator(config)\n",
    "        self.history = []\n",
    "\n",
    "    def get_spill_weight(self, epoch: int) -> float:\n",
    "        \"\"\"\n",
    "        Progressive spill weight based on training phase.\n",
    "        \n",
    "        Growth phase (0 -> growth_phase_end):\n",
    "            weight: spill_weight_min -> spill_weight_growth\n",
    "        \n",
    "        Sculpting phase (growth_phase_end -> sculpt_phase_end):\n",
    "            weight: spill_weight_growth -> spill_weight_max\n",
    "        \"\"\"\n",
    "        cfg = self.config\n",
    "        g_end = cfg['growth_phase_end']\n",
    "        s_end = cfg['sculpt_phase_end']\n",
    "        w_min = cfg['spill_weight_min']\n",
    "        w_growth = cfg['spill_weight_growth']\n",
    "        w_max = cfg['spill_weight_max']\n",
    "        \n",
    "        if epoch < g_end:\n",
    "            # Growth phase: 0 -> 10\n",
    "            progress = epoch / g_end\n",
    "            return w_min + (w_growth - w_min) * progress\n",
    "        else:\n",
    "            # Sculpting phase: 10 -> 50\n",
    "            progress = min(1.0, (epoch - g_end) / (s_end - g_end))\n",
    "            return w_growth + (w_max - w_growth) * progress\n",
    "\n",
    "    def is_sculpting_phase(self, epoch: int) -> bool:\n",
    "        \"\"\"Returns True if we're in the sculpting phase.\"\"\"\n",
    "        return epoch >= self.config['growth_phase_end']\n",
    "\n",
    "    def train_epoch(self, epoch: int) -> dict:\n",
    "        self.model.train()\n",
    "        cfg = self.config\n",
    "\n",
    "        seeds = self.scene_gen.batch(cfg['difficulty'], cfg['batch_size'], self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            corridor, sdf = compute_corridor_and_sdf(\n",
    "                seeds, cfg,\n",
    "                corridor_width=cfg.get('corridor_width', 3),\n",
    "                vertical_envelope=cfg.get('vertical_envelope', 1)\n",
    "            )\n",
    "\n",
    "        steps = random.randint(cfg['steps_min'], cfg['steps_max'])\n",
    "        final = self.model(seeds, steps=steps)\n",
    "\n",
    "        struct = final[:, cfg['ch_structure']]\n",
    "        existing = final[:, cfg['ch_existing']]\n",
    "        available = 1.0 - existing\n",
    "        legality_field = self.legality_loss.compute_legality_field(final)\n",
    "\n",
    "        # Get current spill weight and phase\n",
    "        spill_weight = self.get_spill_weight(epoch)\n",
    "        use_sqrt = self.is_sculpting_phase(epoch)\n",
    "\n",
    "        L = {\n",
    "            'legality': self.legality_loss(final),\n",
    "            'coverage': self.coverage_loss(struct, corridor),\n",
    "            'spill': self.spill_loss(struct, sdf, legality_field, use_sqrt=use_sqrt),\n",
    "            'ground': self.ground_loss(struct, corridor, legality_field),\n",
    "            'thickness': self.thickness_loss(struct),\n",
    "            'sparsity': self.sparsity_loss(struct, available),\n",
    "            'facade': self.facade_loss(final),\n",
    "            'access': self.access_loss(final),\n",
    "            'loadpath': self.loadpath_loss(final),\n",
    "            'cantilever': self.cantilever_loss(struct),\n",
    "            'density': self.density_loss(struct),\n",
    "            'tv': self.tv_loss(struct),\n",
    "        }\n",
    "\n",
    "        # Apply weights (spill weight is dynamic)\n",
    "        total = spill_weight * L['spill']\n",
    "        for k, v in L.items():\n",
    "            if k != 'spill':\n",
    "                total += self.weights[k] * v\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        total.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), cfg['grad_clip'])\n",
    "        self.optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            corridor_vol = corridor.sum().item() / (cfg['grid_size']**3 * cfg['batch_size'])\n",
    "            phase = 'SCULPT' if use_sqrt else 'GROWTH'\n",
    "            metrics = {\n",
    "                'epoch': epoch,\n",
    "                'total_loss': total.item(),\n",
    "                'coverage': compute_coverage(struct, corridor).item(),\n",
    "                'spill': compute_spill(struct, corridor, legality_field).item(),\n",
    "                'spill_weight': spill_weight,\n",
    "                'spill_loss': L['spill'].item(),\n",
    "                'thickness': compute_thickness(final, cfg),\n",
    "                'fill_ratio': compute_fill(final, cfg).item(),\n",
    "                'legality': compute_legality(final, cfg).item(),\n",
    "                'loadpath': compute_loadpath(final, cfg).item(),\n",
    "                'corridor_vol': corridor_vol,\n",
    "                'phase': phase,\n",
    "            }\n",
    "        self.history.append(metrics)\n",
    "        return metrics\n",
    "\n",
    "    def evaluate(self, n_samples: int = 50) -> dict:\n",
    "        self.model.eval()\n",
    "        cfg = self.config\n",
    "        results = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(n_samples):\n",
    "                scene, _ = self.scene_gen.generate(cfg['difficulty'], self.device)\n",
    "                corridor, _ = compute_corridor_and_sdf(\n",
    "                    scene, cfg,\n",
    "                    corridor_width=cfg.get('corridor_width', 3),\n",
    "                    vertical_envelope=cfg.get('vertical_envelope', 1)\n",
    "                )\n",
    "                grown = self.model.grow(scene, steps=50)\n",
    "                struct = grown[:, cfg['ch_structure']]\n",
    "                leg_field = self.legality_loss.compute_legality_field(grown)\n",
    "\n",
    "                results.append({\n",
    "                    'legality': compute_legality(grown, cfg).item(),\n",
    "                    'coverage': compute_coverage(struct, corridor).item(),\n",
    "                    'spill': compute_spill(struct, corridor, leg_field).item(),\n",
    "                    'thickness': compute_thickness(grown, cfg),\n",
    "                    'facade': compute_facade(grown, cfg).item(),\n",
    "                    'loadpath': compute_loadpath(grown, cfg).item(),\n",
    "                    'access': compute_access_reach(grown, cfg).item(),\n",
    "                    'fill_ratio': compute_fill(grown, cfg).item(),\n",
    "                })\n",
    "\n",
    "        return {f'avg_{k}': np.mean([r[k] for r in results]) for k in results[0].keys()}\n",
    "\n",
    "    def save(self, path: str):\n",
    "        torch.save({'model': self.model.state_dict(), 'history': self.history}, path)\n",
    "        print(f'Saved: {path}')\n",
    "\n",
    "\n",
    "print('TrainerV65 defined (2-Phase Curriculum)')\n",
    "print('  Growth phase: epochs 0-600 (spill 0->10, linear distance)')\n",
    "print('  Sculpting phase: epochs 600-1500 (spill 10->50, sqrt distance)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(model, scene_gen, config, device, title=''):\n",
    "    model.eval()\n",
    "    scene, _ = scene_gen.generate(config['difficulty'], device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        corridor, sdf = compute_corridor_and_sdf(\n",
    "            scene, config,\n",
    "            corridor_width=config.get('corridor_width', 3),\n",
    "            vertical_envelope=config.get('vertical_envelope', 1)\n",
    "        )\n",
    "        grown = model.grow(scene, steps=50)\n",
    "\n",
    "    cfg = config\n",
    "    s = grown[0].cpu().numpy()\n",
    "    G = s.shape[1]\n",
    "\n",
    "    existing = s[cfg['ch_existing']] > 0.5\n",
    "    access = s[cfg['ch_access']] > 0.5\n",
    "    structure = s[cfg['ch_structure']] > 0.5\n",
    "    corr = corridor[0].cpu().numpy() > 0.5\n",
    "    leg = LocalLegalityLoss(config).compute_legality_field(grown)[0].cpu().numpy()\n",
    "\n",
    "    in_corr = structure & corr & (leg >= 0.5)\n",
    "    outside = structure & ~corr & (leg >= 0.5)\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 4))\n",
    "\n",
    "    ax1 = fig.add_subplot(141, projection='3d')\n",
    "    if existing.any(): ax1.voxels(existing.transpose(1,2,0), facecolors='gray', alpha=0.3)\n",
    "    if access.any(): ax1.voxels(access.transpose(1,2,0), facecolors='green', alpha=0.9)\n",
    "    if outside.any(): ax1.voxels(outside.transpose(1,2,0), facecolors='orange', alpha=0.6)\n",
    "    if in_corr.any(): ax1.voxels(in_corr.transpose(1,2,0), facecolors='royalblue', alpha=0.6)\n",
    "    ax1.set_title(title)\n",
    "\n",
    "    ax2 = fig.add_subplot(142)\n",
    "    plan = np.zeros((G,G,3))\n",
    "    plan[existing[0]] = [0.5,0.5,0.5]\n",
    "    plan[corr[0] & ~existing[0]] = [0.8,0.9,1.0]\n",
    "    plan[in_corr.max(axis=0)] = [0.2,0.4,0.8]\n",
    "    plan[outside.max(axis=0)] = [1.0,0.6,0.2]\n",
    "    plan[access.max(axis=0)] = [0.2,0.8,0.2]\n",
    "    ax2.imshow(plan.transpose(1,0,2), origin='lower')\n",
    "    ax2.set_title('Ground')\n",
    "\n",
    "    ax3 = fig.add_subplot(143)\n",
    "    elev = np.zeros((G,G,3))\n",
    "    elev[existing.max(axis=1)] = [0.5,0.5,0.5]\n",
    "    elev[in_corr.max(axis=1)] = [0.2,0.4,0.8]\n",
    "    elev[outside.max(axis=1)] = [1.0,0.6,0.2]\n",
    "    elev[access.max(axis=1)] = [0.2,0.8,0.2]\n",
    "    ax3.imshow(elev.transpose(1,0,2), origin='lower')\n",
    "    ax3.set_title('Elevation')\n",
    "\n",
    "    ax4 = fig.add_subplot(144)\n",
    "    ax4.axis('off')\n",
    "    struct = grown[:, config['ch_structure']]\n",
    "    leg_f = LocalLegalityLoss(config).compute_legality_field(grown)\n",
    "\n",
    "    cov = compute_coverage(struct, corridor).item()\n",
    "    spl = compute_spill(struct, corridor, leg_f).item()\n",
    "    thk = compute_thickness(grown, config)\n",
    "    fill = compute_fill(grown, config).item()\n",
    "    corr_vol = corridor.sum().item() / (G**3)\n",
    "\n",
    "    txt = f\"\"\"METRICS (v6.5)\n",
    "Coverage: {cov*100:.1f}% {'OK' if cov>0.7 else 'LOW'}\n",
    "Spill: {spl*100:.1f}% {'OK' if spl<0.2 else 'HIGH'}\n",
    "Thickness: {thk*100:.1f}% {'OK' if thk>0.9 else 'LOW'}\n",
    "Fill: {fill*100:.1f}% {'OK' if 0.05<fill<0.15 else 'BAD'}\n",
    "---\n",
    "Corridor Vol: {corr_vol*100:.1f}%\n",
    "\"\"\"\n",
    "    ax4.text(0.1, 0.9, txt, transform=ax4.transAxes, fontsize=10, va='top', family='monospace')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return grown\n",
    "\n",
    "\n",
    "def plot_curves(history):\n",
    "    epochs = [h['epoch'] for h in history]\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20, 8))\n",
    "\n",
    "    # Row 1\n",
    "    axes[0,0].plot(epochs, [h['total_loss'] for h in history])\n",
    "    axes[0,0].set_title('Total Loss')\n",
    "    axes[0,0].set_yscale('log')\n",
    "\n",
    "    axes[0,1].plot(epochs, [h['coverage'] for h in history], 'b-')\n",
    "    axes[0,1].axhline(0.70, color='k', ls='--')\n",
    "    axes[0,1].set_title('Coverage (>70%)')\n",
    "    axes[0,1].set_ylim(0, 1.1)\n",
    "\n",
    "    axes[0,2].plot(epochs, [h['spill'] for h in history], 'orange')\n",
    "    axes[0,2].axhline(0.20, color='k', ls='--')\n",
    "    axes[0,2].set_title('Spill (<20%)')\n",
    "    axes[0,2].set_ylim(0, 1.1)\n",
    "\n",
    "    axes[0,3].plot(epochs, [h['spill_weight'] for h in history], 'r-')\n",
    "    axes[0,3].axvline(600, color='g', ls='--', label='Phase change')\n",
    "    axes[0,3].set_title('Spill Weight (progressive)')\n",
    "    axes[0,3].legend()\n",
    "\n",
    "    # Row 2\n",
    "    axes[1,0].plot(epochs, [h['thickness'] for h in history], 'purple')\n",
    "    axes[1,0].axhline(0.90, color='k', ls='--')\n",
    "    axes[1,0].set_title('Thickness (>90%)')\n",
    "    axes[1,0].set_ylim(0, 1.1)\n",
    "\n",
    "    axes[1,1].plot(epochs, [h['fill_ratio'] for h in history], 'g-')\n",
    "    axes[1,1].axhline(0.15, color='r', ls='--')\n",
    "    axes[1,1].axhline(0.05, color='g', ls='--')\n",
    "    axes[1,1].set_title('Fill (5-15%)')\n",
    "    axes[1,1].set_ylim(0, 0.3)\n",
    "\n",
    "    axes[1,2].plot(epochs, [h['spill_loss'] for h in history], 'r-')\n",
    "    axes[1,2].set_title('Spill Loss (raw)')\n",
    "\n",
    "    axes[1,3].plot(epochs, [h['legality'] for h in history], 'k-')\n",
    "    axes[1,3].axhline(0.99, color='g', ls='--')\n",
    "    axes[1,3].set_title('Legality (>99%)')\n",
    "    axes[1,3].set_ylim(0.9, 1.01)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print('Visualization defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UrbanPavilionNCA(CONFIG).to(device)\n",
    "trainer = TrainerV65(model, CONFIG, device)\n",
    "\n",
    "print(f'Parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
    "print()\n",
    "print('v6.5 2-PHASE CURRICULUM:')\n",
    "print(f\"  Total epochs: {CONFIG['epochs']}\")\n",
    "print(f\"  Growth phase: 0-{CONFIG['growth_phase_end']} (spill {CONFIG['spill_weight_min']}->{CONFIG['spill_weight_growth']})\")\n",
    "print(f\"  Sculpting phase: {CONFIG['growth_phase_end']}-{CONFIG['sculpt_phase_end']} (spill {CONFIG['spill_weight_growth']}->{CONFIG['spill_weight_max']}, sqrt)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(model, trainer.scene_gen, CONFIG, device, 'Before Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('v6.5 TRAINING - 2-PHASE CURRICULUM (1500 epochs)')\n",
    "print('='*70)\n",
    "print(f\"Phase 1 (GROWTH): epochs 0-{CONFIG['growth_phase_end']}\")\n",
    "print(f\"Phase 2 (SCULPT): epochs {CONFIG['growth_phase_end']}-{CONFIG['sculpt_phase_end']}\")\n",
    "print('='*70)\n",
    "\n",
    "for epoch in tqdm(range(CONFIG['epochs']), desc='Training'):\n",
    "    m = trainer.train_epoch(epoch)\n",
    "\n",
    "    if epoch % CONFIG['log_every'] == 0:\n",
    "        tqdm.write(\n",
    "            f\"E{epoch:4d} [{m['phase']:6s}] | Loss:{m['total_loss']:6.1f} | \"\n",
    "            f\"Cov:{m['coverage']*100:4.0f}% | \"\n",
    "            f\"Spl:{m['spill']*100:4.0f}% | \"\n",
    "            f\"Thk:{m['thickness']*100:4.0f}% | \"\n",
    "            f\"Fill:{m['fill_ratio']*100:5.1f}% | \"\n",
    "            f\"SpillW:{m['spill_weight']:.1f}\"\n",
    "        )\n",
    "\n",
    "    if epoch > 0 and epoch % CONFIG['viz_every'] == 0:\n",
    "        visualize(model, trainer.scene_gen, CONFIG, device, f'Epoch {epoch} ({m[\"phase\"]})')\n",
    "\n",
    "    if epoch > 0 and epoch % CONFIG['save_every'] == 0:\n",
    "        trainer.save(f\"{PROJECT_ROOT}/step_b/checkpoints/v65_epoch_{epoch}.pth\")\n",
    "\n",
    "print('='*70)\n",
    "print('Training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(trainer.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evaluating...')\n",
    "eval_results = trainer.evaluate(50)\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('STEP B v6.5 EVALUATION (2-Phase Curriculum)')\n",
    "print('='*60)\n",
    "\n",
    "targets = {\n",
    "    'legality': (0.99, '>'),\n",
    "    'coverage': (0.70, '>'),\n",
    "    'spill': (0.20, '<'),\n",
    "    'thickness': (0.90, '>'),\n",
    "    'facade': (0.15, '<'),\n",
    "    'loadpath': (0.95, '>'),\n",
    "    'access': (0.90, '>'),\n",
    "    'fill_ratio': (0.15, '<'),\n",
    "}\n",
    "\n",
    "for metric, (target, op) in targets.items():\n",
    "    val = eval_results[f'avg_{metric}']\n",
    "    if op == '>':\n",
    "        ok = val > target\n",
    "        print(f\"{metric:12s}: {val*100:5.1f}% {'PASS' if ok else 'FAIL'} (>{target*100:.0f}%)\")\n",
    "    else:\n",
    "        ok = val < target\n",
    "        print(f\"{metric:12s}: {val*100:5.1f}% {'PASS' if ok else 'FAIL'} (<{target*100:.0f}%)\")\n",
    "\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    visualize(model, trainer.scene_gen, CONFIG, device, f'Final {i+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save(f\"{PROJECT_ROOT}/step_b/checkpoints/v65_final.pth\")\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
