{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning for Porous, Lightweight Structures\n",
    "\n",
    "This notebook fine-tunes the trained v3.1 MODEL C to produce more porous, lightweight architectural structures.\n",
    "\n",
    "## Changes from Base Model\n",
    "1. Increased thickness penalty (30 → 50)\n",
    "2. Increased sparsity penalty (30 → 45)\n",
    "3. Added new PorosityLoss\n",
    "4. Reduced max_thickness (2 → 1)\n",
    "5. Lower fill ratio target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(project_root / 'deploy'))\n",
    "\n",
    "from model_utils import (\n",
    "    UrbanPavilionNCA, \n",
    "    UrbanSceneGenerator, \n",
    "    compute_corridor_target_v31,\n",
    "    LocalLegalityLoss\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_MODEL_DIR = Path('sel/MODEL C - Copy - no change')\n",
    "CONFIG_PATH = BASE_MODEL_DIR / 'config_step_b.json'\n",
    "CHECKPOINT_PATH = BASE_MODEL_DIR / 'v31_fixed_geometry.pth'\n",
    "\n",
    "# Output directory for fine-tuned model\n",
    "OUTPUT_DIR = Path('finetuned_porous')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Load config\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    CONFIG = json.load(f)\n",
    "\n",
    "# Fine-tuning modifications\n",
    "CONFIG['max_thickness'] = 1  # Reduced from 2\n",
    "CONFIG['fill_ratio_min'] = 0.03  # Reduced from 0.05\n",
    "CONFIG['fill_ratio_max'] = 0.10  # Reduced from 0.15\n",
    "CONFIG['lr_finetune'] = 0.0005  # Half of original\n",
    "\n",
    "print('Config loaded with fine-tuning modifications:')\n",
    "print(f\"  max_thickness: {CONFIG['max_thickness']} (was 2)\")\n",
    "print(f\"  fill_ratio: {CONFIG.get('fill_ratio_min', 0.03)}-{CONFIG.get('fill_ratio_max', 0.10)}\")\n",
    "print(f\"  lr_finetune: {CONFIG['lr_finetune']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "model = UrbanPavilionNCA(CONFIG).to(device)\n",
    "\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded checkpoint from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
    "else:\n",
    "    model.load_state_dict(checkpoint)\n",
    "    print('Loaded checkpoint (raw state dict)')\n",
    "\n",
    "print(f'Model parameters: {sum(p.numel() for p in model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Loss Functions\n",
    "\n",
    "We import existing losses and add the new PorosityLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ EXISTING LOSSES ============\n",
    "\n",
    "class CorridorCoverageLoss(nn.Module):\n",
    "    \"\"\"Penalize uncovered corridor voxels.\"\"\"\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, structure: torch.Tensor, corridor_target: torch.Tensor) -> torch.Tensor:\n",
    "        corridor_mask = corridor_target > 0.5\n",
    "        corridor_volume = corridor_mask.float().sum() + 1e-8\n",
    "        covered = (structure * corridor_mask.float()).sum()\n",
    "        coverage_ratio = covered / corridor_volume\n",
    "        return F.relu(0.7 - coverage_ratio)  # Target 70% coverage\n",
    "\n",
    "\n",
    "class CorridorSpillLoss(nn.Module):\n",
    "    \"\"\"Penalize structure outside corridor.\"\"\"\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, structure: torch.Tensor, corridor_target: torch.Tensor, \n",
    "                legality_field: torch.Tensor) -> torch.Tensor:\n",
    "        outside_corridor = (corridor_target < 0.5).float()\n",
    "        legal_outside = outside_corridor * legality_field\n",
    "        spill = (structure * legal_outside).sum()\n",
    "        total_structure = structure.sum() + 1e-8\n",
    "        return spill / total_structure\n",
    "\n",
    "\n",
    "class GroundOpennessLoss(nn.Module):\n",
    "    \"\"\"Keep ground level open except at anchors.\"\"\"\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.street_levels = config['street_levels']\n",
    "\n",
    "    def forward(self, structure: torch.Tensor, corridor_target: torch.Tensor,\n",
    "                legality_field: torch.Tensor) -> torch.Tensor:\n",
    "        ground = structure[:, :self.street_levels]\n",
    "        corridor_ground = corridor_target[:, :self.street_levels]\n",
    "        outside_corridor_ground = (corridor_ground < 0.5).float()\n",
    "        unwanted = ground * outside_corridor_ground\n",
    "        return unwanted.mean()\n",
    "\n",
    "\n",
    "class ThicknessLoss(nn.Module):\n",
    "    \"\"\"Penalize thick/bulky structures.\"\"\"\n",
    "    def __init__(self, max_thickness: int = 1):\n",
    "        super().__init__()\n",
    "        self.max_thickness = max_thickness\n",
    "\n",
    "    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n",
    "        binary = (structure > 0.5).float()\n",
    "        eroded = binary.clone()\n",
    "        for _ in range(self.max_thickness):\n",
    "            eroded = -F.max_pool3d(-eroded.unsqueeze(0).unsqueeze(0), 3, 1, 1).squeeze()\n",
    "        core = eroded\n",
    "        core_ratio = core.sum() / (binary.sum() + 1e-8)\n",
    "        return core_ratio\n",
    "\n",
    "\n",
    "class SparsityLossV31(nn.Module):\n",
    "    \"\"\"Squared sparsity penalty.\"\"\"\n",
    "    def __init__(self, target_ratio: float = 0.08, squared: bool = True):\n",
    "        super().__init__()\n",
    "        self.target = target_ratio\n",
    "        self.squared = squared\n",
    "\n",
    "    def forward(self, structure: torch.Tensor, available: torch.Tensor) -> torch.Tensor:\n",
    "        available_vol = available.sum() + 1e-8\n",
    "        filled = structure.sum()\n",
    "        ratio = filled / available_vol\n",
    "        excess = F.relu(ratio - self.target)\n",
    "        return excess ** 2 if self.squared else excess\n",
    "\n",
    "\n",
    "class DensityPenalty(nn.Module):\n",
    "    \"\"\"Overall density penalty.\"\"\"\n",
    "    def __init__(self, target: float = 0.05):\n",
    "        super().__init__()\n",
    "        self.target = target\n",
    "\n",
    "    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n",
    "        density = structure.mean()\n",
    "        return F.relu(density - self.target)\n",
    "\n",
    "\n",
    "class TotalVariation3D(nn.Module):\n",
    "    \"\"\"Smoothness regularization.\"\"\"\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        dz = torch.abs(x[:, 1:, :, :] - x[:, :-1, :, :]).mean()\n",
    "        dy = torch.abs(x[:, :, 1:, :] - x[:, :, :-1, :]).mean()\n",
    "        dx = torch.abs(x[:, :, :, 1:] - x[:, :, :, :-1]).mean()\n",
    "        return (dz + dy + dx) / 3\n",
    "\n",
    "\n",
    "class AccessConnectivityLoss(nn.Module):\n",
    "    \"\"\"Ensure access points are connected.\"\"\"\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        cfg = self.config\n",
    "        structure = state[:, cfg['ch_structure']]\n",
    "        access = state[:, cfg['ch_access']]\n",
    "        dilated = F.max_pool3d(structure.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "        connected = (access * dilated).sum()\n",
    "        total_access = access.sum() + 1e-8\n",
    "        return 1.0 - (connected / total_access)\n",
    "\n",
    "\n",
    "class LoadPathLoss(nn.Module):\n",
    "    \"\"\"Ensure vertical load paths.\"\"\"\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        cfg = self.config\n",
    "        structure = state[:, cfg['ch_structure']]\n",
    "        B, D, H, W = structure.shape\n",
    "        ground_support = structure[:, 0:1].clone()\n",
    "        supported = ground_support\n",
    "        for z in range(1, D):\n",
    "            below = F.max_pool3d(supported.unsqueeze(1), (1, 3, 3), 1, (0, 1, 1)).squeeze(1)\n",
    "            supported = torch.max(supported, torch.min(structure[:, z:z+1], below[:, -1:]))\n",
    "        unsupported = F.relu(structure - supported.expand_as(structure))\n",
    "        return unsupported.mean()\n",
    "\n",
    "\n",
    "class CantileverLoss(nn.Module):\n",
    "    \"\"\"Limit overhangs.\"\"\"\n",
    "    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n",
    "        below = F.pad(structure[:, :-1], (0, 0, 0, 0, 1, 0))\n",
    "        unsupported = F.relu(structure - below)\n",
    "        return unsupported.mean()\n",
    "\n",
    "\n",
    "class FacadeContactLoss(nn.Module):\n",
    "    \"\"\"Limit contact with existing buildings.\"\"\"\n",
    "    def __init__(self, config: dict, max_contact_ratio: float = 0.15):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.max_ratio = max_contact_ratio\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        cfg = self.config\n",
    "        structure = state[:, cfg['ch_structure']]\n",
    "        existing = state[:, cfg['ch_existing']]\n",
    "        dilated_existing = F.max_pool3d(existing.unsqueeze(1), 3, 1, 1).squeeze(1)\n",
    "        facade_zone = dilated_existing * (1 - existing)\n",
    "        contact = (structure * facade_zone).sum()\n",
    "        total_struct = structure.sum() + 1e-8\n",
    "        ratio = contact / total_struct\n",
    "        return F.relu(ratio - self.max_ratio)\n",
    "\n",
    "\n",
    "print('Existing losses defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ NEW POROSITY LOSS ============\n",
    "\n",
    "class PorosityLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Encourage internal voids within the structure.\n",
    "    Penalizes structures where interior voxels are filled.\n",
    "    \n",
    "    The idea: erode the structure, what remains is \"interior\".\n",
    "    We want some of that interior to be void (not filled).\n",
    "    \"\"\"\n",
    "    def __init__(self, target_porosity: float = 0.25, erosion_steps: int = 1):\n",
    "        super().__init__()\n",
    "        self.target_porosity = target_porosity\n",
    "        self.erosion_steps = erosion_steps\n",
    "\n",
    "    def forward(self, structure: torch.Tensor, corridor: torch.Tensor) -> torch.Tensor:\n",
    "        # Binary structure\n",
    "        binary = (structure > 0.5).float()\n",
    "        \n",
    "        # Erode to find interior\n",
    "        eroded = binary.clone()\n",
    "        for _ in range(self.erosion_steps):\n",
    "            eroded = -F.max_pool3d(\n",
    "                -eroded.unsqueeze(0).unsqueeze(0), 3, 1, 1\n",
    "            ).squeeze(0).squeeze(0)\n",
    "        \n",
    "        # Interior mask (eroded structure = definitely inside)\n",
    "        interior_mask = eroded > 0.5\n",
    "        \n",
    "        if interior_mask.sum() < 10:  # Not enough interior to measure\n",
    "            return torch.tensor(0.0, device=structure.device)\n",
    "        \n",
    "        # Compute how much of the interior is filled\n",
    "        interior_filled = (structure * interior_mask.float()).sum()\n",
    "        interior_total = interior_mask.float().sum()\n",
    "        \n",
    "        # Porosity = 1 - fill_ratio in interior\n",
    "        fill_ratio = interior_filled / (interior_total + 1e-8)\n",
    "        porosity = 1.0 - fill_ratio\n",
    "        \n",
    "        # Penalize if porosity below target\n",
    "        return F.relu(self.target_porosity - porosity)\n",
    "\n",
    "\n",
    "class SurfaceAreaLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Encourage higher surface-to-volume ratio (more articulated forms).\n",
    "    Higher surface area relative to volume = more porous/lattice-like.\n",
    "    \"\"\"\n",
    "    def __init__(self, target_ratio: float = 3.0):\n",
    "        super().__init__()\n",
    "        self.target_ratio = target_ratio\n",
    "\n",
    "    def forward(self, structure: torch.Tensor) -> torch.Tensor:\n",
    "        binary = (structure > 0.5).float()\n",
    "        volume = binary.sum() + 1e-8\n",
    "        \n",
    "        # Compute surface by counting face exposures\n",
    "        # For each direction, count transitions from filled to empty\n",
    "        padded = F.pad(binary.unsqueeze(0).unsqueeze(0), (1,1,1,1,1,1), value=0).squeeze()\n",
    "        \n",
    "        surface = 0\n",
    "        # Z direction\n",
    "        surface += torch.abs(padded[1:, :, :] - padded[:-1, :, :]).sum()\n",
    "        # Y direction  \n",
    "        surface += torch.abs(padded[:, 1:, :] - padded[:, :-1, :]).sum()\n",
    "        # X direction\n",
    "        surface += torch.abs(padded[:, :, 1:] - padded[:, :, :-1]).sum()\n",
    "        \n",
    "        ratio = surface / volume\n",
    "        \n",
    "        # Penalize if ratio below target (we want HIGH surface area)\n",
    "        return F.relu(self.target_ratio - ratio)\n",
    "\n",
    "\n",
    "print('New porosity losses defined')\n",
    "print(f'  PorosityLoss: target_porosity=0.25')\n",
    "print(f'  SurfaceAreaLoss: target_ratio=3.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fine-Tuning Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PorosityFineTuner:\n",
    "    \"\"\"\n",
    "    Fine-tuning trainer with modified weights and new porosity losses.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: nn.Module, config: dict):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        cfg = config\n",
    "        \n",
    "        max_thickness = cfg.get('max_thickness', 1)\n",
    "        max_facade = cfg.get('max_facade_contact', 0.15)\n",
    "        \n",
    "        # Loss functions\n",
    "        self.legality_loss = LocalLegalityLoss(cfg)\n",
    "        self.coverage_loss = CorridorCoverageLoss(cfg)\n",
    "        self.spill_loss = CorridorSpillLoss(cfg)\n",
    "        self.ground_loss = GroundOpennessLoss(cfg)\n",
    "        self.thickness_loss = ThicknessLoss(max_thickness)\n",
    "        self.sparsity_loss = SparsityLossV31(target_ratio=0.06, squared=True)\n",
    "        self.facade_loss = FacadeContactLoss(cfg, max_facade)\n",
    "        self.access_conn_loss = AccessConnectivityLoss(cfg)\n",
    "        self.loadpath_loss = LoadPathLoss(cfg)\n",
    "        self.cantilever_loss = CantileverLoss()\n",
    "        self.density_loss = DensityPenalty(target=0.04)\n",
    "        self.tv_loss = TotalVariation3D()\n",
    "        \n",
    "        # NEW: Porosity losses\n",
    "        self.porosity_loss = PorosityLoss(target_porosity=0.25)\n",
    "        self.surface_loss = SurfaceAreaLoss(target_ratio=2.5)\n",
    "        \n",
    "        # MODIFIED WEIGHTS for porosity fine-tuning\n",
    "        self.weights = {\n",
    "            'legality': 30.0,\n",
    "            'coverage': 20.0,       # Slightly reduced\n",
    "            'spill': 25.0,\n",
    "            'ground': 35.0,\n",
    "            'thickness': 50.0,      # INCREASED (was 30)\n",
    "            'sparsity': 45.0,       # INCREASED (was 30)\n",
    "            'facade': 10.0,\n",
    "            'access_conn': 15.0,\n",
    "            'loadpath': 10.0,       # Slightly increased for stability\n",
    "            'cantilever': 5.0,\n",
    "            'density': 8.0,         # INCREASED (was 3)\n",
    "            'tv': 0.5,              # REDUCED (was 1) - allow more variation\n",
    "            'porosity': 20.0,       # NEW\n",
    "            'surface': 10.0,        # NEW\n",
    "        }\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            model.parameters(), \n",
    "            lr=cfg.get('lr_finetune', 0.0005)\n",
    "        )\n",
    "        self.scene_gen = UrbanSceneGenerator(cfg)\n",
    "        self.history = []\n",
    "        \n",
    "    def train_epoch(self, epoch: int) -> dict:\n",
    "        self.model.train()\n",
    "        cfg = self.config\n",
    "        batch_size = cfg.get('batch_size', 4)\n",
    "        steps_range = (40, 60)\n",
    "        \n",
    "        # Generate batch of scenes\n",
    "        seeds = []\n",
    "        corridors = []\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            params = self._random_scene_params()\n",
    "            seed, info = self.scene_gen.generate(params, device=device)\n",
    "            corridor = compute_corridor_target_v31(\n",
    "                seed, cfg,\n",
    "                corridor_width=cfg.get('corridor_width', 1),\n",
    "                vertical_envelope=cfg.get('vertical_envelope', 1)\n",
    "            )\n",
    "            seeds.append(seed)\n",
    "            corridors.append(corridor)\n",
    "        \n",
    "        seeds = torch.cat(seeds, dim=0)\n",
    "        corridor_target = torch.cat(corridors, dim=0)\n",
    "        \n",
    "        # Apply corridor seeding\n",
    "        seed_scale = cfg.get('corridor_seed_scale', 0.15)\n",
    "        if seed_scale > 0:\n",
    "            seeds[:, cfg['ch_structure']] = torch.clamp(\n",
    "                seeds[:, cfg['ch_structure']] + seed_scale * corridor_target, 0, 1\n",
    "            )\n",
    "        \n",
    "        # Forward pass\n",
    "        self.optimizer.zero_grad()\n",
    "        steps = np.random.randint(*steps_range)\n",
    "        final = self.model(seeds, steps=steps)\n",
    "        \n",
    "        structure = final[:, cfg['ch_structure']]\n",
    "        existing = final[:, cfg['ch_existing']]\n",
    "        available = 1.0 - existing\n",
    "        legality_field = self.legality_loss.compute_legality_field(final)\n",
    "        \n",
    "        # Compute all losses\n",
    "        L_legality = self.legality_loss(final)\n",
    "        L_coverage = self.coverage_loss(structure, corridor_target)\n",
    "        L_spill = self.spill_loss(structure, corridor_target, legality_field)\n",
    "        L_ground = self.ground_loss(structure, corridor_target, legality_field)\n",
    "        L_thickness = self.thickness_loss(structure)\n",
    "        L_sparsity = self.sparsity_loss(structure, available)\n",
    "        L_facade = self.facade_loss(final)\n",
    "        L_access = self.access_conn_loss(final)\n",
    "        L_loadpath = self.loadpath_loss(final)\n",
    "        L_cant = self.cantilever_loss(structure)\n",
    "        L_density = self.density_loss(structure)\n",
    "        L_tv = self.tv_loss(structure)\n",
    "        \n",
    "        # NEW: Porosity losses\n",
    "        L_porosity = self.porosity_loss(structure, corridor_target)\n",
    "        L_surface = self.surface_loss(structure)\n",
    "        \n",
    "        # Total loss\n",
    "        total_loss = (\n",
    "            self.weights['legality'] * L_legality +\n",
    "            self.weights['coverage'] * L_coverage +\n",
    "            self.weights['spill'] * L_spill +\n",
    "            self.weights['ground'] * L_ground +\n",
    "            self.weights['thickness'] * L_thickness +\n",
    "            self.weights['sparsity'] * L_sparsity +\n",
    "            self.weights['facade'] * L_facade +\n",
    "            self.weights['access_conn'] * L_access +\n",
    "            self.weights['loadpath'] * L_loadpath +\n",
    "            self.weights['cantilever'] * L_cant +\n",
    "            self.weights['density'] * L_density +\n",
    "            self.weights['tv'] * L_tv +\n",
    "            self.weights['porosity'] * L_porosity +\n",
    "            self.weights['surface'] * L_surface\n",
    "        )\n",
    "        \n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), cfg.get('grad_clip', 1.0))\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        metrics = {\n",
    "            'epoch': epoch,\n",
    "            'total_loss': total_loss.item(),\n",
    "            'L_coverage': L_coverage.item(),\n",
    "            'L_spill': L_spill.item(),\n",
    "            'L_thickness': L_thickness.item(),\n",
    "            'L_sparsity': L_sparsity.item(),\n",
    "            'L_porosity': L_porosity.item(),\n",
    "            'L_surface': L_surface.item(),\n",
    "            'fill_ratio': structure.mean().item(),\n",
    "        }\n",
    "        self.history.append(metrics)\n",
    "        return metrics\n",
    "    \n",
    "    def _random_scene_params(self) -> dict:\n",
    "        \"\"\"Generate random scene parameters.\"\"\"\n",
    "        G = self.config['grid_size']\n",
    "        gap_width = np.random.randint(8, 16)\n",
    "        gap_center = G // 2\n",
    "        \n",
    "        left_x = (0, gap_center - gap_width // 2)\n",
    "        right_x = (gap_center + gap_width // 2, G)\n",
    "        \n",
    "        buildings = [\n",
    "            {\n",
    "                'x': list(left_x),\n",
    "                'y': [0, np.random.randint(20, 28)],\n",
    "                'z': [0, np.random.randint(10, 18)],\n",
    "                'side': 'left',\n",
    "                'gap_facing_x': left_x[1]\n",
    "            },\n",
    "            {\n",
    "                'x': list(right_x),\n",
    "                'y': [0, np.random.randint(16, 24)],\n",
    "                'z': [0, np.random.randint(10, 18)],\n",
    "                'side': 'right',\n",
    "                'gap_facing_x': right_x[0]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        access_points = [\n",
    "            {'x': gap_center, 'y': np.random.randint(18, 26), 'z': 0, 'type': 'ground'},\n",
    "        ]\n",
    "        \n",
    "        # Sometimes add elevated access\n",
    "        if np.random.random() > 0.3:\n",
    "            access_points.append({\n",
    "                'x': np.random.choice([left_x[1], right_x[0]]),\n",
    "                'y': np.random.randint(2, 8),\n",
    "                'z': np.random.randint(6, 12),\n",
    "                'type': 'elevated'\n",
    "            })\n",
    "        \n",
    "        return {'buildings': buildings, 'access_points': access_points}\n",
    "    \n",
    "    def evaluate(self, n_samples: int = 8) -> dict:\n",
    "        \"\"\"Evaluate on random samples.\"\"\"\n",
    "        self.model.eval()\n",
    "        cfg = self.config\n",
    "        results = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(n_samples):\n",
    "                params = self._random_scene_params()\n",
    "                seed, _ = self.scene_gen.generate(params, device=device)\n",
    "                corridor = compute_corridor_target_v31(seed, cfg)\n",
    "                \n",
    "                seed_scale = cfg.get('corridor_seed_scale', 0.15)\n",
    "                if seed_scale > 0:\n",
    "                    seed[:, cfg['ch_structure']] += seed_scale * corridor\n",
    "                \n",
    "                grown = self.model(seed, steps=50)\n",
    "                structure = grown[:, cfg['ch_structure']]\n",
    "                \n",
    "                # Compute metrics\n",
    "                corridor_mask = corridor > 0.5\n",
    "                coverage = (structure * corridor_mask.float()).sum() / (corridor_mask.sum() + 1e-8)\n",
    "                \n",
    "                outside = (corridor < 0.5).float()\n",
    "                spill = (structure * outside).sum() / (structure.sum() + 1e-8)\n",
    "                \n",
    "                fill_ratio = structure.mean().item()\n",
    "                \n",
    "                results.append({\n",
    "                    'coverage': coverage.item(),\n",
    "                    'spill': spill.item(),\n",
    "                    'fill_ratio': fill_ratio,\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            'avg_coverage': np.mean([r['coverage'] for r in results]),\n",
    "            'avg_spill': np.mean([r['spill'] for r in results]),\n",
    "            'avg_fill_ratio': np.mean([r['fill_ratio'] for r in results]),\n",
    "        }\n",
    "    \n",
    "    def save_checkpoint(self, path: str, epoch: int):\n",
    "        \"\"\"Save checkpoint.\"\"\"\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'weights': self.weights,\n",
    "            'history': self.history,\n",
    "        }, path)\n",
    "        print(f'Saved checkpoint to {path}')\n",
    "\n",
    "\n",
    "print('PorosityFineTuner defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = PorosityFineTuner(model, CONFIG)\n",
    "\n",
    "print('Fine-tuning weights:')\n",
    "for name, weight in trainer.weights.items():\n",
    "    print(f'  {name}: {weight}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning parameters\n",
    "N_EPOCHS = 150\n",
    "EVAL_EVERY = 10\n",
    "SAVE_EVERY = 25\n",
    "\n",
    "print(f'Starting fine-tuning for {N_EPOCHS} epochs...')\n",
    "print(f'  Eval every {EVAL_EVERY} epochs')\n",
    "print(f'  Save every {SAVE_EVERY} epochs')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_fill_ratio = 1.0\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    metrics = trainer.train_epoch(epoch)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(\n",
    "            f\"Epoch {epoch:4d} | Loss: {metrics['total_loss']:.2f} | \"\n",
    "            f\"Fill: {metrics['fill_ratio']*100:.1f}% | \"\n",
    "            f\"Poros: {metrics['L_porosity']:.3f} | \"\n",
    "            f\"Thick: {metrics['L_thickness']:.3f}\"\n",
    "        )\n",
    "    \n",
    "    if epoch % EVAL_EVERY == 0:\n",
    "        eval_results = trainer.evaluate(n_samples=8)\n",
    "        print(f\"  [EVAL] Coverage: {eval_results['avg_coverage']*100:.1f}% | \"\n",
    "              f\"Spill: {eval_results['avg_spill']*100:.1f}% | \"\n",
    "              f\"Fill: {eval_results['avg_fill_ratio']*100:.1f}%\")\n",
    "        \n",
    "        # Save best by fill ratio (lower is better for porosity)\n",
    "        if eval_results['avg_fill_ratio'] < best_fill_ratio and eval_results['avg_coverage'] > 0.5:\n",
    "            best_fill_ratio = eval_results['avg_fill_ratio']\n",
    "            trainer.save_checkpoint(OUTPUT_DIR / 'best_porous.pth', epoch)\n",
    "    \n",
    "    if epoch % SAVE_EVERY == 0:\n",
    "        trainer.save_checkpoint(OUTPUT_DIR / f'checkpoint_epoch_{epoch}.pth', epoch)\n",
    "\n",
    "# Final save\n",
    "trainer.save_checkpoint(OUTPUT_DIR / 'final_porous.pth', N_EPOCHS)\n",
    "print('\\nFine-tuning complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "history = trainer.history\n",
    "epochs = [h['epoch'] for h in history]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "\n",
    "axes[0, 0].plot(epochs, [h['total_loss'] for h in history])\n",
    "axes[0, 0].set_title('Total Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "\n",
    "axes[0, 1].plot(epochs, [h['L_porosity'] for h in history], 'g')\n",
    "axes[0, 1].set_title('Porosity Loss')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "\n",
    "axes[0, 2].plot(epochs, [h['L_thickness'] for h in history], 'purple')\n",
    "axes[0, 2].set_title('Thickness Loss')\n",
    "axes[0, 2].set_xlabel('Epoch')\n",
    "\n",
    "axes[1, 0].plot(epochs, [h['fill_ratio'] * 100 for h in history], 'orange')\n",
    "axes[1, 0].set_title('Fill Ratio %')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].axhline(y=10, color='r', linestyle='--', alpha=0.5, label='Target max')\n",
    "\n",
    "axes[1, 1].plot(epochs, [h['L_coverage'] for h in history], 'b')\n",
    "axes[1, 1].set_title('Coverage Loss')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "\n",
    "axes[1, 2].plot(epochs, [h['L_sparsity'] for h in history], 'r')\n",
    "axes[1, 2].set_title('Sparsity Loss')\n",
    "axes[1, 2].set_xlabel('Epoch')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'training_curves.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs fine-tuned\n",
    "def visualize_comparison(original_model, finetuned_model, config, seed=42):\n",
    "    \"\"\"Generate and visualize comparison.\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    scene_gen = UrbanSceneGenerator(config)\n",
    "    params = {\n",
    "        'buildings': [\n",
    "            {'x': [1, 9], 'y': [0, 27], 'z': [0, 14], 'side': 'left', 'gap_facing_x': 9},\n",
    "            {'x': [23, 32], 'y': [0, 19], 'z': [0, 14], 'side': 'right', 'gap_facing_x': 23}\n",
    "        ],\n",
    "        'access_points': [\n",
    "            {'x': 12, 'y': 23, 'z': 0, 'type': 'ground'},\n",
    "            {'x': 9, 'y': 1, 'z': 11, 'type': 'elevated'}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    seed_state, _ = scene_gen.generate(params, device=device)\n",
    "    corridor = compute_corridor_target_v31(seed_state, config)\n",
    "    \n",
    "    seed_scale = config.get('corridor_seed_scale', 0.15)\n",
    "    if seed_scale > 0:\n",
    "        seed_state[:, config['ch_structure']] += seed_scale * corridor\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        original_model.eval()\n",
    "        finetuned_model.eval()\n",
    "        \n",
    "        orig_result = original_model(seed_state.clone(), steps=50)\n",
    "        fine_result = finetuned_model(seed_state.clone(), steps=50)\n",
    "    \n",
    "    orig_struct = (orig_result[0, config['ch_structure']] > 0.5).cpu().numpy()\n",
    "    fine_struct = (fine_result[0, config['ch_structure']] > 0.5).cpu().numpy()\n",
    "    \n",
    "    print(f'Original fill ratio: {orig_struct.mean()*100:.1f}%')\n",
    "    print(f'Fine-tuned fill ratio: {fine_struct.mean()*100:.1f}%')\n",
    "    print(f'Reduction: {(1 - fine_struct.mean()/orig_struct.mean())*100:.1f}%')\n",
    "    \n",
    "    return orig_struct, fine_struct\n",
    "\n",
    "# Load original model for comparison\n",
    "original_model = UrbanPavilionNCA(CONFIG).to(device)\n",
    "orig_checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "if isinstance(orig_checkpoint, dict) and 'model_state_dict' in orig_checkpoint:\n",
    "    original_model.load_state_dict(orig_checkpoint['model_state_dict'])\n",
    "else:\n",
    "    original_model.load_state_dict(orig_checkpoint)\n",
    "\n",
    "orig_struct, fine_struct = visualize_comparison(original_model, model, CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy best model to deploy folder\n",
    "import shutil\n",
    "\n",
    "deploy_model_dir = project_root / 'deploy' / 'models'\n",
    "deploy_model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "best_checkpoint = OUTPUT_DIR / 'best_porous.pth'\n",
    "if best_checkpoint.exists():\n",
    "    shutil.copy(best_checkpoint, deploy_model_dir / 'v31_porous.pth')\n",
    "    print(f'Copied best model to {deploy_model_dir / \"v31_porous.pth\"}')\n",
    "else:\n",
    "    final_checkpoint = OUTPUT_DIR / 'final_porous.pth'\n",
    "    shutil.copy(final_checkpoint, deploy_model_dir / 'v31_porous.pth')\n",
    "    print(f'Copied final model to {deploy_model_dir / \"v31_porous.pth\"}')\n",
    "\n",
    "# Also save config\n",
    "with open(deploy_model_dir / 'config_porous.json', 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "print(f'Saved config to {deploy_model_dir / \"config_porous.json\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Fine-tuning complete! The model has been trained with:\n",
    "\n",
    "1. **Increased thickness penalty** (30 → 50)\n",
    "2. **Increased sparsity penalty** (30 → 45)\n",
    "3. **New PorosityLoss** targeting 25% internal voids\n",
    "4. **New SurfaceAreaLoss** encouraging articulated forms\n",
    "5. **Reduced max_thickness** (2 → 1)\n",
    "6. **Lower fill ratio target** (5-15% → 3-10%)\n",
    "\n",
    "The fine-tuned model should produce more porous, lattice-like structures while maintaining corridor coverage and structural validity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
